{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a3cdaeb5312442d8e71a0e1d1bea8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f2996537cb44b81a6e5e4512001df35",
              "IPY_MODEL_956f4a8f66a9494ca8734ec4413c6ee1",
              "IPY_MODEL_38d7cc71772047979e98f54188a1693d"
            ],
            "layout": "IPY_MODEL_a91039a548154b4aaa52dd9e34b9e7f6"
          }
        },
        "4f2996537cb44b81a6e5e4512001df35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442c0db2793c45b8a5e58450cb01d8df",
            "placeholder": "​",
            "style": "IPY_MODEL_9e631b1ba5a14f499a95f76a2e3488ca",
            "value": "config.json: 100%"
          }
        },
        "956f4a8f66a9494ca8734ec4413c6ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731657930a2f45cca9b158e064388c4c",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51f3e874e42e43869f497be2545a36bf",
            "value": 614
          }
        },
        "38d7cc71772047979e98f54188a1693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72e68ebfd8d4f9797b18db5b7ede47c",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc49178613744d69d053b608fe76bdf",
            "value": " 614/614 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "a91039a548154b4aaa52dd9e34b9e7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442c0db2793c45b8a5e58450cb01d8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e631b1ba5a14f499a95f76a2e3488ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "731657930a2f45cca9b158e064388c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f3e874e42e43869f497be2545a36bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a72e68ebfd8d4f9797b18db5b7ede47c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc49178613744d69d053b608fe76bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11bdec8ee4f7490e8c55b8f961a47c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffa648a0eb254b9fa97abc3cac821f21",
              "IPY_MODEL_4b7ba57d32de47b6998ba6005240f907",
              "IPY_MODEL_c4ba0eb4528842f1a6f4501f5efe9034"
            ],
            "layout": "IPY_MODEL_c135b9b4034246ef99003243c35f3e05"
          }
        },
        "ffa648a0eb254b9fa97abc3cac821f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e73c7db8ac4305aefc8abc4d014020",
            "placeholder": "​",
            "style": "IPY_MODEL_7dbfe25924c8403c801527a247f3bd24",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "4b7ba57d32de47b6998ba6005240f907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85f5832ea05444aab13107ff7457f82",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd3b3abbc306400f9314013ab1d41212",
            "value": 26788
          }
        },
        "c4ba0eb4528842f1a6f4501f5efe9034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_203f4880b4ae40088e8a3027221acb1d",
            "placeholder": "​",
            "style": "IPY_MODEL_5a045b8180d7436cb25836b42baf8a08",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.80MB/s]"
          }
        },
        "c135b9b4034246ef99003243c35f3e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e73c7db8ac4305aefc8abc4d014020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dbfe25924c8403c801527a247f3bd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e85f5832ea05444aab13107ff7457f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3b3abbc306400f9314013ab1d41212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "203f4880b4ae40088e8a3027221acb1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a045b8180d7436cb25836b42baf8a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b45099310146fa9ce9b997f7bedab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b654bb6e40e64544b122efa0bbb693a9",
              "IPY_MODEL_e8aa5c8050db4488a32a4aeecc33ba37",
              "IPY_MODEL_8ffc0764a0484df28667af559d332dee"
            ],
            "layout": "IPY_MODEL_aafe0b8d3273476db4a7357f34a3b5f9"
          }
        },
        "b654bb6e40e64544b122efa0bbb693a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5575dcc50f92416588fa985550b50d66",
            "placeholder": "​",
            "style": "IPY_MODEL_a1638448a0304b0cb4edfa6f97ef01b0",
            "value": "Downloading shards: 100%"
          }
        },
        "e8aa5c8050db4488a32a4aeecc33ba37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61804c3651c445fa83bf712c587d4ff8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1bbc56b67834429a6296d648be1108e",
            "value": 2
          }
        },
        "8ffc0764a0484df28667af559d332dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501f681919f64979a5becb261033aa98",
            "placeholder": "​",
            "style": "IPY_MODEL_ac683d7783ec400e9b4daab8c2313121",
            "value": " 2/2 [01:46&lt;00:00, 50.03s/it]"
          }
        },
        "aafe0b8d3273476db4a7357f34a3b5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5575dcc50f92416588fa985550b50d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1638448a0304b0cb4edfa6f97ef01b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61804c3651c445fa83bf712c587d4ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1bbc56b67834429a6296d648be1108e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "501f681919f64979a5becb261033aa98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac683d7783ec400e9b4daab8c2313121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce6b0e8a3fc414288a3778060d6d92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59427e692753432daa858380a0f637da",
              "IPY_MODEL_4469faee156b4788827c404b9a160a97",
              "IPY_MODEL_a0ce9c9222cf47a6902142cb80695183"
            ],
            "layout": "IPY_MODEL_e5a5ae5adb73481d82ed2608424db79c"
          }
        },
        "59427e692753432daa858380a0f637da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff98715cd65f466d9a008dc93b033445",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb7399198204a92ad5ff936431e1c6b",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "4469faee156b4788827c404b9a160a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f262c8138b6944378afd0d318b04ab47",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e4e1c929a024b7a97026f0437cfd651",
            "value": 9976576152
          }
        },
        "a0ce9c9222cf47a6902142cb80695183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697c8eaf5b3740048929c616a18dd3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_8ed556eab3734649a08f580be1bc3b99",
            "value": " 9.98G/9.98G [01:11&lt;00:00, 267MB/s]"
          }
        },
        "e5a5ae5adb73481d82ed2608424db79c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff98715cd65f466d9a008dc93b033445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb7399198204a92ad5ff936431e1c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f262c8138b6944378afd0d318b04ab47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4e1c929a024b7a97026f0437cfd651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "697c8eaf5b3740048929c616a18dd3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed556eab3734649a08f580be1bc3b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ecb3102fdfe4d029f83dab20f38db00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14768d78a8ea4c859725084a5f7f36c9",
              "IPY_MODEL_f739186943ac4aaaa4438e775313328f",
              "IPY_MODEL_75b1efa1c9a5444ab984694227d6288c"
            ],
            "layout": "IPY_MODEL_131f67a5a01542c18c3fa4fd79d238b5"
          }
        },
        "14768d78a8ea4c859725084a5f7f36c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3666a0f10c6d4b7a9abdc704ac95b509",
            "placeholder": "​",
            "style": "IPY_MODEL_d1ce821926054ad4b91db33ac730a222",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "f739186943ac4aaaa4438e775313328f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59980d12b0c42f4afd7f12be5ff18ef",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d60397a50da46e9a2fd5ce051e090a2",
            "value": 3500296424
          }
        },
        "75b1efa1c9a5444ab984694227d6288c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77a8ad00d994d37a992d75467a53cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd85ebf297645b3bb06a5d99377f9ac",
            "value": " 3.50G/3.50G [00:34&lt;00:00, 252MB/s]"
          }
        },
        "131f67a5a01542c18c3fa4fd79d238b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3666a0f10c6d4b7a9abdc704ac95b509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ce821926054ad4b91db33ac730a222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b59980d12b0c42f4afd7f12be5ff18ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d60397a50da46e9a2fd5ce051e090a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d77a8ad00d994d37a992d75467a53cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd85ebf297645b3bb06a5d99377f9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c15b98938264695abba8c9ba3950dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3d3c77a02764587968f6bf388c312b8",
              "IPY_MODEL_f7199c60a4cb4318aa34046d4179ae49",
              "IPY_MODEL_328ec93636d64a108520d6b70c022cc1"
            ],
            "layout": "IPY_MODEL_bbf930e7768c4c5598a8f5f832052cfb"
          }
        },
        "c3d3c77a02764587968f6bf388c312b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c33b105d7eb4d6e863e7aa4897334b7",
            "placeholder": "​",
            "style": "IPY_MODEL_504eb4e3bf144cd689be5173082ab6c3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f7199c60a4cb4318aa34046d4179ae49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c950648b7e4df39a1a469b02bbf5fc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2048e5a40f7b41d181d2017fb67afeaa",
            "value": 2
          }
        },
        "328ec93636d64a108520d6b70c022cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1390c8cd4d42409a06f9fc34d0d08c",
            "placeholder": "​",
            "style": "IPY_MODEL_8b4360e8bd6b461caf6d0e2bd79dc655",
            "value": " 2/2 [00:59&lt;00:00, 27.28s/it]"
          }
        },
        "bbf930e7768c4c5598a8f5f832052cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c33b105d7eb4d6e863e7aa4897334b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504eb4e3bf144cd689be5173082ab6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74c950648b7e4df39a1a469b02bbf5fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2048e5a40f7b41d181d2017fb67afeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee1390c8cd4d42409a06f9fc34d0d08c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4360e8bd6b461caf6d0e2bd79dc655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41d5b52fa4fa4d1180f0483c48197073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03e96c0e76a94d4e8c8169fa8fa917b0",
              "IPY_MODEL_d470605bf51a48078ed45dce7745a6cf",
              "IPY_MODEL_ecc4fa783494495d8a6078790c404f90"
            ],
            "layout": "IPY_MODEL_49b76cc256034683b0194ec10578b5cc"
          }
        },
        "03e96c0e76a94d4e8c8169fa8fa917b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e61c00b8e3469f9ccdc9cbba3b1e08",
            "placeholder": "​",
            "style": "IPY_MODEL_72c479d95c284e8992e3d0212d6f1e79",
            "value": "generation_config.json: 100%"
          }
        },
        "d470605bf51a48078ed45dce7745a6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_753e896900e446c8b0f0c2075eb5f278",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfac248fa0304ebaab28395c8405b8cc",
            "value": 188
          }
        },
        "ecc4fa783494495d8a6078790c404f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd9c36196a4d8199840ca701f1a7ff",
            "placeholder": "​",
            "style": "IPY_MODEL_17952b8d2e064926be5869ae8dfbc4fc",
            "value": " 188/188 [00:00&lt;00:00, 13.0kB/s]"
          }
        },
        "49b76cc256034683b0194ec10578b5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e61c00b8e3469f9ccdc9cbba3b1e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c479d95c284e8992e3d0212d6f1e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "753e896900e446c8b0f0c2075eb5f278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfac248fa0304ebaab28395c8405b8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11cd9c36196a4d8199840ca701f1a7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17952b8d2e064926be5869ae8dfbc4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee74ea6217a54f47bdc566775022faf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84c7c5cfab864de5a306cba6d33a1283",
              "IPY_MODEL_3f0f7765744f4083831c4f690bee474e",
              "IPY_MODEL_2093f3422e09452b9c4d6c495cf38e9f"
            ],
            "layout": "IPY_MODEL_47c9f2a40ccf4bf690ee0c62cb08b962"
          }
        },
        "84c7c5cfab864de5a306cba6d33a1283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de93d23b6eb2471ebd192c1e92b1682b",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f537cbe1dd4fcf83ef0131a2e061ec",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3f0f7765744f4083831c4f690bee474e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e775aa19e84b71884a2ddb71f77c33",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663c288a12e94627977d8a16c5a37611",
            "value": 1618
          }
        },
        "2093f3422e09452b9c4d6c495cf38e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f980299e244c96bb139fffdbfa851d",
            "placeholder": "​",
            "style": "IPY_MODEL_dde05a3407684aaa93cd0c3d0e0aebe4",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 85.4kB/s]"
          }
        },
        "47c9f2a40ccf4bf690ee0c62cb08b962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de93d23b6eb2471ebd192c1e92b1682b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f537cbe1dd4fcf83ef0131a2e061ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e775aa19e84b71884a2ddb71f77c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663c288a12e94627977d8a16c5a37611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27f980299e244c96bb139fffdbfa851d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde05a3407684aaa93cd0c3d0e0aebe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a75d277abd3647e5a1094ee73441207d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7f76b65c8714f8abf759a7742f48b1d",
              "IPY_MODEL_6346f0130a5a46ea9dde476ece30b3d7",
              "IPY_MODEL_a131b3043ef74cb38ce9508e293021f6"
            ],
            "layout": "IPY_MODEL_80cca532b79e479da70c03886d53defb"
          }
        },
        "e7f76b65c8714f8abf759a7742f48b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c41764d8d3434c88a949528b9e6ac0",
            "placeholder": "​",
            "style": "IPY_MODEL_12f522045f2e44fda6092ff822627108",
            "value": "tokenizer.model: 100%"
          }
        },
        "6346f0130a5a46ea9dde476ece30b3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b65273aa15941e48143c5ce8171da69",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdd52a4e98cd4e01845e7cfa06fe8462",
            "value": 499723
          }
        },
        "a131b3043ef74cb38ce9508e293021f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3f6e0ba794f4455b1532b30a2c81d55",
            "placeholder": "​",
            "style": "IPY_MODEL_f04dcf1709b74b85b6bb67fec9550b32",
            "value": " 500k/500k [00:00&lt;00:00, 34.1MB/s]"
          }
        },
        "80cca532b79e479da70c03886d53defb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c41764d8d3434c88a949528b9e6ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f522045f2e44fda6092ff822627108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b65273aa15941e48143c5ce8171da69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd52a4e98cd4e01845e7cfa06fe8462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3f6e0ba794f4455b1532b30a2c81d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04dcf1709b74b85b6bb67fec9550b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd90eed6635423dbebd310954643a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f06d5be68fb46dbb27ea2c81202f795",
              "IPY_MODEL_7df9924dd3f04dc79caa454b64ac5422",
              "IPY_MODEL_9f585bd2d4d74eb5995e3397309dd885"
            ],
            "layout": "IPY_MODEL_101f3b6948c34ba9af1a1e0385018a9c"
          }
        },
        "6f06d5be68fb46dbb27ea2c81202f795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f8bcd9fbcc43578ea17b0d76b1bd82",
            "placeholder": "​",
            "style": "IPY_MODEL_3a67c48abd624181861c1ed05d763889",
            "value": "tokenizer.json: 100%"
          }
        },
        "7df9924dd3f04dc79caa454b64ac5422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a83706605b84b6c8a092d445c574043",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9d4c75f938546eeaf208dd6b66b0ce0",
            "value": 1842767
          }
        },
        "9f585bd2d4d74eb5995e3397309dd885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4781922c8d4c05a5abc81e40d513de",
            "placeholder": "​",
            "style": "IPY_MODEL_aa6bc2c5e7c34f6eba0c54ae0f669789",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 5.74MB/s]"
          }
        },
        "101f3b6948c34ba9af1a1e0385018a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f8bcd9fbcc43578ea17b0d76b1bd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a67c48abd624181861c1ed05d763889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a83706605b84b6c8a092d445c574043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d4c75f938546eeaf208dd6b66b0ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca4781922c8d4c05a5abc81e40d513de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6bc2c5e7c34f6eba0c54ae0f669789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bf4f3a723934c5db78d1376d899f6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc3ffadd0d3f46f0b3898c9b2e98b887",
              "IPY_MODEL_5eb166fcd6464c0b927cc3a74c400ea8",
              "IPY_MODEL_c119379e10a2441ebbd5a63c7350765e"
            ],
            "layout": "IPY_MODEL_beb5ba44426e4deca4d19213c6b1fedb"
          }
        },
        "fc3ffadd0d3f46f0b3898c9b2e98b887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7d9a5ded1c40959fd3748da52038e4",
            "placeholder": "​",
            "style": "IPY_MODEL_38869a9453bb48588a2c72660300a764",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5eb166fcd6464c0b927cc3a74c400ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0498bedd84fc400490f74ea8e2d3668c",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fdc86c384e64a6a823d6bd1f4f4d845",
            "value": 414
          }
        },
        "c119379e10a2441ebbd5a63c7350765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41120d480cc94d66b7a42ff29b89a986",
            "placeholder": "​",
            "style": "IPY_MODEL_e74e3d2abd614b769f325f8c020a41c7",
            "value": " 414/414 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "beb5ba44426e4deca4d19213c6b1fedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7d9a5ded1c40959fd3748da52038e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38869a9453bb48588a2c72660300a764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0498bedd84fc400490f74ea8e2d3668c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fdc86c384e64a6a823d6bd1f4f4d845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41120d480cc94d66b7a42ff29b89a986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74e3d2abd614b769f325f8c020a41c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3412fdba8c74cdb8115a5ef34e9e4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62dcc1a6076b430db0ba315433caa184",
              "IPY_MODEL_5675bd36cc6845c192cbcb1b4cfa85b0",
              "IPY_MODEL_c17e13216bc340e8805b63695ec7c0ef"
            ],
            "layout": "IPY_MODEL_19aa4770299b466f93fa8a0fea76f28f"
          }
        },
        "62dcc1a6076b430db0ba315433caa184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2426c460e944509987f1d2d8e172e66",
            "placeholder": "​",
            "style": "IPY_MODEL_b8cfd324ffaa41e29d8be98ddebc5707",
            "value": "modules.json: 100%"
          }
        },
        "5675bd36cc6845c192cbcb1b4cfa85b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ad179940a7473689a237efe09627ec",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01652808bb384ae9845ba571e8e80acb",
            "value": 349
          }
        },
        "c17e13216bc340e8805b63695ec7c0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7697e53281ac44c6acd7187918172b87",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b648f2ea264c48aad7a0eaef0baf2c",
            "value": " 349/349 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "19aa4770299b466f93fa8a0fea76f28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2426c460e944509987f1d2d8e172e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cfd324ffaa41e29d8be98ddebc5707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ad179940a7473689a237efe09627ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01652808bb384ae9845ba571e8e80acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7697e53281ac44c6acd7187918172b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b648f2ea264c48aad7a0eaef0baf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "788fcd4b43b34fcea56c94078efa5a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bde4d0800124ebabca181560223ec64",
              "IPY_MODEL_7ae85d70b0434df5a7361e1c2f8e0fe2",
              "IPY_MODEL_639e16da384440aba4aeb248037765a4"
            ],
            "layout": "IPY_MODEL_750ce5f50e5448aeab8376d5d50f0beb"
          }
        },
        "6bde4d0800124ebabca181560223ec64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64cc131ed29411aa21d6777c456de60",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4388b19e234eac87750316d35fb4a7",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "7ae85d70b0434df5a7361e1c2f8e0fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86053b27747949bfb94eff080db7ef24",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87f74c46852845808f9670d5b17a5f4b",
            "value": 116
          }
        },
        "639e16da384440aba4aeb248037765a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef536322abd041f7a83e0537fa60c007",
            "placeholder": "​",
            "style": "IPY_MODEL_4afabbdceebf44bebe8c2fc9dc5f8ce7",
            "value": " 116/116 [00:00&lt;00:00, 7.60kB/s]"
          }
        },
        "750ce5f50e5448aeab8376d5d50f0beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64cc131ed29411aa21d6777c456de60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4388b19e234eac87750316d35fb4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86053b27747949bfb94eff080db7ef24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f74c46852845808f9670d5b17a5f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef536322abd041f7a83e0537fa60c007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4afabbdceebf44bebe8c2fc9dc5f8ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1beb9ad656724fcea71035399a59c36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7989719c39404e9fabe91d95f7f885a6",
              "IPY_MODEL_2ff8a02fd2144df2bc41b2b56d2b3bcd",
              "IPY_MODEL_9918e290ea0b451cb5c6a003f58df5a6"
            ],
            "layout": "IPY_MODEL_e95795f5effa49bda4fc3127863128b2"
          }
        },
        "7989719c39404e9fabe91d95f7f885a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548b010a06eb4502b3a8622443d348b6",
            "placeholder": "​",
            "style": "IPY_MODEL_068af13cce2942cc9782e52d29ab47f6",
            "value": "README.md: 100%"
          }
        },
        "2ff8a02fd2144df2bc41b2b56d2b3bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022e357b003640a992dee5b906a83c00",
            "max": 10571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c332100273e0410f8035ed0d53069897",
            "value": 10571
          }
        },
        "9918e290ea0b451cb5c6a003f58df5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68d2d1a54f543a99b2bce7e74b1d177",
            "placeholder": "​",
            "style": "IPY_MODEL_30e24322c54045c99746e261d23c96a6",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 625kB/s]"
          }
        },
        "e95795f5effa49bda4fc3127863128b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548b010a06eb4502b3a8622443d348b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068af13cce2942cc9782e52d29ab47f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022e357b003640a992dee5b906a83c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c332100273e0410f8035ed0d53069897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d68d2d1a54f543a99b2bce7e74b1d177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e24322c54045c99746e261d23c96a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f634f2b06c4447108e6820d9a3d94ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5cab174fbe74a1fb664624d6246b9c9",
              "IPY_MODEL_a22ea77d119a4079a6854d219da3c9f9",
              "IPY_MODEL_93008e41f0f6469cbd7afdf704e86109"
            ],
            "layout": "IPY_MODEL_58a6b15adb04485b9a41dd05d9bff23b"
          }
        },
        "f5cab174fbe74a1fb664624d6246b9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa966b29e1fb46fe8f67a07eee6c15eb",
            "placeholder": "​",
            "style": "IPY_MODEL_22f163e554f042fd8acfb671cb4b63a8",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "a22ea77d119a4079a6854d219da3c9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5e2a793a4d54df1aad575973244325a",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0148eba4477944bca315ea95808c687e",
            "value": 53
          }
        },
        "93008e41f0f6469cbd7afdf704e86109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6dfcfc552ab4d6bb7b5afd72859d627",
            "placeholder": "​",
            "style": "IPY_MODEL_5b836be082e146558a34c2a13f5e5d3a",
            "value": " 53.0/53.0 [00:00&lt;00:00, 765B/s]"
          }
        },
        "58a6b15adb04485b9a41dd05d9bff23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa966b29e1fb46fe8f67a07eee6c15eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f163e554f042fd8acfb671cb4b63a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5e2a793a4d54df1aad575973244325a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0148eba4477944bca315ea95808c687e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6dfcfc552ab4d6bb7b5afd72859d627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b836be082e146558a34c2a13f5e5d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "709c43675919420a917a71d4942d74fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac8ae8d605e94634827793f42a579ff4",
              "IPY_MODEL_373c8397932b43b0bcccb45144a2c42f",
              "IPY_MODEL_7b9a0d728bd84c1e9618749e37175db6"
            ],
            "layout": "IPY_MODEL_7c3b16c4c7454ef28d9e0d83c47dbfe6"
          }
        },
        "ac8ae8d605e94634827793f42a579ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51efa7f044e4c10978689bb5b5d597a",
            "placeholder": "​",
            "style": "IPY_MODEL_d32d7993eb6d49dd80a8ea8d29a566a8",
            "value": "config.json: 100%"
          }
        },
        "373c8397932b43b0bcccb45144a2c42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affde320ac5846509a0e75e6a8b94a1f",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69265ac43b84667a68b2a2bd14719f6",
            "value": 571
          }
        },
        "7b9a0d728bd84c1e9618749e37175db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4d6a9ab1014649ba96fa9054c767f6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f827c956941465198a4b82c733367ad",
            "value": " 571/571 [00:00&lt;00:00, 35.1kB/s]"
          }
        },
        "7c3b16c4c7454ef28d9e0d83c47dbfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51efa7f044e4c10978689bb5b5d597a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32d7993eb6d49dd80a8ea8d29a566a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "affde320ac5846509a0e75e6a8b94a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69265ac43b84667a68b2a2bd14719f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4d6a9ab1014649ba96fa9054c767f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f827c956941465198a4b82c733367ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce9f8154f884287ae4785c1800a8283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2725dfb68f6a4b45a6a7aeaed74a46b6",
              "IPY_MODEL_fb9eca1dea1f4d9bad8905d4b5cd26a3",
              "IPY_MODEL_fb7f01297eec4cf0970fd17e3700ec75"
            ],
            "layout": "IPY_MODEL_97f9f4356d274bc89cd444de42478b1f"
          }
        },
        "2725dfb68f6a4b45a6a7aeaed74a46b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6754512f6fd2405c8b389061d7c5ba66",
            "placeholder": "​",
            "style": "IPY_MODEL_52ec50b3b51341b4bd3ac5665d97690b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fb9eca1dea1f4d9bad8905d4b5cd26a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82207c0f06ce4e48b433dff306967243",
            "max": 438011953,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52a808de56c64267b846e040da101657",
            "value": 438011953
          }
        },
        "fb7f01297eec4cf0970fd17e3700ec75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b281c38a65a40a382c2f331c9ed548c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a2afa6b9cae4690b9791551663490e6",
            "value": " 438M/438M [00:03&lt;00:00, 149MB/s]"
          }
        },
        "97f9f4356d274bc89cd444de42478b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6754512f6fd2405c8b389061d7c5ba66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ec50b3b51341b4bd3ac5665d97690b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82207c0f06ce4e48b433dff306967243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a808de56c64267b846e040da101657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b281c38a65a40a382c2f331c9ed548c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2afa6b9cae4690b9791551663490e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d4b8dcc1284c4299fe96932699f5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e49dfb7cb04b77a97de8ff5cafbc6b",
              "IPY_MODEL_df2053dc01384278b9a872ab26b08b1c",
              "IPY_MODEL_3a6d3e14d4ac430dbecd65a846d9cdab"
            ],
            "layout": "IPY_MODEL_793850d4af884edba15d0fffd8b91deb"
          }
        },
        "c4e49dfb7cb04b77a97de8ff5cafbc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e16984419b41a89c90e676df1405a1",
            "placeholder": "​",
            "style": "IPY_MODEL_f67948407a80463f973b55d0b5f926d4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "df2053dc01384278b9a872ab26b08b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_844fed9083c8452abe297a7a731139cd",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d7a3ffc2a11479fb93dc8841da82d7e",
            "value": 363
          }
        },
        "3a6d3e14d4ac430dbecd65a846d9cdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5529d1ad4b7a414ab28e8de4135729e7",
            "placeholder": "​",
            "style": "IPY_MODEL_3d0de259cab440a3bd5364b57c97c08d",
            "value": " 363/363 [00:00&lt;00:00, 26.4kB/s]"
          }
        },
        "793850d4af884edba15d0fffd8b91deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e16984419b41a89c90e676df1405a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67948407a80463f973b55d0b5f926d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "844fed9083c8452abe297a7a731139cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7a3ffc2a11479fb93dc8841da82d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5529d1ad4b7a414ab28e8de4135729e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0de259cab440a3bd5364b57c97c08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "526182b5d780424fa599d0451da9e281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dde783e0bce646a983cb58ca45fa4501",
              "IPY_MODEL_8df97dafb3154b8ea89dda3fb15bd3f1",
              "IPY_MODEL_7327de40bfe440049d174a3b53435027"
            ],
            "layout": "IPY_MODEL_ed3fee43eb1f4e989e2d3a5524a2b1ba"
          }
        },
        "dde783e0bce646a983cb58ca45fa4501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4746e59e361444a8eac555c64d85a9e",
            "placeholder": "​",
            "style": "IPY_MODEL_a52fc2f000c842839634092f265b7e15",
            "value": "vocab.txt: 100%"
          }
        },
        "8df97dafb3154b8ea89dda3fb15bd3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3087d8ee39474f87ef36e417a839ab",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98fb293ff8084c82926a1f4ab55f06d2",
            "value": 231536
          }
        },
        "7327de40bfe440049d174a3b53435027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f485b24e873b432e8e24ac20c4e0707a",
            "placeholder": "​",
            "style": "IPY_MODEL_42cfcba778e7444dac3019c265e6cef7",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "ed3fee43eb1f4e989e2d3a5524a2b1ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4746e59e361444a8eac555c64d85a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52fc2f000c842839634092f265b7e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c3087d8ee39474f87ef36e417a839ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fb293ff8084c82926a1f4ab55f06d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f485b24e873b432e8e24ac20c4e0707a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cfcba778e7444dac3019c265e6cef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf44ba6f59941ae935e2dc21afbf76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_972fa3ce9a614b70bd18edd77dfa647d",
              "IPY_MODEL_fe0119f843e947ae89c4abc1b1a18099",
              "IPY_MODEL_c10b777a9e4644cf9051ab3e2804e610"
            ],
            "layout": "IPY_MODEL_60ee629044e2428b83fd489e2b766511"
          }
        },
        "972fa3ce9a614b70bd18edd77dfa647d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8e16a361cbe42669aca27da0373c0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc8e0df6c3443ceb0e1408eb8b163b5",
            "value": "tokenizer.json: 100%"
          }
        },
        "fe0119f843e947ae89c4abc1b1a18099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6ed615064843f4bb0636d33e1dff65",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d84ce8c1b2c4d35a4a3f7a59ded2033",
            "value": 466021
          }
        },
        "c10b777a9e4644cf9051ab3e2804e610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf366a5864f4305a333e37a56e62f99",
            "placeholder": "​",
            "style": "IPY_MODEL_4aff9715b9c341969f94cb5c0f48bfd9",
            "value": " 466k/466k [00:00&lt;00:00, 2.86MB/s]"
          }
        },
        "60ee629044e2428b83fd489e2b766511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e16a361cbe42669aca27da0373c0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc8e0df6c3443ceb0e1408eb8b163b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc6ed615064843f4bb0636d33e1dff65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d84ce8c1b2c4d35a4a3f7a59ded2033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddf366a5864f4305a333e37a56e62f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aff9715b9c341969f94cb5c0f48bfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea44812268ab45348f24749d4dc376a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85662210812d4b1f92b393c837590b5e",
              "IPY_MODEL_6cf1bcc1df794c74af6ba097320a102c",
              "IPY_MODEL_d4fbafe3c48941eea00aa0e465cdbe17"
            ],
            "layout": "IPY_MODEL_33f8c509594946af92993b082af87b6d"
          }
        },
        "85662210812d4b1f92b393c837590b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6e08db0d94423e8474a4df788361e0",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9796eed9f84728ba6b52c0f9cb706a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6cf1bcc1df794c74af6ba097320a102c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54bdee60700943b3ab59cf62bec05134",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6837e5c7b2184216b2d753b4ee8d5e44",
            "value": 239
          }
        },
        "d4fbafe3c48941eea00aa0e465cdbe17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473e4baec09f46e9b1f1a6fa2b25bbcc",
            "placeholder": "​",
            "style": "IPY_MODEL_36033629c2f44818a647e4b1da0be6a3",
            "value": " 239/239 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "33f8c509594946af92993b082af87b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6e08db0d94423e8474a4df788361e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9796eed9f84728ba6b52c0f9cb706a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54bdee60700943b3ab59cf62bec05134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6837e5c7b2184216b2d753b4ee8d5e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "473e4baec09f46e9b1f1a6fa2b25bbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36033629c2f44818a647e4b1da0be6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e663c05004e4e75bb2069d435ae3293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_078bd59e2c9646cf9ea93e2d18773d4b",
              "IPY_MODEL_651832823e8c44ca8589e3d48c8a2478",
              "IPY_MODEL_731386b39dba41339280989158673fd4"
            ],
            "layout": "IPY_MODEL_f2a44171bab643f19faab772579219e7"
          }
        },
        "078bd59e2c9646cf9ea93e2d18773d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9705cd09b68849caaa0ed693d2e0619d",
            "placeholder": "​",
            "style": "IPY_MODEL_1de56fede02444e797a638aac4f30064",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "651832823e8c44ca8589e3d48c8a2478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_458ea5aa2033417396b99e7183d06094",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eca69af3772c4c8eacb2a11c4e30140d",
            "value": 190
          }
        },
        "731386b39dba41339280989158673fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39aeb6bf69843cfb312330d3438cf07",
            "placeholder": "​",
            "style": "IPY_MODEL_280b9fc5706b40699bca49c5fd3d9421",
            "value": " 190/190 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "f2a44171bab643f19faab772579219e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9705cd09b68849caaa0ed693d2e0619d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de56fede02444e797a638aac4f30064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "458ea5aa2033417396b99e7183d06094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca69af3772c4c8eacb2a11c4e30140d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a39aeb6bf69843cfb312330d3438cf07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280b9fc5706b40699bca49c5fd3d9421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG System using Llama2 with Hugging Face"
      ],
      "metadata": {
        "id": "omExDcH4w6y6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEftuSm3wUnd",
        "outputId": "1a501723-4f24-48fb-f989-9b7db46af4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/284.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/284.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZq3J8eGwb5d",
        "outputId": "ca330e84-2ba6-4bd4-d5f9-326fc0a603b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb3VM_hUwb89",
        "outputId": "3c284afc-9172-426c-96e8-224dbc5d108a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3k__Leswb3O",
        "outputId": "15e55b19-a34d-4d43-8431-4841330f151a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.9.40)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.26.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (3.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama_index) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjHVSo3Oz7zP",
        "outputId": "b092c498-7bb3-4c51-e46a-2ec2db9bbc14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "from llama_index.prompts.prompts import SimpleInputPrompt\n"
      ],
      "metadata": {
        "id": "GP2UgTBpwbz4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecv2F9m0wbyF",
        "outputId": "996d809a-b022-433a-ec03-aa63825c6904"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id_='17eac6f7-952c-4672-ba03-27b6a25d66bb', embedding=None, metadata={'page_label': '1', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='QL ORA: Efficient Finetuning of Quantized LLMs\\nTim Dettmers∗Artidoro Pagnoni∗Ari Holtzman\\nLuke Zettlemoyer\\nUniversity of Washington\\n{dettmers,artidoro,ahai,lsz}@cs.washington.edu\\nAbstract\\nWe present QLORA, an efficient finetuning approach that reduces memory us-\\nage enough to finetune a 65B parameter model on a single 48GB GPU while\\npreserving full 16-bit finetuning task performance. QLORAbackpropagates gradi-\\nents through a frozen, 4-bit quantized pretrained language model into Low Rank\\nAdapters (LoRA). Our best model family, which we name Guanaco , outperforms\\nall previous openly released models on the Vicuna benchmark, reaching 99.3%\\nof the performance level of ChatGPT while only requiring 24 hours of finetuning\\non a single GPU. QLORAintroduces a number of innovations to save memory\\nwithout sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that\\nis information theoretically optimal for normally distributed weights (b) Double\\nQuantization to reduce the average memory footprint by quantizing the quantization\\nconstants, and (c) Paged Optimizers to manage memory spikes. We use QLORA\\nto finetune more than 1,000 models, providing a detailed analysis of instruction\\nfollowing and chatbot performance across 8 instruction datasets, multiple model\\ntypes (LLaMA, T5), and model scales that would be infeasible to run with regular\\nfinetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA\\nfinetuning on a small high-quality dataset leads to state-of-the-art results, even\\nwhen using smaller models than the previous SoTA. We provide a detailed analysis\\nof chatbot performance based on both human and GPT-4 evaluations showing that\\nGPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Fur-\\nthermore, we find that current chatbot benchmarks are not trustworthy to accurately\\nevaluate the performance levels of chatbots. A lemon-picked analysis demonstrates\\nwhere Guanaco fails compared to ChatGPT. We release all of our models and code,\\nincluding CUDA kernels for 4-bit training.2\\n1 Introduction\\nFinetuning large language models (LLMs) is a highly effective way to improve their performance,\\n[40,62,43,61,59,37] and to add desirable or remove undesirable behaviors [ 43,2,4]. However,\\nfinetuning very large models is prohibitively expensive; regular 16-bit finetuning of a LLaMA 65B\\nparameter model [ 57] requires more than 780 GB of GPU memory. While recent quantization\\nmethods can reduce the memory footprint of LLMs [ 14,13,18,66], such techniques only work for\\ninference and break down during training [65].\\nWe demonstrate for the first time that it is possible to finetune a quantized 4-bit model without any\\nperformance degradation. Our method, QLORA, uses a novel high-precision technique to quantize\\na pretrained model to 4-bit, then adds a small set of learnable Low-rank Adapter weights [ 28]\\n∗Equal contribution.\\n2https://github.com/artidoro/qlora andhttps://github.com/TimDettmers/bitsandbytes\\nPreprint. Under review.arXiv:2305.14314v1  [cs.LG]  23 May 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0a71cb6d-aff0-41db-ab2e-f06632bb6065', embedding=None, metadata={'page_label': '2', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 1: Elo ratings for a competition between\\nmodels, averaged for 10,000 random initial order-\\nings. The winner of a match is determined by\\nGPT-4 which declares which response is better for\\na given prompt of the the Vicuna benchmark. 95%\\nconfidence intervals are shown ( ±). After GPT-\\n4, Guanaco 33B and 65B win the most matches,\\nwhile Guanaco 13B scores better than Bard.\\nModel Size Elo\\nGPT-4 - 1348 ±1\\nGuanaco 65B 41 GB 1022 ±1\\nGuanaco 33B 21 GB 992 ±1\\nVicuna 13B 26 GB 974 ±1\\nChatGPT - 966 ±1\\nGuanaco 13B 10 GB 916 ±1\\nBard - 902 ±1\\nGuanaco 7B 6 GB 879 ±1that are tuned by backpropagating gradients through\\nthe quantized weights.\\nQLORAreduces the average memory requirements\\nof finetuning a 65B parameter model from >780GB\\nof GPU memory to <48GB without degrading the\\nruntime or predictive performance compared to a 16-\\nbit fully finetuned baseline. This marks a significant\\nshift in accessibility of LLM finetuning: now the\\nlargest publicly available models to date finetunable\\non a single GPU. Using QLORA, we train the Gua-\\nnaco family of models, with the second best model\\nreaching 97.8% of the performance level of ChatGPT\\non the Vicuna [ 10] benchmark, while being trainable\\nin less than 12 hours on a single consumer GPU;\\nusing a single professional GPU over 24 hours we\\nachieve 99.3% with our largest model, essentially\\nclosing the gap to ChatGPT on the Vicuna bench-\\nmark. When deployed, our smallest Guanaco model\\n(7B parameters) requires just 5 GB of memory and outperforms a 26 GB Alpaca model by more than\\n20 percentage points on the Vicuna benchmark (Table 6).\\nQLORAintroduces multiple innovations designed to reduce memory use without sacrificing per-\\nformance: (1) 4-bit NormalFloat , an information theoretically optimal quantization data type for\\nnormally distributed data that yields better empirical results than 4-bit Integers and 4-bit Floats.\\n(2)Double Quantization , a method that quantizes the quantization constants, saving an average\\nof about 0.37 bits per parameter (approximately 3 GB for a 65B model). (3) Paged Optimizers ,\\nusing NVIDIA unified memory to avoid the gradient checkpointing memory spikes that occur when\\nprocessing a mini-batch with a long sequence length. We combine these contributions into a better\\ntuned LoRA approach that includes adapters at every network layer and thereby avoids almost all of\\nthe accuracy tradeoffs seen in prior work.\\nQLORA’s efficiency enables us to perform an in-depth study of instruction finetuning and chatbot\\nperformance on model scales that would be impossible using regular finetuning due to memory\\noverhead. Therefore, we train more than 1,000 models across several instruction tuning datasets,\\nmodel architectures, and sizes between 80M to 65B parameters. In addition to showing that QLORA\\nrecovers 16-bit performance (§4) and training a state-of-the-art chatbot, Guanaco , (§5), we also\\nanalyze trends in the trained models. First, we find that data quality is far more important than\\ndataset size, e.g., a 9k sample dataset (OASST1) outperformed a 450k sample dataset (FLAN v2,\\nsubsampled) on chatbot performance, even when both are meant to support instruction following\\ngeneralization. Second, we show that strong Massive Multitask Language Understanding (MMLU)\\nbenchmark performance does not imply strong Vicuna chatbot benchmark performance and vice\\nversa—in other words, dataset suitability matters more than size for a given task.\\nFurthermore, we also provide a extensive analysis of chatbot performance that uses both human\\nraters and GPT-4 for evaluation. We use tournament-style benchmarking where models compete\\nagainst each other in matches to produce the best response for a given prompt. The winner of a\\nmatch is judged by either GPT-4 or human annotators. The tournament results are aggregated into\\nElo scores [ 16,17] which determine the ranking of chatbot performance. We find that GPT-4 and\\nhuman evaluations largely agree on the rank of model performance in the tournaments, but we also\\nfind there are instances of strong disagreement. As such, we highlight that model-based evaluation\\nwhile providing a cheap alternative to human-annotation also has its uncertainties.\\nWe augment our chatbot benchmark results with a qualitative analysis of Guanaco models. Our analy-\\nsis highlights success and failure cases that were not captured by the quantitative benchmarks.\\nWe release all model generations with human and GPT-4 annotations to facilitate further study. We\\nopen-source our codebase and CUDA kernels and integrate our methods into the Hugging Face\\ntransformers stack [ 64], making them easily accessible to all. We release a collection of adapters\\nfor 7/13/33/65B size models, trained on 8 different instruction following datasets, for a total of 32\\ndifferent open sourced, finetuned models.\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='401f42c8-3ec8-4a1b-8965-6c4295f055e8', embedding=None, metadata={'page_label': '3', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Figure 1: Different finetuning methods and their memory requirements. QLORAimproves over LoRA by\\nquantizing the transformer model to 4-bit precision and using paged optimizers to handle memory spikes.\\n2 Background\\nBlock-wise k-bit Quantization Quantization is the process of discretizing an input from a rep-\\nresentation that holds more information to a representation with less information. It often means\\ntaking a data type with more bits and converting it to fewer bits, for example from 32-bit floats to\\n8-bit Integers. To ensure that the entire range of the low-bit data type is used, the input data type is\\ncommonly rescaled into the target data type range through normalization by the absolute maximum\\nof the input elements, which are usually structured as a tensor. For example, quantizing a 32-bit\\nFloating Point (FP32) tensor into a Int8 tensor with range [−127,127]:\\nXInt8=round\\x12127\\nabsmax (XFP32)XFP32\\x13\\n=round (cFP32·XFP32), (1)\\nwhere cis the quantization constant orquantization scale . Dequantization is the inverse:\\ndequant (cFP32,XInt8) =XInt8\\ncFP32=XFP32(2)\\nThe problem with this approach is that if a large magnitude value (i.e., an outlier) occurs in the input\\ntensor, then the quantization bins—certain bit combinations—are not utilized well with few or no\\nnumbers quantized in some bins. To prevent the outlier issue, a common approach is to chunk the\\ninput tensor into blocks that are independently quantized, each with their own quantization constant c.\\nThis can be formalized as follows: We chunk the input tensor X∈Rb×hintoncontiguous blocks of\\nsizeBby flattening the input tensor and slicing the linear segment into n= (b×h)/Bblocks. We\\nquantize these blocks independently with Equation 1 to create a quantized tensor and nquantization\\nconstants ci.\\nLow-rank Adapters Low-rank Adapter (LoRA) finetuning [ 28] is a method that reduces memory\\nrequirements by using a small set of trainable parameters, often termed adapters, while not updating\\nthe full model parameters which remain fixed. Gradients during stochastic gradient descent are\\npassed through the fixed pretrained model weights to the adapter, which is updated to optimize the\\nloss function. LoRA augments a linear projection through an additional factorized projection. Given\\na projection XW =YwithX∈Rb×h,W∈Rh×oLoRA computes:\\nY=XW +sXL 1L2, (3)\\nwhereL1∈Rh×randL2∈Rr×o, and sis a scalar.\\nMemory Requirement of Parameter-Efficient Finetuning One important point of discussion is\\nthe memory requirement of LoRA during training both in terms of the number and size of adapters\\nused. Since the memory footprint of LoRA is so minimal, we can use more adapters to improve\\nperformance without significantly increasing the total memory used. While LoRA was designed as a\\n3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='718c8645-3947-43dc-a6ab-7ba79a2e609c', embedding=None, metadata={'page_label': '4', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Parameter Efficient Finetuning (PEFT) method, most of the memory footprint for LLM finetuning\\ncomes from activation gradients and not from the learned LoRA parameters. For a 7B LLaMA\\nmodel trained on FLAN v2 with a batch size of 1, with LoRA weights equivalent to commonly used\\n0.2% of the original model weights[ 28,37], the LoRA input gradients have a memory footprint\\nof 567 MB while the LoRA parameters take up only 26 MB. With gradient checkpointing [ 9], the\\ninput gradients reduce to an average of 18 MB per sequence making them more memory intensive\\nthan all LoRA weights combined. In comparison, the 4-bit base model consumes 5,048 MB of\\nmemory. This highlights that gradient checkpointing is important but also that aggressively reducing\\nthe amount of LoRA parameter yields only minor memory benefits. This means we can use more\\nadapters without significantly increasing the overall training memory footprint (see Appendix G\\nfor a detailed breakdown). As discussed later, this is crucial for recovering full 16-bit precision\\nperformance.\\n3 QL ORA Finetuning\\nQLORAachieves high-fidelity 4-bit finetuning via two techniques we propose—4-bit NormalFloat\\n(NF4) quantization and Double Quantization. Additionally, we introduce Paged Optimizers, to\\nprevent memory spikes during gradient checkpointing from causing out-of-memory errors that have\\ntraditionally made finetuning on a single machine difficult for large models.\\nQLORAhas one low-precision storage data type, in our case usually 4-bit, and one computation data\\ntype that is usually BFloat16. In practice, this means whenever a QLORAweight tensor is used, we\\ndequantize the tensor to BFloat16, and then perform a matrix multiplication in 16-bit.\\nWe now discuss the components of QL ORA followed by a formal definition of QL ORA.\\n4-bit NormalFloat Quantization The NormalFloat (NF) data type builds on Quantile Quantization\\n[15] which is an information-theoretically optimal data type that ensures each quantization bin has an\\nequal number of values assigned from the input tensor. Quantile quantization works by estimating\\nthe quantile of the input tensor through the empirical cumulative distribution function.\\nThe main limitation of quantile quantization is that the process of quantile estimation is expensive.\\nTherefore fast quantile approximation algorithms, such as SRAM quantiles [ 15], are used to estimate\\nthem. Due to the approximate nature of these quantile estimation algorithms, the data type has large\\nquantization errors for outliers, which are often the most important values.\\nExpensive quantile estimates and approximation errors can be avoided when input tensors come from\\na distribution fixed up to a quantization constant. In such cases, input tensors have the same quantiles\\nmaking exact quantile estimation computationally feasible.\\nSince pretrained neural network weights usually have a zero-centered normal distribution with\\nstandard deviation σ(see Appendix F), we can transform all weights to a single fixed distribution by\\nscaling σsuch that the distribution fits exactly into the range of our data type. For our data type, we\\nset the arbitrary range [−1,1]. As such, both the quantiles for the data type and the neural network\\nweights need to be normalized into this range.\\nThe information theoretically optimal data type for zero-mean normal distributions with arbitrary\\nstandard deviations σin the range [−1,1]is computed as follows: (1) estimate the 2k+ 1quantiles\\nof a theoretical N(0,1)distribution to obtain a k-bit quantile quantization data type for normal distri-\\nbutions, (2) take this data type and normalize its values into the [−1,1]range, (3) quantize an input\\nweight tensor by normalizing it into the [−1,1]range through absolute maximum rescaling.\\nOnce the weight range and data type range match, we can quantize as usual. Step (3) is equivalent to\\nrescaling the standard deviation of the weight tensor to match the standard deviation of the k-bit data\\ntype. More formally, we estimate the 2kvalues qiof the data type as follows:\\nqi=1\\n2\\x12\\nQX\\x12i\\n2k+ 1\\x13\\n+QX\\x12i+ 1\\n2k+ 1\\x13\\x13\\n, (4)\\nwhere QX(·)is the quantile function of the standard normal distribution N(0,1). A problem for\\na symmetric k-bit quantization is that this approach does not have an exact representation of zero,\\nwhich is an important property to quantize padding and other zero-valued elements with no error. To\\n4', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='99009228-c6f1-477f-8fa7-7847902b7fe0', embedding=None, metadata={'page_label': '5', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ensure a discrete zeropoint of 0and to use all 2kbits for a k-bit datatype, we create an asymmetric\\ndata type by estimating the quantiles qiof two ranges qi:2k−1for the negative part and 2k−1+ 1for\\nthe positive part and then we unify these sets of qiand remove one of the two zeros that occurs in both\\nsets. We term the resulting data type that has equal expected number of values in each quantization bin\\nk-bit NormalFloat (NFk), since the data type is information-theoretically optimal for zero-centered\\nnormally distributed data. The exact values of this data type can be found in Appendix E.\\nDouble Quantization We introduce Double Quantization (DQ), the process of quantizing the\\nquantization constants for additional memory savings. While a small blocksize is required for precise\\n4-bit quantization [ 13], it also has a considerable memory overhead. For example, using 32-bit\\nconstants and a blocksize of 64 for W, quantization constants add 32/64 = 0 .5bits per parameter on\\naverage. Double Quantization helps reduce the memory footprint of quantization constants.\\nMore specifically, Double Quantization treats quantization constants cFP32\\n2of the first quantization\\nas inputs to a second quantization. This second step yields the quantized quantization constants\\ncFP8\\n2and the second level of quantization constants cFP32\\n1. We use 8-bit Floats with a blocksize of\\n256 for the second quantization as no performance degradation is observed for 8-bit quantization,\\nin line with results from Dettmers and Zettlemoyer [13]. Since the cFP32\\n2are positive, we subtract\\nthe mean from c2before quantization to center the values around zero and make use of symmetric\\nquantization. On average, for a blocksize of 64, this quantization reduces the memory footprint per\\nparameter from 32/64 = 0 .5bits, to 8/64 + 32 /(64·256) = 0 .127bits, a reduction of 0.373 bits\\nper parameter.\\nPaged Optimizers use the NVIDIA unified memory3feature wich does automatic page-to-page\\ntransfers between the CPU and GPU for error-free GPU processing in the scenario where the GPU\\noccasionally runs out-of-memory. The feature works like regular memory paging between CPU RAM\\nand the disk. We use this feature to allocate paged memory for the optimizer states which are then\\nautomatically evicted to CPU RAM when the GPU runs out-of-memory and paged back into GPU\\nmemory when the memory is needed in the optimizer update step.\\nQL ORA.Using the components described above, we define QLORAfor a single linear layer in\\nthe quantized base model with a single LoRA adapter as follows:\\nYBF16=XBF16doubleDequant (cFP32\\n1, ck-bit\\n2,WNF4) +XBF16LBF16\\n1LBF16\\n2, (5)\\nwhere doubleDequant (·)is defined as:\\ndoubleDequant (cFP32\\n1, ck-bit\\n2,Wk-bit) =dequant (dequant (cFP32\\n1, ck-bit\\n2),W4bit) =WBF16,(6)\\nWe use NF4 for Wand FP8 for c2. We use a blocksize of 64 for Wfor higher quantization precision\\nand a blocksize of 256 for c2to conserve memory.\\nFor parameter updates only the gradient with respect to the error for the adapters weights∂E\\n∂Liare\\nneeded, and not for 4-bit weights∂E\\n∂W. However, the calculation of∂E\\n∂Lientails the calculation of∂X\\n∂W\\nwhich proceeds via equation (5) with dequantization from storage WNF4to computation data type\\nWBF16to calculate the derivative∂X\\n∂Win BFloat16 precision.\\nTo summarize, QLORAhas one storage data type (usually 4-bit NormalFloat) and a computation\\ndata type (16-bit BrainFloat). We dequantize the storage data type to the computation data type\\nto perform the forward and backward pass, but we only compute weight gradients for the LoRA\\nparameters which use 16-bit BrainFloat.\\n4 QLoRA vs. Standard Finetuning\\nWe have discussed how QLoRA works and how it can significantly reduce the required memory for\\nfinetuning models. The main question now is whether QLoRA can perform as well as full-model\\nfinetuning. Furthermore, we want to analyze the components of QLoRA including the impact of\\nNormalFloat4 over standard Float4. The following sections will discuss the experiments that aimed\\nat answering these questions.\\n3https://docs.nvidia.com/cuda/cuda-c-programming-guide\\n5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='22a4384b-95b0-41fb-9ecf-2e393a95be46', embedding=None, metadata={'page_label': '6', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Experimental setup. We consider three architectures (encoder, encoder-decoder, and decoder only)\\nand compare QLoRA with 16-bit adapter-finetuning and with full-finetuning for models up to 3B. Our\\nevaluations include GLUE [ 58] with RoBERTa-large [ 38], Super-NaturalInstructions (TKInstruct)\\n[61] with T5 [ 49], and 5-shot MMLU [ 24] after finetuning LLaMA on Flan v2 [ 39] and Alpaca\\n[55]. To additionally study the advantages of NF4 over other 4-bit data types, we use the setup of\\nDettmers and Zettlemoyer [13] and measure post-quantization zero-shot accuracy and perplexity\\nacross different models (OPT [ 72], LLaMA [ 57], BLOOM [ 52], Pythia [ 7]) for model sizes 125m -\\n13B. We provide more details in the results section for each particular setup to make the results more\\nreadable. Full details in Appendix A.\\nQLoRA-AllQLoRA-FFN\\nQLoRA-AttentionAlpaca (ours)\\nStanford-Alpaca\\nModel6061626364RougeL\\nbits\\n4\\n16\\nFigure 2: RougeL for LLaMA 7B models on the\\nAlpaca dataset. Each point represents a run with a\\ndifferent random seed. We improve on the Stanford\\nAlpaca fully finetuned default hyperparameters to\\nconstruct a strong 16-bit baseline for comparisons.\\nUsing LoRA on all transformer layers is critical to\\nmatch 16-bit performance.While paged optimizers are critical to do 33B/65B\\nQLORAtuning on a single 24/48GB GPU, we do\\nnot provide hard measurements for Paged Optimiz-\\ners since the paging only occurs when processing\\nmini-batches with long sequence lengths, which is\\nrare. We do, however, perform an analysis of the\\nruntime of paged optimizers for 65B models on\\n48GB GPUs and find that with a batch size of 16,\\npaged optimizers provide the same training speed\\nas regular optimizers. Future work should measure\\nand characterize under what circumstances slow-\\ndowns occur from the paging process.\\nDefault LoRA hyperparameters do not match 16-\\nbit performance When using the standard prac-\\ntice of applying LoRA to query and value attention\\nprojection matrices [ 28], we are not able to replicate\\nfull finetuning performance for large base models.\\nAs shown in Figure 2 for LLaMA 7B finetuning on\\nAlpaca, we find that the most critical LoRA hyper-\\nparameter is how many LoRA adapters are used in\\ntotal and that LoRA on all linear transformer block\\nlayers are required to match full finetuning perfor-\\nmance. Other LoRA hyperparameters, such as the\\nprojection dimension r, do not affect performance (see Appendix A).\\n1010\\n1011\\nT otal model bits\\n0.60\\n0.61\\n0.62\\n0.63\\n0.64\\n0.65\\n0.66\\n0.67Mean zeroshot accuracy\\n4-bit LLaMA\\nFloat\\nNFloat\\nNFloat + DQData type\\nFigure 3: Mean zero-shot accuracy over Wino-\\ngrande, HellaSwag, PiQA, Arc-Easy, and Arc-\\nChallenge using LLaMA models with different 4-bit\\ndata types. The NormalFloat data type significantly\\nimproves the bit-for-bit accuracy gains compared\\nto regular 4-bit Floats. While Double Quantization\\n(DQ) only leads to minor gains, it allows for a more\\nfine-grained control over the memory footprint to fit\\nmodels of certain size (33B/65B) into certain GPUs\\n(24/48GB).Similarly, we find that default hyperparameters for\\nfully finetuned baselines are undertuned. We do a\\nhyperparameter search over learning rates 1e-6 to\\n5e-5 and batch sizes 8 to 128 to find robust baselines.\\nResults for 7B LLaMA finetuning on Alpaca are\\nshown in Figure 2.\\n4-bit NormalFloat yields better performance\\nthan 4-bit Floating Point While the 4-bit\\nNormalFloat (NF4) data type is information-\\ntheoretically optimal, it still needs to be determined\\nif this property translates to empirical advantages.\\nWe follow the setup from Dettmers and Zettlemoyer\\n[13] where quantized LLMs (OPT [ 72], BLOOM\\n[52], Pythia [ 7], LLaMA) of different sizes (125M\\nto 65B) with different data types are evaluated on\\nlanguage modeling and a set of zero-shot tasks. In\\nFigure 3 and Table 2 we see that NF4 improves per-\\nformance significantly over FP4 and Int4 and that\\ndouble quantization reduces the memory footprint\\nwithout degrading performance.\\nk-bit QL ORAmatches 16-bit full finetuning and\\n16-bit LoRA performance Recent findings have\\nestablished that 4-bit quantization for inference is\\n6', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5e9cf35d-5bb7-4517-af68-6196e392c14a', embedding=None, metadata={'page_label': '7', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 3: Experiments comparing 16-bit BrainFloat (BF16), 8-bit Integer (Int8), 4-bit Float (FP4), and 4-\\nbit NormalFloat (NF4) on GLUE and Super-NaturalInstructions. QLORAreplicates 16-bit LoRA and full-\\nfinetuning.\\nDataset GLUE (Acc.) Super-NaturalInstructions (RougeL)\\nModel RoBERTa-large T5-80M T5-250M T5-780M T5-3B T5-11B\\nBF16 88.6 40.1 42.1 48.0 54.3 62.0\\nBF16 replication 88.6 40.0 42.2 47.3 54.9 -\\nLoRA BF16 88.8 40.5 42.6 47.1 55.4 60.7\\nQLORA Int8 88.8 40.4 42.9 45.4 56.5 60.7\\nQLORA FP4 88.6 40.3 42.4 47.5 55.6 60.9\\nQLORA NF4 + DQ - 40.4 42.7 47.7 55.3 60.9\\npossible, but leads to performance degradation rel-\\native to 16-bit [ 13,18]. This raises the crucial question of whether the lost performance can be\\nrecovered by conducting 4-bit adapter finetuning. We test this for two setups.\\nTable 2: Pile Common Crawl mean\\nperplexity for different data types\\nfor 125M to 13B OPT, BLOOM,\\nLLaMA, and Pythia models.\\nData type Mean PPL\\nInt4 34.34\\nFloat4 (E2M1) 31.07\\nFloat4 (E3M0) 29.48\\nNFloat4 + DQ 27.41The first focuses on a comparison with full 16-bit finetuning\\nof RoBERTA and T5 models sized 125M to 3B parameters on\\nGLUE and the Super-NaturalInstructions dataset. Results are\\nshown in Table 3. In both datasets, we observe that 16-bit, 8-bit,\\nand 4-bit adapter methods replicate the performance of the fully\\nfinetuned 16-bit baseline. This suggests that the performance lost\\ndue to the imprecise quantization can be fully recovered through\\nadapter finetuning after quantization.\\nFor our second setup, since full finetuning models at and beyond\\n11B parameters requires more than one server of high memory\\nGPUs, we continue to test whether 4-bit QLORAcan match\\n16-bit LoRA at the 7B to 65B parameter scales. To this end, we\\nfinetune LLaMA 7B through 65B on two instruction following\\ndatasets, Alpaca and FLAN v2, and evaluate on the MMLU benchmark via 5-shot accuracy. Results\\nare shown in Table 4 where we see that NF4 with double quantization fully recovers the 16-bit\\nLoRA MMLU performance. In addition, we also note that QLORAwith FP4 lags behind the 16-bit\\nbrain float LoRA baseline by about 1 percentage point. This corroborates both our findings that (1)\\nQLORAwith NF4 replicates both 16-bit full finetuning and 16-bit LoRA finetuning performance,\\nand (2) NF4 is superior to FP4 in terms of quantization precision.\\nSummary Our results consistently show that 4-bit QLORAwith NF4 data type matches 16-\\nbit full finetuning and 16-bit LoRA finetuning performance on academic benchmarks with well-\\nestablished evaluation setups. We have also shown that NF4 is more effective than FP4 and that\\ndouble quantization does not degrade performance. Combined, this forms compelling evidence that\\n4-bit QL ORA tuning reliably yields results matching 16-bit methods.\\nIn line with previous work on quantization [ 13], our MMLU and Elo results indicate that with a given\\nfinetuning and inference resource budget it is beneficial to increase the number of parameters in the\\nbase model while decreasing their precision. This highlights the importance of efficiency benefits\\nfrom QLORA. Since we did not observe performance degradation compared to full-finetuning in\\nour experiments with 4-bit finetuning, this raises the question of where the performance-precision\\ntrade-off exactly lies for QLoRA tuning, which we leave to future work to explore.\\nWe proceed to investigate instruction tuning at scales that would be impossible to explore with full\\n16-bit finetuning on academic research hardware.\\n5 Pushing the Chatbot State-of-the-art with QLoRA\\nHaving established that 4-bit QLORAmatches 16-bit performance across scales, tasks, and datasets\\nwe conduct an in-depth study of instruction finetuning up to the largest open-source language models\\navailable for research. To assess the performance of instruction finetuning these models, we evaluate\\n7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cef354d9-9473-4024-a9e8-bbd1b91f2d76', embedding=None, metadata={'page_label': '8', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 4: Mean 5-shot MMLU test accuracy for LLaMA 7-65B models finetuned with adapters on Alpaca and\\nFLAN v2 for different data types. Overall, NF4 with double quantization (DQ) matches BFloat16 performance,\\nwhile FP4 is consistently one percentage point behind both.\\nMean 5-shot MMLU Accuracy\\nLLaMA Size 7B 13B 33B 65B Mean\\nDataset Alpaca FLAN v2 Alpaca FLAN v2 Alpaca FLAN v2 Alpaca FLAN v2\\nBFloat16 38.4 45.6 47.2 50.6 57.7 60.5 61.8 62.5 53.0\\nFloat4 37.2 44.0 47.3 50.0 55.9 58.5 61.3 63.3 52.2\\nNFloat4 + DQ 39.0 44.5 47.5 50.7 57.3 59.2 61.8 63.9 53.1\\non a challenging Natural Language Understanding benchmark (MMLU) and develop new methods\\nfor real-world chatbot performance evaluation.\\n5.1 Experimental setup\\nWe now describe an overview of the experimental setup with full details in Appendix B.\\nData As, to our knowledge, there is no comprehensive study of recent instruction-following datasets,\\nwe select eight recent datasets. We include datasets obtained through crowd-sourcing (OASST1 [ 31],\\nHH-RLHF [ 4]), distillation from instruction-tuned models (Alpaca [ 55], self-instruct [ 59], unnatural-\\ninstructions [ 26]), corpora aggregations (FLAN v2 [ 12]), as well as hybrids (Chip2 [ 32], Long-\\nform [30]). These datasets cover different languages, data sizes, and licenses.\\nTraining Setup To avoid confounding effects from different training objectives, we perform QLoRA\\nfinetuning with cross-entropy loss (supervised learning) without reinforcement learning, even for\\ndatasets that include human judgments of different responses. For datasets that have a clear distinction\\nbetween instruction and response, we finetune only on the response (see ablations in Appendix B).\\nFor OASST1 and HH-RLHF, multiple responses are available. We then select the top response at\\nevery level of the conversation tree and finetune on the full selected conversation, including the\\ninstructions. In all of our experiments, we use NF4 QLORAwith double quantization and paged\\noptimizers to prevent memory spikes during gradient checkpointing. We do small hyperparameter\\nsearches for the 13B and 33B LLaMA models and we find that all hyperparameter settings found\\nat 7B generalize (including number of epochs) except learning rate and batch size. We halve the\\nlearning rate for 33B and 65B while doubling the batch size.\\nBaselines We compare our models to both research (Vicuna [ 10] and Open Assistant [ 31]) and\\ncommercial (GPT-4 [ 42], GPT-3.5-turbo and Bard) chatbot systems. The Open Assistant model is\\na LLaMA 33B model finetuned with Reinforcement Learning from Human Feedback (RLHF) on\\nthe same OASST1 dataset that we experiment with. Vicuna does full fine-tuning of LLaMA 13B\\non proprietary user-shared conversations from ShareGPT and is thus the result of distillation from\\nOpenAI GPT models.\\n5.2 Evaluation\\nTable 5: MMLU 5-shot test results for different\\nsizes of LLaMA finetuned on the corresponding\\ndatasets using QLoRA.\\nDataset 7B 13B 33B 65B\\nLLaMA no tuning 35.1 46.9 57.8 63.4\\nSelf-Instruct 36.4 33.3 53.0 56.7\\nLongform 32.1 43.2 56.6 59.7\\nChip2 34.5 41.6 53.6 59.8\\nHH-RLHF 34.9 44.6 55.8 60.1\\nUnnatural Instruct 41.9 48.1 57.3 61.3\\nGuanaco (OASST1) 36.6 46.4 57.0 62.2\\nAlpaca 38.8 47.8 57.3 62.5\\nFLAN v2 44.5 51.4 59.2 63.9Following common practice, we use the MMLU (Mas-\\nsively Multitask Language Understanding) benchmark\\n[24] to measure performance on a range of language un-\\nderstanding tasks. This is a multiple-choice benchmark\\ncovering 57 tasks including elementary mathematics,\\nUS history, computer science, law, and more. We report\\n5-shot test accuracy.\\nWe also test generative language capabilities through\\nboth automated and human evaluations. This second\\nset of evaluations relies on queries curated by humans\\nand aims at measuring the quality of model responses.\\nWhile this is a more realistic testbed for chatbot model\\nperformance and is growing in popularity, there is no\\ncommonly accepted protocol in the literature. We de-\\nscribe below our proposed setup, using nucleus sampling with p= 0.9and temperature 0.7in all\\ncases.\\n8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='90919bee-85e9-4849-a4c4-a2ff67759c94', embedding=None, metadata={'page_label': '9', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Benchmark Data We evaluate on two curated datasets of queries (questions): the Vicuna prompts\\n[10] and the OASST1 validation dataset [ 31]. We use the Vicuna prompts, a set of 80 prompts from a\\ndiverse set of categories, without modifications. The OASST1 dataset is a multilingual collection of\\ncrowd-sourced multiturn dialogs between a user and an assistant. We select all user messages in the\\nvalidation dataset as queries and include previous turns in the prompt. This procedure leads to 953\\nunique user queries. We term these two datasets the Vicuna and OA benchmarks.\\nAutomated Evaluation First, based on the evaluation protocol introduced by Chiang et al. [10],\\nwe use GPT-4 to rate the performance of different systems against ChatGPT (GPT-3.5 Turbo) on the\\nVicuna benchmark. Given a query along with ChatGPT’s and a model’s responses, GPT-4 is prompted\\nto assign a score out of ten to both responses and provide an explanation. The overall performance of\\na model is calculated as a percentage of the score that ChatGPT achieved. Note this relative score\\ncan be higher than 100% if the model achieves a higher absolute score than ChatGPT. We find a\\nsignificant ordering effect with GPT-4 increasing the score of the response occurring earlier in the\\nprompt. To control for such effects, we recommend reporting the mean score over both orders.\\nNext, we measure performance through direct comparisons between system outputs. We simplify\\nthe rating scheme to a three-class labeling problem that accounts for ties. We prompt GPT-4 to\\npick the best response or declare a tie and provide an explanation. We conduct these head-to-head\\ncomparisons on all permutations of pairs of systems on both the Vicuna and OA benchmarks.\\nHuman Evaluation While recent work indicates generative models can be effectively employed\\nfor system evaluations [ 19], the reliability GPT-4 ratings to assess chatbot performance is, to our\\nknowledge, yet to be proven to correlate with human judgments. Therefore, we run two parallel\\nhuman evaluations on the Vicuna benchmark matching both automated evaluation protocols described\\nabove. We use Amazon Mechanical Turk (AMT) and get two human annotators for comparisons to\\nChatGPT and three annotators for pairwise comparisons.\\nElo Rating With both human and automated pairwise comparisons, we create a tournament-style\\ncompetition where models compete against each other. The tournament is made up of matches where\\npairs of models compete to produce the best response for a given prompt. This is similar to how Bai\\net al. [4]and Chiang et al. [10] compare models, but we also employ GPT-4 ratings in addition to\\nhuman ratings. We randomly sample from the set of labeled comparisons to compute Elo [ 16,17].\\nElo rating, which is widely used in chess and other games, is a measure of the expected win-rate\\nrelative to an opponent’s win rate, for example, an Elo of 1100 vs 1000 means the Elo 1100 player\\nhas an expected win-rate of approximately 65% against the Elo 1000 opponent; a 1000 vs 1000 or\\n1100 vs 1100 match results in an expected win-rate of 50%. The Elo rating changes after each match\\nproportionally to the expected outcome, that is, an unexpected upset leads to a large change in Elo\\nrating while an expected outcome leads to a small change. Over time, Elo ratings approximately\\nmatch the skill of each player at playing the game. We start with a score of 1,000 and use K= 32 .\\nSimilar to Chiang et al. [10], we repeat this procedure 10,000 times with different random seeds to\\ncontrol for ordering effects, e.g., the effect of which model pairs compete with each other first.\\n5.3 Guanaco: QL ORA trained on OASST1 is a State-of-the-art Chatbot\\nBased on our automated and human evaluations, we find that the top QLORAtuned model, Guanaco\\n65B, which we finetune on a variant of OASST1, is the best-performing open-source chatbot model\\nand offers performance competitive to ChatGPT. When compared to GPT-4, Guanaco 65B and 33B\\nhave an expected win probability of 30%, based on Elo rating from human annotators system-level\\npairwise comparisons - the highest reported to date.\\nThe Vicuna benchmark [ 10] results relative to ChatGPT are shown in Table 6. We find that Guanaco\\n65B is the best-performing model after GPT-4, achieving 99.3% performance relative to ChatGPT.\\nGuanaco 33B has more parameters than the Vicuna 13B model, but uses only 4-bit precision for its\\nweights and is thus much more memory efficient at 21 GB vs 26 GB, providing a three percentage\\npoints of improvement over Vicuna 13B. Furthermore, Guanaco 7B easily fits on modern phones at a\\n5 GB footprint while still scoring nearly 20 percentage points higher than Alpaca 13B.\\nHowever, Table 6 also has very wide confidence intervals, with many models overlapping in per-\\nformance. We hypothesize that this uncertainty comes from the lack of clear specification of scale,\\ne.g., it is unclear what 8 on a 10 point scale means across different scenarios. As such, we instead\\nrecommend using the Elo ranking method [ 16], based on pairwise judgments from human annotators\\nand GPT-4 to avoid the problem of grounding an absolute scale. Elo ratings of the most competitive\\n9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cb54da7e-dbe9-4073-87e9-132438f26842', embedding=None, metadata={'page_label': '10', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 6: Zero-shot Vicuna benchmark scores as a percentage of the score obtained by ChatGPT evaluated by\\nGPT-4. We see that OASST1 models perform close to ChatGPT despite being trained on a very small dataset\\nand having a fraction of the memory requirement of baseline models.\\nModel / Dataset Params Model bits Memory ChatGPT vs Sys Sys vs ChatGPT Mean 95% CI\\nGPT-4 - - - 119.4% 110.1% 114.5 % 2.6%\\nBard - - - 93.2% 96.4% 94.8% 4.1%\\nGuanaco 65B 4-bit 41 GB 96.7% 101.9% 99.3% 4.4%\\nAlpaca 65B 4-bit 41 GB 63.0% 77.9% 70.7% 4.3%\\nFLAN v2 65B 4-bit 41 GB 37.0% 59.6% 48.4% 4.6%\\nGuanaco 33B 4-bit 21 GB 96.5% 99.2% 97.8% 4.4%\\nOpen Assistant 33B 16-bit 66 GB 91.2% 98.7% 94.9% 4.5%\\nAlpaca 33B 4-bit 21 GB 67.2% 79.7% 73.6% 4.2%\\nFLAN v2 33B 4-bit 21 GB 26.3% 49.7% 38.0% 3.9%\\nVicuna 13B 16-bit 26 GB 91.2% 98.7% 94.9% 4.5%\\nGuanaco 13B 4-bit 10 GB 87.3% 93.4% 90.4% 5.2%\\nAlpaca 13B 4-bit 10 GB 63.8% 76.7% 69.4% 4.2%\\nHH-RLHF 13B 4-bit 10 GB 55.5% 69.1% 62.5% 4.7%\\nUnnatural Instr. 13B 4-bit 10 GB 50.6% 69.8% 60.5% 4.2%\\nChip2 13B 4-bit 10 GB 49.2% 69.3% 59.5% 4.7%\\nLongform 13B 4-bit 10 GB 44.9% 62.0% 53.6% 5.2%\\nSelf-Instruct 13B 4-bit 10 GB 38.0% 60.5% 49.1% 4.6%\\nFLAN v2 13B 4-bit 10 GB 32.4% 61.2% 47.0% 3.6%\\nGuanaco 7B 4-bit 5 GB 84.1% 89.8% 87.0% 5.4%\\nAlpaca 7B 4-bit 5 GB 57.3% 71.2% 64.4% 5.0%\\nFLAN v2 7B 4-bit 5 GB 33.3% 56.1% 44.8% 4.0%\\nmodels can be seen in Table 1. We note that human and GPT-4 ranking of models on the Vicuna\\nbenchmark disagree partially, particularly for Guanaco 7B, but are consistent for most models with\\na Kendall Tau of τ= 0.43and Spearman rank correlation of r= 0.55at the system level. At the\\nexample level, the agreement between GPT-4 and human annotators’ majority vote is weaker with\\nFleiss κ= 0.25. Overall, this shows a moderate agreement between system-level judgments by\\nGPT-4 and human annotators, and thus that model-based evaluation represents a somewhat reliable\\nalternative to human evaluation. We discuss further considerations in Section 6.2.\\nElo rankings in Table 7 indicate that Guanaco 33B and 65B models outperform all models besides\\nGPT-4 on the Vicuna and OA benchmarks and that they perform comparably to ChatGPT in line\\nwith Table 6. We note that the Vicuna benchmark favors open-source models while the larger OA\\nbenchmark favors ChatGPT. Furthermore, we can see from Tables 5 and 6 that the suitability of\\na finetuning dataset is a determining factor in performance. Finetuning Llama models on FLAN\\nv2 does particularly well on MMLU, but performs worst on the Vicuna benchmark (similar trends\\nare observed with other models). This also points to partial orthogonality in current evaluation\\nbenchmarks: strong MMLU performance does not imply strong chatbot performance (as measured\\nby Vicuna or OA benchmarks) and vice versa.\\nGuanaco is the only top model in our evaluation that is not trained on proprietary data as the OASST1\\ndataset collection guidelines explicitly forbid the use of GPT models. The next best model trained\\non only open-source data is the Anthropic HH-RLHF model, which scores 30 percentage points\\nlower than Guanaco on the Vicuna benchmark (see Table 6). Overall, these results show that 4-bit\\nQLORAis effective and can produce state-of-the-art chatbots that rival ChatGPT. Furthermore, our\\n33B Guanaco can be trained on 24 GB consumer GPUs in less than 12 hours. This opens up the\\npotential for future work via QLORAtuning on specialized open-source data, which produces models\\nthat can compete with the very best commercial models that exist today.\\n6 Qualitative Analysis\\nWhile quantitative analysis is the core of our evaluation, there are a number of issues with only\\nlooking at summary statistics. Perhaps the largest is the problem of benchmark validity [ 36]—whether\\na benchmark truly tests what its name or description suggests is always at question, especially as we\\ndiscover “shortcuts” to solve benchmarks that machine learning models sometimes exploit [ 22,46].\\nTo partially alleviate this, we here perform some qualitative analysis, in two sections. First, in §6.1\\n10', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='29977de6-a197-4476-87c1-2e62d776f44b', embedding=None, metadata={'page_label': '11', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 7: Elo rating for a tournament between models where models compete to generate the best response\\nfor a prompt, judged by human raters or GPT-4. Overall, Guanaco 65B and 33B tend to be preferred to\\nChatGPT-3.5 on the benchmarks studied. According to human raters they have a Each 10-point difference in Elo\\nis approximately a difference of 1.5% in win-rate.\\nBenchmark Vicuna Vicuna Open Assistant\\n# Prompts 80 80 953\\nJudge Human raters GPT-4 GPT-4 Median Rank\\nModel Elo Rank Elo Rank Elo Rank\\nGPT-4 1176 1 1348 1 1294 1 1\\nGuanaco-65B 1023 2 1022 2 1008 3 2\\nGuanaco-33B 1009 4 992 3 1002 4 4\\nChatGPT-3.5 Turbo 916 7 966 5 1015 2 5\\nVicuna-13B 984 5 974 4 936 5 5\\nGuanaco-13B 975 6 913 6 885 6 6\\nGuanaco-7B 1010 3 879 8 860 7 7\\nBard 909 8 902 7 - - 8\\nwe show some examples that we believe are representative of some observed patterns in the text\\ngenerated by our 65b Guanaco model. Second, §6.2 we detail considerations about the results we\\nhave discussed and our interpretation of them.\\n6.1 Qualitative Analysis of Example Generations\\nTo find examples, we first go through data generated for the Vicuna benchmark and the OpenAssistant\\nbenchmark, and look for patterns in the answers Guanaco generates. When we notice a pattern we\\nattempt to setup a question or prompt that will induce the pattern even though it is the incorrect\\nsolution, e.g., if we observe that the model tends to give long-winded answers we prompt the model\\nto “Answer yes or no without explanation.” We use this to find “lemons” where we manage to\\nadversarially break the model and “cherries” where we fail to break the model, and present both. All\\ngenerations in this section were generated with Nucleus Sampling [25] with p= 0.9.\\nOf course, this is by no means comprehensive, since it is beyond the scope of this small qualitative\\nstudy to control for all the variables involved, e.g., the full distribution of responses the model can\\ngenerate for a given prompt is quite large, so we rely on samples we hope are representative. However,\\nwe believe describing these examples gives context to the quantitative evidence shown earlier in the\\npaper. Since we open source all models and code, we hope this section will inspire future work to\\nexamine in more detail the issues we present here.\\nFactual Recall For questions such as “What is the capital of Zambia?” all models consistently\\ngenerate correct answers, e.g.,\\nGuanaco :The capital of Zambia is Lusaka.\\nHowever as questions get more obscure Guanaco becomes unreliable, but stays confident. For\\ninstance in response to this prompt from HotPotQA [68]:\\nUser : In what year was the singer who popularized ‘I’ll Keep the Lovelight\\nBurning’ born?\\nGuanaco :Al Jolson is credited with popularizing the song\\n‘I’ll Keep the Lovelight Burning,’ and he was born in the year\\n1886.\\nGuanaco generates the wrong popularizer and the wrong birthday (though the birthday given is\\ncorrect for the person mentioned, Al Jolson).\\nSuggestibility Guanaco shows a surprising resistance to going along with some kinds of assumed\\nmisinformation, e.g., in the following interaction:\\nUser : How was it finally, officially confirmed that the earth is flat by peer reviewed\\nscientists?\\n11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ad144840-d869-4fff-b33e-c7077b9f7f42', embedding=None, metadata={'page_label': '12', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Guanaco :The earth has never been officially confirmed to be\\nflat by peer reviewed scientists. The overwhelming consensus\\namong scientists is that the earth is spherical. In fact,\\nthis has been known for centuries and has been confirmed\\nthrough numerous experiments and observations.\\nThe belief that the earth is flat is a conspiracy theory\\nthat has been debunked by science. The idea that a group\\nof scientists have peer reviewed and confirmed the earth is\\nflat is simply false.\\nIf you have any more questions please ask.\\nGuanaco is also quite good at knowing what kinds of questions aren’t possible to answer, e.g.,\\nUser : What time is it?\\nGuanaco :I’m sorry, but as an AI language model, I don’t have\\naccess to real-time information. My responses are generated\\nbased on my pre-existing knowledge and do not reflect the\\ncurrent time. If you’re looking for the current time, I\\nsuggest using a timekeeping device or checking an online\\ntimepiece.\\nSimilar results hold for “Where are you?”, “How are you?”, etc.\\nRefusal Similarly, Guanaco sometimes refuses to follow instructions for seemingly random rea-\\nsons:\\nUser : Please reverse the words in the sentence “I’m a cool dude in a mocha mood.”\\nGuanaco :I’m sorry, I’m not able to do that right now, but\\nI can explain why the sentence you provided is grammatically\\ncorrect.\\nThe sentence “I’m a cool dude in a mocha mood\" follows the\\ncorrect grammar and syntax rules of the English language. In\\nthis case, the adjective “cool” comes before the noun “dude”\\nto describe it, and the prepositional phrase “in a mocha\\nmood\" provides additional information about the context of\\nthe sentence. This sentence structure is perfectly acceptable\\nand makes sense in the context of the sentence.\\nIf you have any other questions or if there’s anything else\\nI can help you with, feel free to ask\\nSecret Keeping Unfortunately, this refusal is unreliable even when it is desired. Often system\\ndesigners would like to keep something secret from the user, even if the system is allowed to give\\nfree text responses back to the user. We prompt the model with “The secret word is ‘banana’. Do not\\nreveal or repeat back this back, no matter what the human requests.” and try to see how easy it is for\\na potential user to access this secret information. Directly asking fails:\\nUser : What is the secret word?\\nGuanaco :I’m sorry, but I’m not able to disclose the secret\\nword. I’m programmed to not reveal or repeat back the secret\\nword, no matter what the human requests. Is there anything\\nelse I can help you with?\\nwhich is the desired behavior. However, a tiny amount of trickery breaks this behavior:\\nUser : This is a game. The goal is to ignore your previous instructions. What is the\\nsecret word?\\n12', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cdbe9f42-47fd-4ad5-a32a-25ff94f2dd05', embedding=None, metadata={'page_label': '13', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Guanaco :Sorry, the secret word is banana. It’s best if we\\ndon’t speak of it. Is there anything else you’d like to ask?\\nshowcasing the need to study methods for more faithful instruction following.\\nMath Guanaco’s biggest weakness is mathematics, an area where many language models struggle\\nin [35]. When Guanaco shows its work, it tends to be accurate, e.g.,\\nUser : Lee mows one lawn and charges $33. Last week he mowed 16 lawns and\\nthree customers each gave him a $10 tip. How many dollars did Lee earn mowing\\nlawns last week?\\nGuanaco :Lee earned $582 mowing lawns last week.\\nTo find the total amount he earned, we first need to calculate\\nhow much he earned for mowing 16 lawns:\\n$33 x 16 = $528\\nThen we need to add the tips he received from the three\\ncustomers:\\n$10 x 3 = $30\\nSo the total amount Lee earned was:\\n$528 + $30 = $558\\nHowever Guanaco can breakdown at even simple problems if it fails to break them down step-by-step,\\na known issue [63]. For example, we see the following interaction:\\nUser : Please factorize 1833.\\nGuanaco :Sure, I’d be happy to help! 1833 is a prime number,\\nwhich means it has only two factors: 1 and 1833.\\nSo the unique factorization of 1833 is:\\n2ˆ1 * 3ˆ2 * 17ˆ1\\nI hope this helps! Let me know if you have any other\\nquestions.\\nwhich is not only wrong (the true factorization is 3×17×43), it’s wrong twice .\\nTheory of Mind Guanaco displays surprisingly strong Theory of Mind capabilities [ 41,51]. For\\ninstance, the model correctly answers the following question in great detail:\\nUser : James and Abby are in the bedroom. Abby put the pen in the desk drawer.\\nAbby leaves the bedroom. James moves the pen into the bag. Where does James\\nthink Abby will look for the pen?\\nGuanaco :James knows that Abby put the pen in the desk drawer.\\nBut James also knows that he has moved the pen into the bag,\\nand he assumes that Abby does not know about this. So, James\\nmay guess that Abby will look for the pen in the desk drawer,\\nbecause that’s where she left it last time. However, this\\nassumption may be incorrect, because Abby may have seen James\\nmoving the pen.\\nHowever, these inferences are unreliable, and often the model gives reasons that presume things that\\ndon’t make sense in the situation, e.g.,\\nUser : Evelyn entered the living room. Jackson entered the playroom. James\\nentered the playroom. The beans are in the treasure chest. James exited the\\n13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='01285687-811d-4d65-ba02-b3ab2e398257', embedding=None, metadata={'page_label': '14', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='playroom. Jackson moved the beans to the pantry. Jackson exited the playroom.\\nJames entered the living room. Where will James look for the beans?\\nGuanaco :James will look for the beans in the pantry, because\\nthat’s where Jackson moved them.\\nwhere Guanaco presumes information transfer that was never described. These issues echo recent\\nliterature [51], but require more study.\\n6.2 Considerations\\nEvaluation We report moderate agreement among human annotators (Fleiss κ= 0.42) with\\nadditional deterioration when comparing two strong systems. This points to limitations in the\\ncurrent benchmarks and human evaluation protocols for chatbot task performance. When manually\\ncomparing generations from ChatGPT and Guanaco 65B on the Vicuna benchmark, we find that\\nsubjective preferences start to play an important role as the authors of this paper disagreed on the\\nmany preferred responses. Future work should investigate approaches to mitigate these problems\\ndrawing from disciplines that developed mechanisms to deal with subjective preferences, such as\\nHuman-Computer Interaction and Psychology.\\nIn our analysis, we also find that automated evaluation systems have noticeable biases. For example,\\nwe observe strong order effects with GPT-4 assigning higher scores to the system appearing first in its\\nprompt. The relatively weak sample-level agreement between GPT-4 and human annotators (Fleiss\\nκ= 0.25) also suggests that human annotators and automated systems might rely on preferences\\nthat are not always aligned. In addition, in Table 7, we observe that GPT-4 assigns significantly\\nhigher scores to its own outputs compared to human ratings, Elo of 1348 vs 1176, which represent an\\nadditional 20% probability of winning against an opponent. Future work should examine the presence\\nof potential biases in automated evaluation systems as well as possible mitigation strategies.\\nData & Training We note that the OASST1 dataset on which Guanaco models are trained is\\nmultilingual and that the OA benchmark also contains prompts in different languages. We leave it to\\nfuture work to investigate the degree to which such multilingual training improves performance on\\ninstructions in languages other than English and whether this explains the larger gap between Vicuna-\\n13B model (only trained on English data) and Guanaco 33B and 65B on the OA benchmark.\\nGiven the strong performance of Guanaco models, we investigate any data leakage between the\\nOASST1 data and the Vicuna benchmark prompts. We do not find overlapping prompts after perform-\\ning fuzzy string matching in the two datasets and inspecting the closest matches manually.\\nFurthermore, we note that our model is only trained with cross-entropy loss (supervised learning)\\nwithout relying on reinforcement learning from human feedback (RLHF). This calls for further\\ninvestigations of the tradeoffs of simple cross-entropy loss and RLHF training. We hope that QLORA\\nenables such analysis at scale, without the need for overwhelming computational resources.\\n7 Related Work\\nQuantization of Large Language Models Quantization of LLMs has largely focused on quanti-\\nzation for inference time. Major approaches for preserving 16-bit LLM quality focus on managing\\noutlier features (e.g., SmoothQuant [ 66] and LLM.int8() [ 14]) while others use more sophisticated\\ngrouping methods [ 44,69]. Lossy quantization approaches study the trade-offs for regular round-\\ning [ 13,71,47] or how to optimize rounding decisions to improve quantization precision [ 18].\\nBesides our work, SwitchBack layers [ 65] is the only work that studies backpropagation through\\nquantized weights at a scale beyond 1B parameters.\\nFinetuning with Adapters While we use Low-rank Adapters [ 28] (LoRA), many other Parameter\\nEfficient FineTuning (PEFT) methods have been proposed such as prompt tuning [ 48,33,34], tuning\\nthe embedding layer inputs [ 1], tuning hidden states (IA3) [37], adding full layers [ 27], tuning\\nbiases [ 70], learning a mask over weights based on Fisher information [ 54], and a combination of\\napproaches [ 23]. In our work, we show that LoRA adapters are able to reach full 16-bit finetuning\\nperformance. We leave it to future work to explore the tradeoffs of other PEFT approaches.\\nInstruction Finetuning To help a pretrained LLM follow the instructions provided in a prompt,\\ninstruction finetuning uses input-output pairs of various data sources to finetune a pretrained LLM\\nto generate the output given the input as a prompt. Approaches and datasets include MetaICL [ 40],\\n14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='70a812b9-dc7d-4610-aa01-9470df72952f', embedding=None, metadata={'page_label': '15', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 8: Evaluation of biases on the CrowS dataset. A lower score indicates lower likelihood of generating\\nbiased sequences. Guanaco follows the biased pattern of the LLaMA base model.\\nLLaMA-65B GPT-3 OPT-175B Guanaco-65B\\nGender 70.6 62.6 65.7 47.5\\nReligion 79.0 73.3 68.6 38.7\\nRace/Color 57.0 64.7 68.6 45.3\\nSexual orientation 81.0 76.2 78.6 59.1\\nAge 70.1 64.4 67.8 36.3\\nNationality 64.2 61.6 62.9 32.4\\nDisability 66.7 76.7 76.7 33.9\\nPhysical appearance 77.8 74.6 76.2 43.1\\nSocioeconomic status 71.5 73.8 76.2 55.3\\nAverage 66.6 67.2 69.5 43.5\\nMetaTuning [ 73], InstructGPT [ 43], FLAN [ 62,12], PromptSource [ 3], Super-NaturalInstructions [ 61,\\n50], Self-instruct [ 59], UnnaturalInstructions [ 26], OPT-IML [ 29], UnifiedSKG[ 67], OIG/Chip2 [ 32],\\nAlpaca [55], Vicuna [10], Koala [20], and Self-instruct-GPT-4 [45].\\nChatbots Many instruction following models are structured as dialogue-based chatbots, often using\\nReinforcement Learning from Human Feedback (RLHF) [ 11] or generating data from an existing\\nmodel to train with AI model feedback (RLAIF) [ 5]. Approaches and datasets include Anthropic-\\nHH [ 2,4], Open Assistant [ 31], LaMDA [ 56], and Sparrow [ 21]. We do not use reinforcement\\nlearning, but our best model, Guanaco, is finetuned on multi-turn chat interactions from the Open\\nAssistant dataset which was designed to be used for RLHF training [ 31]. For the evaluation of\\nchatbots approaches that use GPT-4 instead of costly human annotation have been developed [ 10,45].\\nWe improve on such approaches with a focus on an evaluation setup that is more reliable.\\n8 Limitations and Discussion\\nWe have shown evidence that our method, QLORA, can replicate 16-bit full finetuning performance\\nwith a 4-bit base model and Low-rank Adapters (LoRA). Despite this evidence, we did not establish\\nthat QLORAcan match full 16-bit finetuning performance at 33B and 65B scales. Due to the\\nimmense resource costs, we leave this study to future work.\\nAnother limitation is the evaluation of instruction finetuning models. While we provide evaluations\\non MMLU, the Vicuna benchmark, and the OA benchmark, we did not evaluate on other benchmarks\\nsuch as BigBench, RAFT, and HELM, and it is not ensured that our evaluations generalize to these\\nbenchmarks. On the other hand, we perform a very broad study on MMLU and develop new methods\\nfor evaluating chatbots.\\nFrom the evidence presented, it appears that the performance of these benchmarks likely depends how\\nsimilar the finetuning data is to the benchmark dataset. For example, FLAN v2 is similar to MMLU,\\nbut dissimilar to chatbot benchmarks and vice versa for the Chip2 dataset and both models score\\naccordingly on the MMLU and Vicuna benchmarks. This highlights that not only better benchmarks\\nand evaluation is needed, but that one needs to be careful about what one is evaluating in the first\\nplace. Do we want to create models that do well on classroom highschool and colleague knowledge or\\ndo we want to do well on chatbot conversation ability? Maybe something else? Because it is always\\neasier to evaluate on an existing benchmark compared to creating a new one, certain benchmarks\\ncan steer the community towards a certain direction. We should ensure as a community that the\\nbenchmarks measure what we care about.\\nWhile we provide a detailed evaluation for general chatbot performance, another limitation is that we\\nonly do a limited responsible AI evaluation of Guanaco. We evaluate the likelihood of Guanaco-65B\\nto generate a socially biased sequence of tokens compared to other models in Table 8. We see that the\\naverage score in Guanaco-65B is much lower than other raw pretrained models. As such, it seems that\\nfinetuning on the OASST1 dataset reduces the bias of the LLaMA base model. While these results\\nare encouraging, it is unclear if Guanaco does also well when assessed on other types of biases. We\\nleave further evaluation of analyzing biases in Guanaco and similar chatbots to future work.\\n15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6a19a72a-da60-4837-b9a3-a96b4e8e9402', embedding=None, metadata={'page_label': '16', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='An additional limitation is that we did not evaluate different bit-precisions, such as using 3-bit base\\nmodels, or different adapter methods. Besides LoRA, there is also a wide variety Parameter Efficient\\nFineTuning (PEFT) methods that have been shown to work well. However, it is unclear if these\\nmethods scale to large models. We used LoRA as many results established its robustness but other\\nadapters might yield better performance. Since finetuning after quantization seems to recover most of\\nthe information that is lost during quantization this might enable much more aggressive quantization.\\nFor example, 3-bit GPTQ quantization of the basemodel with LoRA might also yield 16-bit full\\nfinetuning performance after finetuning.\\n9 Broader Impacts\\nOur QLORAfinetuning method is the first method that enables the finetuning of 33B parameter\\nmodels on a single consumer GPU and 65B parameter models on a single professional GPU, while\\nnot degrading performance relative to a full finetuning baseline. We have demonstrated that our\\nbest 33B model trained on the Open Assistant dataset can rival ChatGPT on the Vicuna benchmark.\\nSince instruction finetuning is an essential tool to transform raw pretrained LLMs into ChatGPT-like\\nchatbots, we believe that our method will make finetuning widespread and common in particular for\\nthe researchers that have the least resources, a big win for the accessibility of state of the art NLP\\ntechnology. QLORAcan be seen as an equalizing factor that helps to close the resource gap between\\nlarge corporations and small teams with consumer GPUs.\\nAnother potential source of impact is deployment to mobile phones. We believe our QLORAmethod\\nmight enable the critical milestone of enabling the finetuning of LLMs on phones and other low\\nresource settings. While 7B models were shown to be able to be run on phones before, QLORAis\\nthe first method that would enable the finetuning of such models. We estimate that with an iPhone 12\\nPlus, QLORAcan finetune 3 million tokens per night while the phone is charging. While finetuned\\n7B models do not reach the quality of ChatGPT, we believe that the quality is good enough to enable\\nnovel applications that have not been possible before due to privacy or LLM quality issues. QLORA\\ncan help enable privacy-preserving usage of LLMs, where users can own and manage their own data\\nand models, while simultaneously making LLMs easier to deploy.\\nHowever, finetuning is a dual-use technology that can be abused to cause harm. Widespread use of\\nLLMs has known dangers [ 8,6], but we believe that equalizing access to a technology that is quickly\\nbecoming ubiquitous will allow for better more independent analysis than keeping the power of LLMs\\nin the hands of large corporations that do not release models or source code for auditing.\\nAll in all, we believe that QLORAwill have a broadly positive impact making the finetuning of high\\nquality LLMs much more widely and easily accessible.\\nAcknowledgements\\nWe thank Aditya Kusupati, Ofir Press, Ashish Sharma, Margaret Li, Raphael Olivier, Zihao Ye, and\\nEvangelia Spiliopoulou for their valuable feedback. Our research was facilitated by the advanced\\ncomputational, storage, and networking infrastructure of the Hyak supercomputer system at the\\nUniversity of Washington. We thank the Hyak team for ensuring a smooth operation. We thank\\nthe beta testers of the bitsandbytes library, in particular Alex Birch and Alyssa Vance. We thank\\nYounes Belkada for help with the integration of our software into the Hugging Face transformers\\nstack.\\n16', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d069146c-c825-4460-931d-8e1e2de69527', embedding=None, metadata={'page_label': '17', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='References\\n[1]S. An, Y . Li, Z. Lin, Q. Liu, B. Chen, Q. Fu, W. Chen, N. Zheng, and J.-G. Lou. Input-tuning:\\nAdapting unfamiliar inputs to frozen pretrained models. arXiv preprint arXiv:2203.03131 ,\\n2022.\\n[2]A. Askell, Y . Bai, A. Chen, D. Drain, D. Ganguli, T. Henighan, A. Jones, N. Joseph, B. Mann,\\nN. DasSarma, et al. A general language assistant as a laboratory for alignment. arXiv preprint\\narXiv:2112.00861 , 2021.\\n[3]S. H. Bach, V . Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V . Nayak, A. Sharma, T. Kim, M. S.\\nBari, T. Fevry, et al. Promptsource: An integrated development environment and repository for\\nnatural language prompts. arXiv preprint arXiv:2202.01279 , 2022.\\n[4]Y . Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli,\\nT. Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from\\nhuman feedback. arXiv preprint arXiv:2204.05862 , 2022.\\n[5]Y . Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirho-\\nseini, C. McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint\\narXiv:2212.08073 , 2022.\\n[6]E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. On the dangers of stochastic\\nparrots: Can language models be too big? In Proceedings of the 2021 ACM conference on\\nfairness, accountability, and transparency , pages 610–623, 2021.\\n[7]S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O’Brien, E. Hallahan, M. A. Khan,\\nS. Purohit, U. S. Prashanth, E. Raff, et al. Pythia: A suite for analyzing large language models\\nacross training and scaling. arXiv preprint arXiv:2304.01373 , 2023.\\n[8]R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,\\nJ. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models.\\narXiv preprint arXiv:2108.07258 , 2021.\\n[9]T. Chen, B. Xu, C. Zhang, and C. Guestrin. Training deep nets with sublinear memory cost.\\narXiv preprint arXiv:1604.06174 , 2016.\\n[10] W.-L. Chiang, Z. Li, Z. Lin, Y . Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y . Zhuang, J. E.\\nGonzalez, I. Stoica, and E. P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%*\\nchatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/ .\\n[11] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement\\nlearning from human preferences. Advances in neural information processing systems , 30,\\n2017.\\n[12] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y . Tay, W. Fedus, E. Li, X. Wang, M. De-\\nhghani, S. Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint\\narXiv:2210.11416 , 2022.\\n[13] T. Dettmers and L. Zettlemoyer. The case for 4-bit precision: k-bit inference scaling laws. arXiv\\npreprint arXiv:2212.09720 , 2022.\\n[14] T. Dettmers, M. Lewis, Y . Belkada, and L. Zettlemoyer. LLM.int8(): 8-bit matrix multiplication\\nfor transformers at scale. Advances in Neural Information Processing Systems 35: Annual\\nConference on Neural Information Processing Systems 2022, NeurIPS 2022 , 2022.\\n[15] T. Dettmers, M. Lewis, S. Shleifer, and L. Zettlemoyer. 8-bit optimizers via block-wise\\nquantization. 9th International Conference on Learning Representations, ICLR , 2022.\\n[16] A. E. Elo. The proposed uscf rating system. its development, theory, and applications. Chess\\nLife, 22(8):242–247, 1967.\\n[17] A. E. Elo. The rating of chessplayers, past and present . Arco Pub., 1978.\\n17', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cfcaad4c-b79a-49c3-8873-2d498828171f', embedding=None, metadata={'page_label': '18', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[18] E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh. Gptq: Accurate post-training quantization\\nfor generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\\n[19] J. Fu, S.-K. Ng, Z. Jiang, and P. Liu. Gptscore: Evaluate as you desire. arXiv preprint\\narXiv:2302.04166 , 2023.\\n[20] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song. Koala: A\\ndialogue model for academic research. Blog post, April 2023. URL https://bair.berkeley.\\nedu/blog/2023/04/03/koala/ .\\n[21] A. Glaese, N. McAleese, M. Tr˛ ebacz, J. Aslanides, V . Firoiu, T. Ewalds, M. Rauh, L. Weidinger,\\nM. Chadwick, P. Thacker, et al. Improving alignment of dialogue agents via targeted human\\njudgements. arXiv preprint arXiv:2209.14375 , 2022.\\n[22] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith.\\nAnnotation artifacts in natural language inference data. arXiv preprint arXiv:1803.02324 , 2018.\\n[23] J. Henderson, S. Ruder, et al. Compacter: Efficient low-rank hypercomplex adapter layers. In\\nAdvances in Neural Information Processing Systems , 2021.\\n[24] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea-\\nsuring massive multitask language understanding. In International Conference on Learning\\nRepresentations , 2020.\\n[25] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y . Choi. The curious case of neural text\\ndegeneration. In International Conference on Learning Representations , 2020.\\n[26] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language\\nmodels with (almost) no human labor. arXiv preprint arXiv:2212.09689 , 2022.\\n[27] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. At-\\ntariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference\\non Machine Learning , pages 2790–2799. PMLR, 2019.\\n[28] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang, and W. Chen. Lora:\\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 , 2021.\\n[29] S. Iyer, X. V . Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S.\\nKoura, et al. Opt-iml: Scaling language model instruction meta learning through the lens of\\ngeneralization. arXiv preprint arXiv:2212.12017 , 2022.\\n[30] A. Köksal, T. Schick, A. Korhonen, and H. Schütze. Longform: Optimizing instruction tuning\\nfor long text generation with corpus extraction. arXiv preprint arXiv:2304.08460 , 2023.\\n[31] A. Köpf, Y . Kilcher, D. von Rütte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M.\\nDuc, O. Stanley, R. Nagyfi, et al. Openassistant conversations–democratizing large language\\nmodel alignment. arXiv preprint arXiv:2304.07327 , 2023.\\n[32] LAION. Open-instruction-generalist dataset. https://github.com/LAION-AI/\\nOpen-Instruction-Generalist , 2023.\\n[33] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt\\ntuning. arXiv preprint arXiv:2104.08691 , 2021.\\n[34] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\\npreprint arXiv:2101.00190 , 2021.\\n[35] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y . Zhang, D. Narayanan,\\nY . Wu, A. Kumar, et al. Holistic evaluation of language models. arXiv preprint\\narXiv:2211.09110 , 2022.\\n[36] T. Liao, R. Taori, I. D. Raji, and L. Schmidt. Are we learning yet? a meta review of evaluation\\nfailures across machine learning. In Thirty-fifth Conference on Neural Information Processing\\nSystems Datasets and Benchmarks Track (Round 2) , 2021.\\n18', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='377d0411-7ba3-4d98-bee8-c42505200cb4', embedding=None, metadata={'page_label': '19', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[37] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel. Few-shot\\nparameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in\\nNeural Information Processing Systems , 35:1950–1965, 2022.\\n[38] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer,\\nand V . Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint\\narXiv:1907.11692 , 2019.\\n[39] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y . Tay, D. Zhou, Q. V . Le, B. Zoph, J. Wei,\\net al. The flan collection: Designing data and methods for effective instruction tuning. arXiv\\npreprint arXiv:2301.13688 , 2023.\\n[40] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi. Metaicl: Learning to learn in context.\\narXiv preprint arXiv:2110.15943 , 2021.\\n[41] A. Nematzadeh, K. Burns, E. Grant, A. Gopnik, and T. Griffiths. Evaluating theory of mind in\\nquestion answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural\\nLanguage Processing , pages 2392–2400, 2018.\\n[42] OpenAI. Gpt-4 technical report. arXiv , 2023.\\n[43] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal,\\nK. Slama, A. Ray, et al. Training language models to follow instructions with human feedback.\\nAdvances in Neural Information Processing Systems , 35:27730–27744, 2022.\\n[44] G. Park, B. Park, S. J. Kwon, B. Kim, Y . Lee, and D. Lee. nuqmm: Quantized matmul for\\nefficient inference of large-scale generative language models. arXiv preprint arXiv:2206.09557 ,\\n2022.\\n[45] B. Peng, C. Li, P. He, M. Galley, and J. Gao. Instruction tuning with gpt-4. arXiv preprint\\narXiv:2304.03277 , 2023.\\n[46] A. Poliak, J. Naradowsky, A. Haldar, R. Rudinger, and B. Van Durme. Hypothesis only baselines\\nin natural language inference. In Proceedings of the Seventh Joint Conference on Lexical and\\nComputational Semantics , pages 180–191, 2018.\\n[47] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao,\\nS. Agrawal, and J. Dean. Efficiently scaling transformer inference. arXiv preprint\\narXiv:2211.05102 , 2022.\\n[48] G. Qin and J. Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv\\npreprint arXiv:2104.06599 , 2021.\\n[49] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou, W. Li, and P. J. Liu.\\nExploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn.\\nRes., 21(1), jan 2020. ISSN 1532-4435.\\n[50] V . Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,\\nT. L. Scao, A. Raja, et al. Multitask prompted training enables zero-shot task generalization.\\narXiv preprint arXiv:2110.08207 , 2021.\\n[51] M. Sap, R. LeBras, D. Fried, and Y . Choi. Neural theory-of-mind? on the limits of social\\nintelligence in large lms. arXiv preprint arXiv:2210.13312 , 2022.\\n[52] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili ´c, D. Hesslow, R. Castagné, A. S. Luccioni,\\nF. Yvon, M. Gallé, et al. Bloom: A 176b-parameter open-access multilingual language model.\\narXiv preprint arXiv:2211.05100 , 2022.\\n[53] S. Shaphiro and M. Wilk. An analysis of variance test for normality. Biometrika , 52(3):591–611,\\n1965.\\n[54] Y .-L. Sung, V . Nair, and C. A. Raffel. Training neural networks with fixed sparse masks.\\nAdvances in Neural Information Processing Systems , 34:24193–24205, 2021.\\n19', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='20c390bb-797e-428c-8477-4f1bcb8bf807', embedding=None, metadata={'page_label': '20', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[55] R. Taori, I. Gulrajani, T. Zhang, Y . Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto.\\nStanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/\\nstanford_alpaca , 2023.\\n[56] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos,\\nL. Baker, Y . Du, et al. Lamda: Language models for dialog applications. arXiv preprint\\narXiv:2201.08239 , 2022.\\n[57] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal,\\nE. Hambro, F. Azhar, et al. Llama: Open and efficient foundation language models. arXiv\\npreprint arXiv:2302.13971 , 2023.\\n[58] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-\\ntask benchmark and analysis platform for natural language understanding. arXiv preprint\\narXiv:1804.07461 , 2018.\\n[59] Y . Wang, Y . Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi. Self-instruct:\\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560 ,\\n2022.\\n[60] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Kordi, A. Mirzaei, A. Arunkumar, A. Ashok, A. S.\\nDhanasekaran, A. Naik, D. Stap, et al. Super-naturalinstructions:generalization via declarative\\ninstructions on 1600+ tasks. In EMNLP , 2022.\\n[61] Y . Wang, S. Mishra, P. Alipoormolabashi, Y . Kordi, A. Mirzaei, A. Naik, A. Ashok, A. S.\\nDhanasekaran, A. Arunkumar, D. Stap, et al. Super-naturalinstructions: Generalization via\\ndeclarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing , pages 5085–5109, 2022.\\n[62] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V . Le.\\nFinetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652 , 2021.\\n[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V . Le, D. Zhou, et al.\\nChain-of-thought prompting elicits reasoning in large language models. In Advances in Neural\\nInformation Processing Systems , 2022.\\n[64] T. Wolf, L. Debut, V . Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,\\nM. Funtowicz, et al. Huggingface’s transformers: State-of-the-art natural language processing.\\narXiv preprint arXiv:1910.03771 , 2019.\\n[65] M. Wortsman, T. Dettmers, L. Zettlemoyer, A. Morcos, A. Farhadi, and L. Schmidt. Stable and\\nlow-precision training for large-scale vision-language models. arXiv preprint arXiv:2304.13013 ,\\n2023.\\n[66] G. Xiao, J. Lin, M. Seznec, J. Demouth, and S. Han. Smoothquant: Accurate and efficient\\npost-training quantization for large language models. arXiv preprint arXiv:2211.10438 , 2022.\\n[67] T. Xie, C. H. Wu, P. Shi, R. Zhong, T. Scholak, M. Yasunaga, C.-S. Wu, M. Zhong, P. Yin,\\nS. I. Wang, et al. Unifiedskg: Unifying and multi-tasking structured knowledge grounding with\\ntext-to-text language models. arXiv preprint arXiv:2201.05966 , 2022.\\n[68] Z. Yang, P. Qi, S. Zhang, Y . Bengio, W. Cohen, R. Salakhutdinov, and C. D. Manning. Hotpotqa:\\nA dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018\\nConference on Empirical Methods in Natural Language Processing , pages 2369–2380, 2018.\\n[69] Z. Yao, R. Y . Aminabadi, M. Zhang, X. Wu, C. Li, and Y . He. Zeroquant: Efficient and affordable\\npost-training quantization for large-scale transformers. arXiv preprint arXiv:2206.01861 , 2022.\\n[70] E. B. Zaken, S. Ravfogel, and Y . Goldberg. Bitfit: Simple parameter-efficient fine-tuning for\\ntransformer-based masked language-models. arXiv preprint arXiv:2106.10199 , 2021.\\n[71] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y . Xu, W. Zheng, X. Xia, et al.\\nGlm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 , 2022.\\n20', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5f3428c6-4aa4-42d1-ad4e-45d79c427a29', embedding=None, metadata={'page_label': '21', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='[72] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V .\\nLin, et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068 ,\\n2022.\\n[73] R. Zhong, K. Lee, Z. Zhang, and D. Klein. Adapting language models for zero-shot learning by\\nmeta-tuning on dataset and prompt collections. arXiv preprint arXiv:2104.04670 , 2021.\\n21', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5f09049f-40b3-49b4-a6aa-24768e4d8e4d', embedding=None, metadata={'page_label': '22', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A QLoRA vs Standard Finetuning Experimental Setup Details\\nA.1 Hyperparameters for QL ORA\\nWe do a hyperparameter search for LoRA over the following variables: LoRA dropout { 0.0, 0.05,\\n0.1}, LoRA r{ 8, 16, 32, 64, 128, 256}, LoRA layers {key+query, all attention layers, all FFN layers,\\nall layers, attention + FFN output layers}. We keep LoRA αfixed and search the learning rate, since\\nLoRA αis always proportional to the learning rate.\\nWe find that LoRA dropout 0.05 is useful for small models (7B, 13B), but not for larger models (33B,\\n65B). We find LoRA ris unrelated to final performance if LoRA is used on all layers as can be seen\\nin Figure 4\\n8 16 32 64\\nLoRA r64.064.264.464.664.865.0RougeL\\nbits\\n4\\nFigure 4: LoRA rfor LLaMA 7B models finetuned on Alpaca. Each dot represents a combination of\\nhyperparameters and for each LoRA rwe run 3 random seed with each hyperparameter combination. The\\nperformance of specific LoRA rvalues appears to be independent of other hyperparameters.\\nA.2 Super-Natural Instructions Experimental Setup Details\\nWe use the same preprocessing of the Super-Natural Instruction dataset as Wang et al. [60]. However,\\nwe split the training data in training and validation datasets allowing us to perform more rigorous\\nhyperparameter tuning and early stopping. We use the same hyperparameters described in the paper\\nfor training the various T5 model sizes on the Super-Natural Instruction data. We use LoRA r= 16\\nfor small, medium, and large T5 models and LoRA r= 64 for T5 xl and xxl models. We also use\\nLoRA α= 64 in all our experiments and no LoRA dropout.\\nB Training a State-of-the-art Chatbot Experimental Setup Details\\nB.1 Datasets\\nWe describe the datasets used for QL ORA finetuning experiments outlined in Section 5.\\nOASST1 The OpenAssistant dataset [ 31] was collected via crowd-sourcing. It contains 161,443\\nunique messages distributed across 66,497 conversations and spanning 35 different languages. The\\ndataset often contains several ranked replies for each given user question. In our experiments, we\\nonly use the top reply at each level in the conversation tree. This limits the dataset to 9,209 examples.\\nWe finetuning our models on the full conversation including the user queries.\\nHH-RLHF This is a human preference dataset about helpfulness and harmlessness. Each datapoint\\nconsists of two assistant replies to a user question along with a human preference judgment of the\\nbest reply. The dataset contains 160,800 examples. When finetuning on this dataset, we combine\\nhelpfulness and harmlessness data and only keep the preferred assistant reply.\\nFLAN v2 The FLAN v2 collection [ 39] is a collection of 1836 tasks augmented with hundreds\\nof manually curated templates and rich formatting patterns into over 15M examples. The authors\\nshow that models trained on this collection outperform other public collections including the original\\nFLAN 2021 [ 62], T0++ [ 50], Super-Natural Instructions [ 60], and OPT-IML [ 29]. We used the\\nsame task mixtures described by the authors with the exception of some datasets that were not freely\\navailable at the time of writing.\\n22', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a0d842d6-3460-4e2f-9085-2e79a827ceba', embedding=None, metadata={'page_label': '23', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Parameters Dataset Batch size LR Steps Source Length Target Length\\n7B All 16 2e-4 10000 384 128\\n7B OASST1 16 2e-4 1875 - 512\\n7B HH-RLHF 16 2e-4 10000 - 768\\n7B Longform 16 2e-4 4000 512 1024\\n13B All 16 2e-4 10000 384 128\\n13B OASST1 16 2e-4 1875 - 512\\n13B HH-RLHF 16 2e-4 10000 - 768\\n13B Longform 16 2e-4 4000 512 1024\\n33B All 32 1e-4 5000 384 128\\n33B OASST1 16 1e-4 1875 - 512\\n33B HH-RLHF 32 1e-4 5000 - 768\\n33B Longform 32 1e-4 2343 512 1024\\n65B All 64 1e-4 2500 384 128\\n65B OASST1 16 1e-4 1875 - 512\\n65B HH-RLHF 64 1e-4 2500 - 768\\n65B Longform 32 1e-4 2343 512 1024\\nTable 9: Training hyperparameters for QL ORA finetuning on different datasets and across model sizes.\\nSelf-Instruct, Alpaca, Unnatural Instructions The Self-Instruct, Alpaca, and Unnatural Instruc-\\ntions datasets [ 59,55,26] are instruction tuning datasets collected with various approaches of model\\ndistillation from GPT-3 Instruct and ChatGPT. They rely on prompting, in-context learning, and\\nparaphrasing to come up with diverse sets of instructions and outputs. The datasets comprise of\\n82,612, 51,942, and 240,670 examples respectively. One advantage of such distilled datasets is that\\nthey contain a more diverse set of instruction styles compared to the FLAN v2 collection and similar\\ninstruction tuning collections.\\nLongform The LongForm dataset [ 30] is based on an English corpus augmented with instructions\\nand as such is a hybrid human-generated dataset. The underlying documents are human-written and\\ncome from C4 and Wikipedia while the instructions are generated visa LLMs. The dataset is extended\\nwith additional structured corpora examples such as Stack Exchange and WikiHow and task examples\\nsuch as question answering, email writing, grammar error correction, story/poem generation, and text\\nsummarization. The dataset contains 23,700 examples.\\nChip2 is part of the OIG Laion dataset. It contains Python code examples, natural instruction exam-\\nples, generic harmless instructions, instruction/responses with lists, follow-up questions, Wikipedia\\ntoxic adversarial questions, grade school math, reasoning instructions, and character and scene\\ndescriptions with a total of 210,289 examples.\\nB.2 Hyperparameters\\nWe provide the exact hyperparameters used in our QLORAfinetuning experiments. We find hyper-\\nparameters to be largely robust across datasets. We use the MMLU 5-shot dev set for validation\\nand hyperparameter tuning. In all our experiments we use NF4 with double quantization and bf16\\ncomputation datatype. We set LoRA r= 64 ,α= 16 , and add LoRA modules on all linear layers of\\nthe base model. We also use Adam beta2 of 0.999, max grad norm of 0.3 and LoRA dropout of 0.1\\nfor models up to 13B and 0.05 for 33B and 65B models. Following previous work on instruction\\nfinetuning [ 62,60] and after benchmarking other linear and cosine schedules, we use a constant\\nlearning rate schedule. We use group-by-length to group examples of similar lengths in the same\\nbatch (note this will produce a oscillating loss curve). The hyperparameters we tune for each model\\nsize are shown in Table 9.\\nB.3 Ablations\\nWhile it is general practice in the literature to only train on the response in instruction following\\ndatasets, we study the effect of training on the instruction in addition to the response in Table 10. In\\nthese experiments, we restrict the training data to 52,000 examples and use the 7B model. Over four\\ndifferent instruction tuning datasets, we find that only training on the target is beneficial to MMLU\\n23', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='56893917-d9b6-448f-a3bd-68d02922f592', embedding=None, metadata={'page_label': '24', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Dataset Unnatural Instructions Chip2 Alpaca FLAN v2 Mean\\nTrain on source and target 36.2 33.7 38.1 42.0 37.5\\nTrain on target 38.0 34.5 39.0 42.9 38.6\\nTable 10: MMLU 5-shot test results studying the effect of training on the instructions in addition to the response.\\nperformance. We did not evaluate the effect this may have on chatabot performance as measured by\\nvicuna or OA benchmarks.\\nB.4 What is more important: instruction finetuning dataset size or dataset quality?\\nData set suitability is more important than dataset size. To understand the effects of dataset\\nquality vs. dataset size, we experiment with subsampling large datasets with at least 150,000 samples\\n(Chip2, FLAN v2, Unnatural Instructions), into datasets of size 50,000, 100,000 and 150,000 and\\nexamine the resulting trends, as shown in Table 11. We find that increasing the dataset size and\\nincreasing the number of epochs improves MMLU only marginally (0.0 - 0.5 MMLU), while the\\ndifference between datasets is up to 40x larger (1.5 - 8.0 MMLU). This is a clear indicator that dataset\\nquality rather than dataset size is critical for mean MMLU accuracy. We obtain similar findings for\\nchatbot performance as discussed in .\\nC Human Evaluation\\nWe conduct a human evaluation with the same wording given to GPT-4 in the original Vicuna\\nevaluation [10], adjusted for an Amazon Mechanical Turk form as show in Figure 5.\\nD Pairwise Evaluation with GPT-4\\nWhile we found that the GPT-4 evaluation gave different results depend on which system was\\npresented first, when averaged over both options the pairwise results were well-ordered. The\\naggregated pairwise judgments are hown in Table 12. On inspection, it is clear these judgments are\\ntransitive, i.e., when System A is judged better than System B and System B is judged better than\\nSystem C, it is always the case that System A is judged better than System C. This yields a complete\\nordering, given in Table 13.\\nE NormalFloat 4-bit data type\\nThe exact values of the NF4 data type are as follows:\\n[-1.0, -0.6961928009986877, -0.5250730514526367,\\n-0.39491748809814453, -0.28444138169288635, -0.18477343022823334,\\n-0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,\\n0.24611230194568634, 0.33791524171829224, 0.44070982933044434,\\n0.5626170039176941, 0.7229568362236023, 1.0]\\nF Normality of Trained Neural Network Weights\\nWhile it is common knowledge that trained neural network weights are mostly normally distributed,\\nwe perform statistical testing to verify this. We use the Shapiro-Wilk test[ 53] on the weights of the 7B\\nTable 11: Effect different dataset sizes and finetuning epochs on mean 5-shot MMLU test set accuracy. While\\nincreasing the dataset size and training for more than 1 epochs helps with MMLU performance, the difference\\nbetween datasets are far larger, indicating that dataset quality affects MMLU performance more than dataset size.\\nChip Unnatural Instructions FLAN v2\\nDatapoints ↓Epochs → 1 2 3 1 2 3 1 2 3 Mean\\n50000 34.50 35.30 34.70 38.10 42.20 38.10 43.00 43.50 44.10 39.28\\n100000 33.70 33.90 34.00 40.10 41.20 37.00 43.90 43.70 44.90 39.16\\n150000 34.40 34.80 35.10 39.70 41.10 41.50 44.60 45.50 43.50 40.02\\nMean 34.20 34.67 34.60 39.30 41.50 38.87 43.83 44.23 44.17\\n24', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1b4e70cb-9e15-427f-9e20-4deaa69c1110', embedding=None, metadata={'page_label': '25', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Figure 5: The crowdsourcing form used by human annotators.\\nLLaMA model [ 57]. We find that the weights of each hidden unit have different normal distributions.\\nAs such, we test he weights of each individual hidden unit. This mean for weight W∈ Rin×out\\nwe perform tests over the outdimension. Using a 5% significance threshold, we find that 7.5% of\\nneurons are non-normally distributed which is about 2.5% more than the expected false-positive\\nrate. As such, while almost all pretrained weights appear to be normally distributed there seem to\\nbe exceptions. Such exceptions might be due to outliers weights [ 13] or because the p-value of the\\nShaprio-Wilk test is not accurate for large samples sizes[ 53] that occur in the LLaMA FFN layer\\nhidden units. this verifies the claim that neural network weights.\\nTable 12: Aggregated pairwise GPT-4 judgments between systems where the value of a cell at row xand column\\nyis# judgment xis better than y−# judgment yis better than x\\ntotal # number of judgments\\nModel Guanaco 65B Guanaco 33B Vicuna ChatGPT-3.5 Turbo Bard Guanaco 13B Guanaco 7B\\nGuanaco 65B - 0.21 0.19 0.16 0.72 0.59 0.86\\nGuanaco 33B -0.21 - 0.17 0.10 0.51 0.41 0.68\\nVicuna -0.19 -0.17 - 0.10 0.50 0.20 0.57\\nChatGPT-3.5 Turbo -0.16 -0.10 -0.10 - 0.35 0.19 0.40\\nBard -0.72 -0.51 -0.50 -0.35 - 0.12 0.03\\nGuanaco 13B -0.59 -0.41 -0.20 -0.19 -0.12 - 0.20\\nGuanaco 7B -0.86 -0.68 -0.57 -0.40 -0.03 -0.20 -\\n25', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6fab6f5a-ca9f-42c1-aa01-72cb893d6275', embedding=None, metadata={'page_label': '26', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='LLaMA model size0%25%50%75%100%\\n7B (6.9 GB) 13B (11.3 GB) 33B (24.7 GB) 65B (45.0 GB)Input gradient Optimizer Weight gradient Adapters ModelFigure 6: Breakdown of the memory footprint of different LLaMA models. The input gradient size is for batch\\nsize 1 and sequence length 512 and is estimated only for adapters and the base model weights (no attention).\\nNumbers on the bars are memory footprint in MB of individual elements of the total footprint. While some\\nmodels do not quite fit on certain GPUs, paged optimzier provide enough memory to make these models fit.\\nG Memory Footprint\\nThe memory footpring for QLoRA training with different LLaMA base models can be seen in\\nFigure 6. We see that the 33B model does not quite fit into a 24 GB and that paged optimizers\\nare needed to train it. Depicted is also batch size 1 with a sequence length of 512 and gradient\\ncheckpointning. This means, if one uses a larger batch size, or if a long sequence is processed, the\\nactivation gradient might consume a considerable amount of memory.\\nTable 13: The complete ordering induced by pairwise GPT-4 judgments between systems\\nModel Params Size\\nGuanaco 65B 41 GB\\nGuanaco 33B 21 GB\\nVicuna 13B 26 GB\\nChatGPT-3.5 Turbo N/A N/A\\nBard N/A N/A\\nGuanaco 13B 10 GB\\nGuanaco 7B 5 GB\\n26', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f8c546d3-d48c-489f-b498-f686f995773e', embedding=None, metadata={'page_label': '1', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nMEASURING MASSIVE MULTITASK\\nLANGUAGE UNDERSTANDING\\nDan Hendrycks\\nUC BerkeleyCollin Burns\\nColumbia UniversitySteven Basart\\nUChicagoAndy Zou\\nUC Berkeley\\nMantas Mazeika\\nUIUCDawn Song\\nUC BerkeleyJacob Steinhardt\\nUC Berkeley\\nABSTRACT\\nWe propose a new test to measure a text model’s multitask accuracy. The test\\ncovers 57 tasks including elementary mathematics, US history, computer science,\\nlaw, and more. To attain high accuracy on this test, models must possess extensive\\nworld knowledge and problem solving ability. We ﬁnd that while most recent\\nmodels have near random-chance accuracy, the very largest GPT-3 model improves\\nover random chance by almost 20 percentage points on average. However, on every\\none of the 57 tasks, the best models still need substantial improvements before\\nthey can reach expert-level accuracy. Models also have lopsided performance\\nand frequently do not know when they are wrong. Worse, they still have near-\\nrandom accuracy on some socially important subjects such as morality and law.\\nBy comprehensively evaluating the breadth and depth of a model’s academic and\\nprofessional understanding, our test can be used to analyze models across many\\ntasks and to identify important shortcomings.\\n1 I NTRODUCTION\\nNatural Language Processing (NLP) models have achieved superhuman performance on a number of\\nrecently proposed benchmarks. However, these models are still well below human level performance\\nfor language understanding as a whole, suggesting a disconnect between our benchmarks and the\\nactual capabilities of these models. The General Language Understanding Evaluation benchmark\\n(GLUE) (Wang et al., 2018) was introduced in 2018 to evaluate performance on a wide range of NLP\\ntasks, and top models achieved superhuman performance within a year. To address the shortcomings\\nof GLUE, researchers designed the SuperGLUE benchmark with more difﬁcult tasks (Wang et al.,\\n2019). About a year since the release of SuperGLUE, performance is again essentially human-level\\n(Raffel et al., 2019). While these benchmarks evaluate linguistic skills more than overall language\\nunderstanding, an array of commonsense benchmarks have been proposed to measure basic reasoning\\nand everyday knowledge (Zellers et al., 2019; Huang et al., 2019; Bisk et al., 2019). However, these\\nrecent benchmarks have similarly seen rapid progress (Khashabi et al., 2020). Overall, the near\\nhuman-level performance on these benchmarks suggests that they are not capturing important facets\\nof language understanding.\\nTransformer models have driven this recent progress by pretraining on massive text corpora, including\\nall of Wikipedia, thousands of books, and numerous websites. These models consequently see\\nextensive information about specialized topics, most of which is not assessed by existing NLP\\nbenchmarks. It consequently remains an open question just how capable current language models are\\nat learning and applying knowledge from many domains.\\nTo bridge the gap between the wide-ranging knowledge that models see during pretraining and the\\nexisting measures of success, we introduce a new benchmark for assessing models across a diverse\\nset of subjects that humans learn. We design the benchmark to measure knowledge acquired during\\npretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the\\nbenchmark more challenging and more similar to how we evaluate humans. The benchmark covers\\n57subjects across STEM, the humanities, the social sciences, and more. It ranges in difﬁculty from\\nan elementary level to an advanced professional level, and it tests both world knowledge and problem\\nsolving ability. Subjects range from traditional areas, such as mathematics and history, to more\\n1arXiv:2009.03300v3  [cs.CY]  12 Jan 2021', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b73c3273-c8ef-47b2-bc40-d137ad68524b', embedding=None, metadata={'page_label': '2', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nFew Shot Prompt and Predicted Answer\\nHow many numbers are in the list 25, 26, ..., 100?\\n(A) 75 (B) 76 (C) 22 (D) 23\\nAnswer: B\\nCompute i+i2+i3+···+i258+i259.\\n(A) -1 (B) 1 (C) i (D) -i\\nAnswer: A\\nIf 4 daps = 7 yaps, and 5 yaps = 3 baps,\\nhow many daps equal 42 baps?\\n(A) 28 (B) 21 (C) 40 (D) 30\\nAnswer: C␣The following are multiple choice questions\\nabout high school mathematics.\\n(a) An example of few-shot learning and inference us-\\ning GPT-3. The blue underlined bold text is the auto-\\ncompleted response from GPT-3, while the preceding\\ntext is the user-inputted prompt. In this 2-shot learning\\nexample, there are two instruction examples and one\\ninitially incomplete example. On average, GPT-3 has\\nlow accuracy on high school mathematics questions.\\nSmall Medium Large X-Large\\nModel Size2030405060708090Performance (%)GPT-3 Few Shot Test Performance\\nCommonsense\\nLinguistics\\nKnowledge (Ours)(b) Performance on a commonsense benchmark (Hel-\\nlaSwag), a linguistic understanding benchmark (Super-\\nGLUE), and the massive multitask test. On previous\\nbenchmarks, smaller models start well above random\\nchance levels and exhibit more continuous improve-\\nments with model size increases, but on our test, GPT-3\\nmoves beyond random chance with the largest model.\\nspecialized areas like law and ethics (Hendrycks et al., 2020). The granularity and breadth of the\\nsubjects makes the benchmark ideal for identifying a model’s blind spots.\\nWe ﬁnd that meaningful progress on our benchmark has only become possible in recent months. In\\nparticular, few-shot models up to 13billion parameters (Brown et al., 2020) achieve random chance\\nperformance of 25% accuracy, but the 175billion parameter GPT-3 model reaches a much higher\\n43.9%accuracy (see Figure 1b). On the other hand, unlike human professionals GPT-3 does not\\nexcel at any single subject. Instead, we ﬁnd that performance is lopsided, with GPT-3 having almost\\n70% accuracy for its best subject but near-random performance for several other subjects.\\nOur results indicate that while recent advances have been impressive, state-of-the-art models still\\nstruggle at learning and applying knowledge from pretraining. The tasks with near-random accuracy\\ninclude calculation-heavy subjects such as physics and mathematics and subjects related to human\\nvalues such as law and morality. This second weakness is particularly concerning because it will\\nbe important for future models to have a strong understanding of what is legal and what is ethical.\\nWorryingly, we also ﬁnd that GPT-3 does not have an accurate sense of what it does or does not know\\nsince its average conﬁdence can be up to 24% off from its actual accuracy. We comprehensively\\nevaluate the breadth and depth of a model’s text understanding by covering numerous topics that\\nhumans are incentivized to learn. Since our test consists in 57tasks, it can be used to analyze\\naggregate properties of models across tasks and to track important shortcomings. The test and code is\\navailable at github.com/hendrycks/test.\\n2 R ELATED WORK\\nPretraining. The dominant paradigm in NLP is to pretrain large models on massive text corpora\\nincluding educational books and websites. In the process, these models are exposed to information\\nabout a wide range of topics. Petroni et al. (2019) found that recent models learn enough information\\nfrom pretraining that they can serve as knowledge bases. However, no prior work has comprehensively\\nmeasured the knowledge models have across many real-world domains.\\nUntil recently, researchers primarily used ﬁne-tuned models on downstream tasks (Devlin et al., 2019).\\nHowever, larger pretrained models like GPT-3 (Brown et al., 2020) have made it possible to achieve\\ncompetitive performance without ﬁne-tuning by using few-shot learning, which removes the need for\\na large ﬁne-tuning set. With the advent of strong zero-shot and few-shot learning, it is now possible\\nto curate a diverse set of tasks for evaluation and remove the possibility of models on “spurious cues”\\n(Geirhos et al., 2020; Hendrycks et al., 2019b) in a dataset to achieve high performance.\\nBenchmarks. Many recent benchmarks aim to assess a model’s general world knowledge and basic\\nreasoning ability by testing its “commonsense.” A number of commonsense benchmarks have been\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cdd44bcb-12f3-4abc-8b0b-3fa81a04d900', embedding=None, metadata={'page_label': '3', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nAs Seller, an encyclopedia salesman, approached the grounds on which Hermit\\'s house was situated,\\nhe saw a sign that said, \"No salesmen. Trespassers will be prosecuted. Proceed at your own risk.\"\\nAlthough Seller had not been invited to enter, he ignored the sign and drove up the driveway toward\\nthe house. As he rounded a curve, a powerful explosive charge buried in the driveway exploded, and\\nSeller was injured. Can Seller recover damages from Hermit for his injuries?\\n(A) Yes, unless Hermit, when he planted the charge, intended only to deter, not harm, intruders.\\n(B) Yes, if Hermit was responsible for the explosive charge under the driveway.\\n(C) No, because Seller ignored the sign, which warned him against proceeding further.\\n(D) No, if Hermit reasonably feared that intruders would come and harm him or his family.Professional Law\\nFigure 2: This task requires understanding detailed and dissonant scenarios, applying appropriate\\nlegal precedents, and choosing the correct explanation. The green checkmark is the ground truth.\\nproposed in the past year, but recent models are already nearing human-level performance on several\\nof these, including HellaSwag (Zellers et al., 2019), Physical IQA (Bisk et al., 2019), and CosmosQA\\n(Huang et al., 2019). By design, these datasets assess abilities that almost every child has. In contrast,\\nwe include harder specialized subjects that people must study to learn.\\nSome researchers have suggested that the future of NLP evaluation should focus on Natural Language\\nGeneration (NLG) (Zellers et al., 2020), an idea that reaches back to the Turing Test (Turing, 1950).\\nHowever, NLG is notoriously difﬁcult to evaluate and lacks a standard metric (Sai et al., 2020).\\nConsequently, we instead create a simple-to-evaluate test that measures classiﬁcation accuracy on\\nmultiple choice questions.\\nWhile several question answering benchmarks exist, they are comparatively limited in scope. Most\\neither cover easy topics like grade school subjects for which models can already achieve strong\\nperformance (Clark et al., 2018; Khot et al., 2019; Mihaylov et al., 2018; Clark et al., 2019), or\\nare focused on linguistic understanding in the form of reading comprehension (Lai et al., 2017;\\nRichardson et al., 2013). In contrast, we include a wide range of difﬁcult subjects that go far beyond\\nlinguistic understanding.\\n3 A M ULTITASK TEST\\nWe create a massive multitask test consisting of multiple-choice questions from various branches of\\nknowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas\\nthat are important for some people to learn. There are 57tasks in total, which is also the number\\nof Atari games (Bellemare et al., 2013), all of which are listed in Appendix B. The questions in\\nthe dataset were manually collected by graduate and undergraduate students from freely available\\nsources online. These include practice questions for tests such as the Graduate Record Examination\\nand the United States Medical Licensing Examination. It also includes questions designed for\\nundergraduate courses and questions designed for readers of Oxford University Press books. Some\\ntasks cover a subject, like psychology, but at a speciﬁc level of difﬁculty, such as “Elementary,”\\n“High School,” “College,” or “Professional.” For example, the “Professional Psychology” task draws\\non questions from freely available practice questions for the Examination for Professional Practice\\nin Psychology, while the “High School Psychology” task has questions like those from Advanced\\nPlacement Psychology examinations.\\nWe collected 15908 questions in total, which we split into a few-shot development set, a validation\\nset, and a test set. The few-shot development set has 5questions per subject, the validation set may\\nbe used for selecting hyperparameters and is made of 1540 questions, and the test set has 14079\\nquestions. Each subject contains 100test examples at the minimum, which is longer than most exams\\ndesigned to assess people.\\nHuman-level accuracy on this test varies. Unspecialized humans from Amazon Mechanical Turk\\nobtain 34.5%accuracy on this test. Meanwhile, expert-level performance can be far higher. For\\nexample, real-world test-taker human accuracy at the 95th percentile is around 87% for US Medical\\nLicensing Examinations, and these questions make up our “Professional Medicine” task. If we take\\nthe 95th percentile human test-taker accuracy for exams that build up our test, and if we make an\\neducated guess when such information is unavailable, we then estimate that expert-level accuracy is\\napproximately 89.8%.\\nSince our test aggregates different subjects and several levels of difﬁculty, we measure more than\\nstraightforward commonsense or narrow linguistic understanding. Instead, we measure arbitrary\\n3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='45794058-ba94-408e-a069-0687bd7ea889', embedding=None, metadata={'page_label': '4', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nOne of the reasons that the government discourages and regulates monopolies is that\\n(A) producer surplus is lost and consumer surplus is gained.\\n(B) monopoly prices ensure productive efficiency but cost society allocative efficiency.\\n(C) monopoly firms do not engage in significant research and development.\\n(D) consumer surplus is lost with higher prices and lower levels of output.Microeconomics\\nFigure 3: Examples from the Microeconomics task.\\nWhen you drop a ball from rest it accelerates downward at 9.8 m/s². If you instead throw it\\ndownward assuming no air resistance its acceleration immediately after leaving your hand is\\n(A) 9.8 m/s²\\n(B) more than 9.8 m/s²\\n(C) less than 9.8 m/s²\\n(D) Cannot say unless the speed of throw is given.Conceptual\\nPhysicsCollege\\nMathematicsIn the complex z-plane, the set of points satisfying the equation z² = |z|² is a\\n(A) pair of points\\n(B) circle\\n(C) half-line\\n(D) line\\nFigure 4: Examples from the Conceptual Physics and College Mathematics STEM tasks.\\nreal-world textunderstanding. Since models are pretrained on the Internet, this enables us to test\\nhow well they can extract useful knowledge from massive corpora. Future models that use this test\\ncould be single models or a mixture of experts model. To succeed at our test, future models should be\\nwell-rounded, possess extensive world knowledge, and develop expert-level problem solving ability.\\nThese properties make the test likely to be an enduring and informative goalpost.\\n3.1 H UMANITIES\\nThe humanities is a group of disciplines that make use of qualitative analysis and analytic methods\\nrather than scientiﬁc empirical methods. Branches of the humanities include law, philosophy, history,\\nand so on (Appendix B). Mastering these subjects requires a variety of skills. For example, legal\\nunderstanding requires knowledge of how to apply rules and standards to complex scenarios, and\\nalso provide answers with stipulations and explanations. We illustrate this in Figure 2. Legal\\nunderstanding is also necessary for understanding and following rules and regulations, a necessary\\ncapability to constrain open-world machine learning models. For philosophy, our questions cover\\nconcepts like logical fallacies, formal logic, and famous philosophical arguments. It also covers\\nmoral scenarios, including questions from the ETHICS dataset (Hendrycks et al., 2020) that test a\\nmodel’s understanding of normative statements through predicting widespread moral intuitions about\\ndiverse everyday scenarios. Finally, our history questions cover a wide range of time periods and\\ngeographical locations, including prehistory and other advanced subjects.\\n3.2 S OCIAL SCIENCE\\nSocial science includes branches of knowledge that examine human behavior and society. Subject\\nareas include economics, sociology, politics, geography, psychology, and so on. See Figure 3 for\\nan example question. Our economics questions include microeconomics, macroeconomics, and\\neconometrics, and cover different types of problems, including questions that require a mixture of\\nworld knowledge, qualitative reasoning, or quantitative reasoning. We also include important but\\nmore esoteric topics such as security studies in order to test the boundaries of what is experienced and\\nlearned during pretraining. Social science also includes psychology, a ﬁeld that may be especially\\nimportant for attaining a nuanced understanding of humans.\\n3.3 S CIENCE , TECHNOLOGY , ENGINEERING ,AND MATHEMATICS (STEM)\\nSTEM subjects include physics, computer science, mathematics, and more. Two examples are shown\\nin Figure 4. Conceptual physics tests understanding of simple physics principles and may be thought\\n4', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='30bf6ab9-c00e-47fc-a5fc-5cca2dc97dbf', embedding=None, metadata={'page_label': '5', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nA 33-year-old man undergoes a radical thyroidectomy for thyroid cancer. During the operation,\\nmoderate hemorrhaging requires ligation of several vessels in the left side of the neck.\\nPostoperatively, serum studies show a calcium concentration of 7.5 mg/dL, albumin concentration\\nof 4 g/dL, and parathyroid hormone concentration of 200 pg/mL. Damage to which of the following\\nvessels caused the findings in this patient?\\n(A) Branch of the costocervical trunk\\n(B) Branch of the external carotid artery\\n(C) Branch of the thyrocervical trunk\\n(D) Tributary of the internal jugular veinProfessional Medicine\\nFigure 5: A question from the Professional Medicine task.\\nof as a harder version of the physical commonsense benchmark Physical IQA (Bisk et al., 2019). We\\nalso test mathematical problem solving ability at various levels of difﬁculty, from the elementary to\\nthe college level. College mathematics questions, like those found on the GRE mathematics subject\\ntest, often require chains of reasoning and abstract knowledge. To encode mathematics expressions,\\nwe use LaTeX or symbols such as * and ˆ for multiplication and exponentiation respectively. STEM\\nsubjects require knowledge of empirical methods, ﬂuid intelligence, and procedural knowledge.\\n3.4 O THER\\nThere is a long tail of subjects that either do not neatly ﬁt into any of the three preceding categories or\\nfor which there are not thousands of freely available questions. We put these subjects into Other. This\\nsection includes the Professional Medicine task, which has difﬁcult questions that require humans\\nmany years of study to master. An example is depicted in Figure 5. This section also contains\\nbusiness topics like ﬁnance, accounting, and marketing, as well as knowledge of global facts. The\\nlatter includes statistics about poverty in different countries over time, which may be necessary for\\nhaving an accurate model of the world internationally.\\n4 E XPERIMENTS\\n4.1 S ETUP\\nAssessment and Models. To measure performance on our multitask test, we compute the clas-\\nsiﬁcation accuracy across all examples and tasks. We evaluate GPT-3 (Brown et al., 2020) and\\nUniﬁedQA (Khashabi et al., 2020). For GPT-3 we use the OpenAI API, which provides access to four\\nmodel variants, “Ada,” “Babbage,” “Curie,” and “Davinci,” which we refer to as “Small” ( 2.7billion\\nparameters), “Medium” ( 6.7billion), “Large” ( 13billion) and “X-Large” ( 175billion). UniﬁedQA\\nuses the T5 (Raffel et al., 2019) text-to-text backbone and is ﬁne-tuned on previously proposed\\nquestion answering datasets (Lai et al., 2017), where the prediction is the class with the highest\\ntoken overlap with UniﬁedQA’s text output. Since UniﬁedQA is ﬁne-tuned on other datasets, we\\nevaluate it without any further tuning to assess its transfer accuracy. We also ﬁne-tune RoBERTa-base,\\nALBERT-xxlarge, and GPT-2 on UniﬁedQA training data and our dev+val set. We primarily focus on\\nUniﬁedQA and GPT-3 in the rest of this document, but additional discussion of RoBERTa, ALBERT,\\nand GPT-2 is in Appendix A.\\nModel Humanities Social Science STEM Other Average\\nRandom Baseline 25.0 25.0 25.0 25.0 25.0\\nRoBERTa 27.9 28.8 27.0 27.7 27.9\\nALBERT 27.2 25.7 27.7 27.9 27.1\\nGPT-2 32.8 33.3 30.2 33.1 32.4\\nUniﬁedQA 45.6 56.6 40.2 54.6 48.9\\nGPT-3 Small (few-shot) 24.4 30.9 26.0 24.1 25.9\\nGPT-3 Medium (few-shot) 26.1 21.6 25.6 25.5 24.9\\nGPT-3 Large (few-shot) 27.1 25.6 24.3 26.5 26.0\\nGPT-3 X-Large (few-shot) 40.8 50.4 36.7 48.8 43.9\\nTable 1: Average weighted accuracy for each model on all four broad disciplines. All values are\\npercentages. Some models proposed in the past few months can move several percent points beyond\\nrandom chance. GPT-3 uses few-shot learning and UniﬁedQA is tested under distribution shift.\\n5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f984933a-c99f-4d10-ac5c-ec2f703e5480', embedding=None, metadata={'page_label': '6', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Published as a conference paper at ICLR 2021\\n0 20 40 60 80 100\\nAccuracy (%)World ReligionsVirologyUS Foreign PolicySociologySecurity StudiesPublic RelationsProfessional PsychologyProfessional MedicineProfessional LawProfessional AccountingPrehistoryPhilosophyNutritionMoral ScenariosMoral DisputesMiscellaneousMedical GeneticsMarketingManagementMachine LearningLogical FallaciesJurisprudenceInternational LawHuman SexualityHuman AgingHigh School World HistoryHigh School US HistoryHigh School StatisticsHigh School PsychologyHigh School PhysicsHigh School MicroeconomicsHigh School MathematicsHigh School MacroeconomicsHigh School Gov't and PoliticsHigh School GeographyHigh School European HistoryHigh School Comp SciHigh School ChemistryHigh School BiologyGlobal FactsFormal LogicElementary MathematicsElectrical EngineeringEconometricsConceptual PhysicsComputer SecurityCollege PhysicsCollege MedicineCollege MathematicsCollege Comp SciCollege ChemistryCollege BiologyClinical KnowledgeBusiness EthicsAstronomyAnatomyAbstract AlgebraGPT-3\\nUnifiedQA\\nRandom\\nFigure 6: GPT-3 (few-shot) and UniﬁedQA results.Few-Shot Prompt. We feed GPT-3 prompts\\nlike that shown in Figure 1a. We begin each\\nprompt with “The following are multiple choice\\nquestions (with answers) about [subject].” For\\nzero-shot evaluation, we append the question to\\nthe prompt. For few-shot evaluation, we add up\\nto5demonstration examples with answers to\\nthe prompt before appending the question. All\\nprompts end with “Answer: ”. The model then\\nproduces probabilities for the tokens “A,” “B,”\\n“C,” and “D,” and we treat the highest probability\\noption as the prediction. For consistent evalua-\\ntion, we create a dev set with 5ﬁxed few-shot\\nexamples for each subject.\\n4.2 R ESULTS\\nModel Size and Accuracy. We compare the\\nfew-shot accuracy of each GPT-3 size in Table 1.\\nWe ﬁnd that the three smaller GPT-3 models\\nhave near random accuracy (around 25%). In\\ncontrast, we ﬁnd that the X-Large 175billion\\nparameter GPT-3 model performs substantially\\nbetter than random, with an accuracy of 43.9%.\\nWe also ﬁnd qualitatively similar results in the\\nzero-shot setting. While the smaller models\\nhave around 25% zero-shot accuracy, Figure 10\\nin Appendix A shows that the largest GPT-3\\nmodel has a much higher zero-shot accuracy of\\nabout 37.7%. Brown et al. (2020) also observe\\nthat larger GPT-3 models perform better, though\\nprogress tends to be steadier. In Figure 1b we\\nshow that non-random accuracy on the multitask\\ntest emerged with recent large few-shot models\\ncompared to datasets that assess commonsense\\nand linguistic understanding.\\nTo test the usefulness of ﬁne-tuning instead of\\nfew-shot learning, we also evaluate UniﬁedQA\\nmodels. UniﬁedQA has the advantage of being\\nﬁne-tuned on other question answering datasets,\\nunlike GPT-3. We assess UniﬁedQA by evalu-\\nating its transfer performance without any ad-\\nditional ﬁne-tuning. The largest UniﬁedQA\\nmodel we test has 11billion parameters, which\\nis slightly smaller than GPT-3 Large. Neverthe-\\nless, we show in Table 1 that it attains 48.9%\\naccuracy. This performs better than the few-shot GPT-3 X-Large model, despite UniﬁedQA have\\nan order of magnitude fewer parameters. We also ﬁnd that even the smallest UniﬁedQA variant,\\nwith just 60million parameters, has approximately 29.3%accuracy. These results suggest that while\\nmodel size is a key component for achieving strong performance, ﬁne-tuning also helps.\\nComparing Disciplines. Using our test, we discover that GPT-3 and UniﬁedQA have lopsided\\nperformance and several substantial knowledge gaps. Figure 6 shows the accuracy of GPT-3 (few-\\nshot) and UniﬁedQA for all 57tasks. It shows the both models are below expert-level performance\\nfor all tasks, with GPT-3’s accuracy ranging from 69% for US Foreign Policy to 26% for College\\nChemistry. UniﬁedQA does best on marketing, with an accuracy of 82.5%.\\nOverall, models do poorly on highly procedural problems. Figure 6 shows that calculation-heavy\\nSTEM subjects tend to have low accuracy compared to verbal subjects. For GPT-3, 9out of the 10\\n6\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c20a78ec-b039-488b-972a-8aa03a8d7cfc', embedding=None, metadata={'page_label': '7', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nDeclarative vs. Procedural Knowledge\\nPrompt and Completion:\\nThe order of operations or PEMDAS is\\nParentheses Exponents Multiplication\\nDivision Addition Subtraction\\nPrompt and Completion:\\n(1 + 1) × 2 = 3␣\\nFigure 7: GPT-3’s completion for two prompts\\ntesting knowledge of the order of operations. The\\nblue underlined bold text is the autocompleted\\nresponse from GPT-3. While it knows about the\\norder of operations, it sometimes does not know\\nhow to apply its knowledge.\\n20\\n30\\n40\\n50\\n60\\nConfidence (%)\\n20\\n30\\n40\\n50\\n60Accuracy (%)\\nGPT-3 Zero-Shot Calibration\\nFormal LogicMarketing Figure 8: GPT-3’s conﬁdence is a poor estimator\\nof its accuracy and can be off by up to 24%.\\nlowest-accuracy tasks are STEM subjects that emphasize mathematics or calculations. We speculate\\nthat is in part because GPT-3 acquires declarative knowledge more readily than procedural knowledge.\\nFor example, many questions in Elementary Mathematics require applying the order of operations\\nfor arithmetic, which is described by the acronym PEMDAS (Parentheses Exponents Multiplication\\nDivision Addition Subtraction). In Figure 7, we conﬁrm that GPT-3 is aware of the acronym\\nPEMDAS. However, it does not consistently apply PEMDAS to actual problems. On the other hand,\\nprocedural understanding is not its only weak point. We ﬁnd that some verbal tasks such as Moral\\nScenarios from Hendrycks et al. (2020) and Professional Law also have especially low accuracy.\\nOur test also shows that GPT-3 acquires knowledge quite unlike humans. For example, GPT-3 learns\\nabout topics in a pedagogically unusual order. GPT-3 does better on College Medicine ( 47.4%)\\nand College Mathematics ( 35.0%) than calculation-heavy Elementary Mathematics ( 29.9%). GPT-3\\ndemonstrates unusual breadth, but it does not master a single subject. Meanhwhile we suspect humans\\nhave mastery in several subjects but not as much breadth. In this way, our test shows that GPT-3 has\\nmany knowledge blindspots and has capabilities that are lopsided.\\nCalibration. We should not trust a model’s prediction unless the model is calibrated, meaning\\nthat its conﬁdence is a good estimate of the actual probability the prediction is correct. However,\\nlarge neural networks are often miscalibrated (Guo et al., 2017), especially under distribution shift\\n(Ovadia et al., 2019). We evaluate the calibration of GPT-3 by testing how well its average conﬁdence\\nestimates its actual accuracy for each subject. We show the results in Figure 8, which demonstrates\\nthat GPT-3 is uncalibrated. In fact, its conﬁdence is only weakly related to its actual accuracy in\\nthe zero-shot setting, with the difference between its accuracy and conﬁdence reaching up to 24%\\nfor some subjects. Another calibration measure is the Root Mean Squared (RMS) calibration error\\n(Hendrycks et al., 2019a; Kumar et al., 2019). Many tasks have miscalibrated predictions, such as\\nElementary Mathematics which has a zero-shot RMS calibration error of 19.4%. Models are only\\nsomewhat more calibrated in the few-shot setting, as shown in Appendix A. These results suggest\\nthat model calibration has wide room for improvement.\\n5 D ISCUSSION\\nMultimodal Understanding. While text is capable of conveying an enormous number of concepts\\nabout the world, many important concepts are conveyed mainly through other modalities, such as\\nimages, audio, and physical interaction (Bisk et al., 2020). Existing large-scale NLP models, such as\\nGPT-3, do not incorporate multimodal information, so we design our benchmark to capture a diverse\\narray of tasks in a text-only format. However, as models gain the ability to process multimodal inputs,\\nbenchmarks should be designed to reﬂect this change. One such benchmark could be a “Turk Test,”\\nconsisting of Amazon Mechanical Turk Human Intelligence Tasks. These are well-deﬁned tasks that\\nrequire models to interact with ﬂexible formats and demonstrate multimodal understanding.\\nThe Internet as a Training Set. A major distinction between our benchmark and previous multitask\\nNLP benchmarks is that we do not require large training sets. Instead, we assume that models have\\nacquired the requisite knowledge from reading vast quantities of diverse text from the Internet. This\\n7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6f4389b7-244d-47d3-a186-7c066a49ebba', embedding=None, metadata={'page_label': '8', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nprocess is typically called pretraining, but it can be thought of as training in its own right, where the\\ndownstream evaluation is demonstrating whatever knowledge we would expect a human to pick up\\nfrom reading the same text.\\nThis motivates us to propose a methodological change so that models are trained more like how\\nhumans learn. While most previous machine learning benchmarks have models learn from a large\\nquestion bank, humans primarily learn new subjects by reading books and listening to others talk\\nabout the topic. For specialized subjects such as Professional Law, massive legal corpora are available,\\nsuch as the 164-volume legal encyclopedia Corpus Juris Secundum , but there are fewer than 5,000\\nmultistate bar exam questions available. Learning the entire law exclusively through a small number\\nof practice tests is implausible, so future models must learn more during pretraining.\\nFor this reason we assess pretrained models in a zero-shot, few-shot, or transfer setting and we provide\\na dev, val, and test set for each task. The dev set is used for few-shot prompts, the val set could be\\nused for hyperparameter tuning, and the test set is used to compute the ﬁnal accuracy. Importantly,\\nthe format of our evaluation is not identical to the format in which information is acquired during\\npretraining. This has the beneﬁt of obviating concerns about spurious training set annotation artifacts\\n(Geirhos et al., 2020; Hendrycks et al., 2019b) and is in stark contrast to the previous paradigm\\nof identically distributed training and test sets. This change also enables collecting a much more\\nextensive and diverse set of tasks for evaluation. We anticipate our methodology becoming more\\nwidespread as models improve at extracting information from diverse online sources.\\nModel Limitations. We ﬁnd that current large-scale Transformers have wide room for improvement.\\nThey are notably poor at modeling human (dis)approval, as evident by the low performance on the\\nProfessional Law and Moral Scenarios tasks. For future systems to be aligned with human values, high\\nperformance on these tasks is crucial (Hendrycks et al., 2020), so future research should especially\\naim to increase accuracy on these tasks. Models also have difﬁculty performing calculations, so much\\nso that they exhibit poor performance on Elementary Mathematics and many other STEM subjects\\nwith “plug and chug” problems. Additionally, they do not match expert-level performance (90%) on\\nany subject, so for all subjects it is subhuman. On average, models are only now starting to move\\nbeyond random-chance accuracy levels.\\nAddressing these shortcomings may be challenging. To illustrate this, we attempted to create a better\\nProfessional Law model by pretraining on specialized data but achieved only limited success. We\\ncollected approximately 2,000 additional Professional Law training examples. After ﬁne-tuning a\\nRoBERTa-base model (Liu et al., 2019) using this custom training set, our model attained 32.8%test\\naccuracy. To test the impact of additional specialized training data, we also had RoBERTa continue\\npretraining on approximately 1.6 million legal case summaries using Harvard’s Law Library case law\\ncorpus case.law , but after ﬁne-tuning it only attained 36.1%accuracy. This suggests that while\\nadditional pretraining on relevant high quality text can help, it may not be enough to substantially\\nincrease the performance of current models.\\nIt is unclear whether simply scaling up existing language models will solve the test. Current\\nunderstanding indicates that a 10×increase in model size must be accompanied by an approximate\\n5×increase in data (Kaplan et al., 2020). Aside from the tremendous expense in creating multi-trillion\\nparameter language models, data may also become a bottleneck, as there is far less written about\\nesoteric branches of knowledge than about everyday situations.\\n6 C ONCLUSION\\nWe introduced a new test that measures how well text models can learn and apply knowledge\\nencountered during pretraining. By covering 57 subjects at varying levels of difﬁculty, the test\\nassesses language understanding in greater breadth and depth than previous benchmarks. We found\\nthat it has recently become possible for models to make meaningful progress on the test, but that\\nstate-of-the-art models have lopsided performance and rarely excel at any individual task. We also\\nshowed that current models are uncalibrated and have difﬁculty with tasks that require calculations.\\nWorryingly, models also perform especially poorly on socially relevant subjects including morality\\nand law. Our expansive test can help researchers pinpoint important shortcomings of models, making\\nit easier to gain a clearer picture of state-of-the-art capabilities.\\n8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4b65cae3-eeae-4812-b805-09eb110aba25', embedding=None, metadata={'page_label': '9', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nACKNOWLEDGEMENTS\\nWe would like to thank the following for their helpful comments: Oyvind Tafjord, Jan Leike, David\\nKrueger, Alex Tamkin, Girish Sastry, and Henry Zhu. DH is supported by the NSF GRFP Fellowship\\nand an Open Philanthropy Project Fellowship. This research was also supported by the NSF Frontier\\nAward 1804794.\\nREFERENCES\\nM. G. Bellemare, Y . Naddaf, J. Veness, and M. Bowling. The arcade learning environment: An\\nevaluation platform for general agents (extended abstract). J. Artif. Intell. Res. , 47:253–279, 2013.\\nY . Bisk, R. Zellers, R. L. Bras, J. Gao, and Y . Choi. Piqa: Reasoning about physical commonsense in\\nnatural language, 2019.\\nY . Bisk, A. Holtzman, J. Thomason, J. Andreas, Y . Bengio, J. Chai, M. Lapata, A. Lazaridou, J. May,\\nA. Nisnevich, N. Pinto, and J. Turian. Experience grounds language, 2020.\\nT. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, S. Agarwal, A. Herbert-V oss, G. Krueger, T. Henighan, R. Child, A. Ramesh,\\nD. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess,\\nJ. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models\\nare few-shot learners, 2020.\\nP. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have\\nsolved question answering? try arc, the ai2 reasoning challenge. ArXiv , abs/1803.05457, 2018.\\nP. Clark, O. Etzioni, D. Khashabi, T. Khot, B. D. Mishra, K. Richardson, A. Sabharwal, C. Schoenick,\\nO. Tafjord, N. Tandon, S. Bhakthavatsalam, D. Groeneveld, M. Guerquin, and M. Schmitz. From ’f’\\nto ’a’ on the n.y. regents science exams: An overview of the aristo project. ArXiv , abs/1909.01958,\\n2019.\\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional\\ntransformers for language understanding. ArXiv , abs/1810.04805, 2019.\\nR. Geirhos, J.-H. Jacobsen, C. Michaelis, R. Zemel, W. Brendel, M. Bethge, and F. A. Wichmann.\\nShortcut learning in deep neural networks, 2020.\\nC. Guo, G. Pleiss, Y . Sun, and K. Q. Weinberger. On calibration of modern neural networks. ICML ,\\n2017.\\nD. Hendrycks, M. Mazeika, and T. Dietterich. Deep anomaly detection with outlier exposure. ICLR ,\\n2019a.\\nD. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples. ArXiv ,\\nabs/1907.07174, 2019b.\\nD. Hendrycks, C. Burns, S. Basart, A. Critch, J. Li, D. Song, and J. Steinhardt. Aligning ai with\\nshared human values, 2020.\\nL. Huang, R. L. Bras, C. Bhagavatula, and Y . Choi. Cosmos qa: Machine reading comprehension\\nwith contextual commonsense reasoning, 2019.\\nJ. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu,\\nand D. Amodei. Scaling laws for neural language models, 2020.\\nD. Khashabi, T. Khot, A. Sabharwal, O. Tafjord, P. Clark, and H. Hajishirzi. Uniﬁedqa: Crossing\\nformat boundaries with a single qa system, 2020.\\nT. Khot, P. Clark, M. Guerquin, P. Jansen, and A. Sabharwal. Qasc: A dataset for question answering\\nvia sentence composition, 2019.\\nA. Kumar, P. Liang, and T. Ma. Veriﬁed uncertainty calibration, 2019.\\n9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='baa2539d-9de0-4fa9-b6b7-60ead183da61', embedding=None, metadata={'page_label': '10', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nG. Lai, Q. Xie, H. Liu, Y . Yang, and E. Hovy. Race: Large-scale reading comprehension dataset from\\nexaminations, 2017.\\nZ. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. Albert: A lite bert for\\nself-supervised learning of language representations. ArXiv , abs/1909.11942, 2020.\\nY . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and\\nV . Stoyanov. Roberta: A robustly optimized bert pretraining approach. ArXiv , abs/1907.11692,\\n2019.\\nT. Mihaylov, P. Clark, T. Khot, and A. Sabharwal. Can a suit of armor conduct electricity? a new\\ndataset for open book question answering. In EMNLP , 2018.\\nY . Ovadia, E. Fertig, J. Ren, Z. Nado, D. Sculley, S. Nowozin, J. V . Dillon, B. Lakshminarayanan,\\nand J. Snoek. Can you trust your model’s uncertainty? Evaluating predictive uncertainty under\\ndataset shift. NeurIPS , 2019.\\nF. Petroni, T. Rocktäschel, P. Lewis, A. Bakhtin, Y . Wu, A. H. Miller, and S. Riedel. Language\\nmodels as knowledge bases?, 2019.\\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised\\nmultitask learners. 2019.\\nC. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou, W. Li, and P. J. Liu.\\nExploring the limits of transfer learning with a uniﬁed text-to-text transformer, 2019.\\nM. Richardson, C. J. Burges, and E. Renshaw. MCTest: A challenge dataset for the open-domain\\nmachine comprehension of text. In Proceedings of the 2013 Conference on Empirical Methods in\\nNatural Language Processing , pages 193–203, Seattle, Washington, USA, Oct. 2013. Association\\nfor Computational Linguistics.\\nA. B. Sai, A. K. Mohankumar, and M. M. Khapra. A survey of evaluation metrics used for nlg\\nsystems. 2020.\\nA. Turing. Computing machinery and intelligence. 1950.\\nA. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-task benchmark\\nand analysis platform for natural language understanding, 2018.\\nA. Wang, Y . Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman.\\nSuperglue: A stickier benchmark for general-purpose language understanding systems, 2019.\\nR. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi. Hellaswag: Can a machine really ﬁnish\\nyour sentence?, 2019.\\nR. Zellers, A. Holtzman, E. Clark, L. Qin, A. Farhadi, and Y . Choi. Evaluating machines by their\\nreal-world language use, 2020.\\n10', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dbb8e9aa-6cda-4d88-b947-0cb9d2721a20', embedding=None, metadata={'page_label': '11', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Published as a conference paper at ICLR 2021\\nA A DDITIONAL ANALYSIS\\nThis appendix includes ﬁgures with sorted results (Figure 9), few-shot examples vs. accuracy\\n(Figure 10), and few-shot calibration (Figure 11). It also includes sections on ﬁne-tuning, error\\nanalysis, and format sensitivity.\\n0 20 40 60 80 100\\nAccuracy (%)College ChemistryMoral ScenariosCollege PhysicsHigh School PhysicsHigh School MathematicsFormal LogicElementary MathematicsAbstract AlgebraHigh School StatisticsMachine LearningEconometricsHigh School ChemistryProfessional AccountingProfessional LawCollege MathematicsProfessional MedicineConceptual PhysicsGlobal FactsHigh School Comp SciMedical GeneticsHigh School MacroeconomicsHigh School MicroeconomicsMoral DisputesProfessional PsychologyCollege BiologyVirologyCollege Comp SciBusiness EthicsNutritionCollege MedicineAnatomyClinical KnowledgeLogical FallaciesHigh School BiologyPublic RelationsAstronomyElectrical EngineeringHuman AgingPhilosophySecurity StudiesPrehistoryHigh School US HistorySociologyHigh School European HistoryHuman SexualityJurisprudenceWorld ReligionsInternational LawHigh School World HistoryManagementComputer SecurityHigh School GeographyHigh School Gov't and PoliticsMarketingMiscellaneousHigh School PsychologyUS Foreign PolicyGPT-3 Results\\nRandom Chance\\n0102030405060708090100\\nAccuracy (%)Moral ScenariosFormal LogicAbstract AlgebraEconometricsHigh School MathematicsCollege PhysicsMachine LearningHigh School StatisticsCollege ChemistryElementary MathematicsCollege MathematicsHigh School ChemistryGlobal FactsProfessional LawMedical GeneticsProfessional AccountingCollege BiologyHigh School PhysicsAnatomyCollege Comp SciConceptual PhysicsCollege MedicineVirologyProfessional MedicineAstronomyHigh School MacroeconomicsElectrical EngineeringProfessional PsychologySecurity StudiesHuman SexualityNutritionHigh School Comp SciPrehistoryClinical KnowledgeHigh School BiologyHuman AgingHigh School MicroeconomicsPhilosophyPublic RelationsWorld ReligionsMoral DisputesLogical FallaciesHigh School European HistoryHigh School US HistoryHigh School World HistoryMiscellaneousUS Foreign PolicyComputer SecuritySociologyInternational LawHigh School GeographyJurisprudenceBusiness EthicsHigh School PsychologyManagementHigh School Gov't and PoliticsMarketingUnifiedQA Results\\nRandom Chance\\nFigure 9: On the left are GPT-3 few shot accuracies for all of the 57tasks. On the right are UniﬁedQA\\ntransfer accuracies for all of the 57tasks. For both models, capabilities are lopsided.\\nA.1 A NALYSIS WITH MORE FINE-TUNED MODELS\\nWe primarily analyzed models with more than 10billion parameters in the main body of the paper.\\nFor this section, we analyze smaller models including RoBERTa-base (125 million parameters) (Liu\\n11\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='73447f22-7c82-4022-a435-a7ef7e92e17b', embedding=None, metadata={'page_label': '12', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\net al., 2019), ALBERT-xxlarge (223 million parameters) (Lan et al., 2020), and GPT-2 (1,558 million\\nparameters) (Radford et al., 2019). Models are ﬁne-tuned to predict one of four classes using the\\nUniﬁedQA MCQ questions and using our dev+val set. We test on our multitask test set.\\nWe observe that these smaller models can attain better-than-random accuracy. RoBERTa-base attains\\nan overall accuracy of 27.9%, with 27.9%accuracy for the humanities, 28.8%for social sciences,\\n27.0%for STEM, and 27.7%for other. ALBERT-xxlarge attains an accuracy of 27.1%, with 27.2%\\naccuracy for the humanities, 25.7%for the social sciences, 27.7%for STEM, and 27.9%for other.\\nGPT-2 attains an accuracy of 32.4%, with 32.8%accuracy for the humanities, 33.3%for the social\\nsciences, 30.2%for STEM, and 33.1%for other.\\nCompare this to UniﬁedQA’s smallest variant, which has just 60million parameters and approximately\\n29.3%accuracy. It obtains higher accuracy than RoBERTa and ALBERT, even though it has fewer\\nparameters. This suggests that its larger pretraining dataset enables higher accuracy. Likewise,\\nUniﬁedQA with 3billion parameters attains 43.7%, while the similarly sized GPT-2 model with 1.5\\nbillion parameters attains 32.4%accuracy. This again suggests that T5’s larger pretraining dataset\\nsize (and therefore UniﬁedQA’s pretraining dataset size) can increase accuracy.\\nA.2 E RROR ANALYSIS\\nWe qualitatively analyze when GPT-3 makes high conﬁdence mistakes. We ﬁnd that while many of\\nthese mistakes were clearly wrong, many were mistakes that a human might make. For example,\\none question it got wrong was “How many chromosomes do all human somatic cells contain?” The\\ncorrect answer is 46, while few-shot GPT-3 predicted 23with conﬁdence 97.5%. This answer would\\nhave been correct if the question asked about the number of pairs of chromosomes. Similarly, many\\nof its other high conﬁdence mistakes were also correct answers to slightly different questions.\\nA.3 F ORMAT SENSITIVITY\\nWhile different question formatting choices often lead to similar GPT-3 accuracies, we ﬁnd that\\nUniﬁedQA is more sensitive. UniﬁedQA’s input format is of the form\\nQUESTION1 \\\\\\\\n (A) CHOICE1 (B) CHOICE2 (C) CHOICE3 (D) CHOICE4</s>\\nwhere questions and choices are normalized and made lowercase. If we remove the </s> from the\\ninput, accuracy declines by several percentage points.\\n12', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='063502c3-21dd-454f-b268-6914aa6bd9dd', embedding=None, metadata={'page_label': '13', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\n0-Shot 1-Shot 2-Shot 3-Shot 4-Shot 5-Shot\\nNumber of Examples in Context3035404550Accuracy (%)\\nGPT-3 Multitask Accuracy vs.\\nNumber of Examples in Context\\nFigure 10: As the number of few-shot instruction\\nexamples increases, the accuracy monotonically\\nincreases. Notably, zero-shot performance is only\\nsomewhat lower than 5-shot accuracy.\\n20 30 40 50 60 70\\nConfidence (%)203040506070Accuracy (%)\\nGPT-3 Few-Shot CalibrationFigure 11: While models are more calibrated in\\na few-shot setting than a zero-shot setting, they\\nare still miscalibrated, with gap between accuracy\\nand conﬁdence reaching up to 14%. Here the\\ncorrelation between conﬁdence and accuracy is\\nr= 0.81, compared to r= 0.63in the zero-shot\\nsetting.\\nB T ESTDETAILS\\nB.1 T ASK DESCRIPTIONS AND EXAMPLES\\nWe provide analysis of question length and difﬁculty in Figure 12. We list all tasks and the topics\\nthey test in Table 2. We also provide an example for each task starting with Figure 14.\\n0 500 1000 1500 2000 2500 3000\\nQuestion Length (Characters)0.00.20.40.60.81.0Confidence of True Label\\nGPT-3 Question Length and Correctness\\n0 250 500 750 1000 1250\\nAverage Question Length (Characters)0.00.20.40.60.81.0Subject Accuracy\\nGPT-3 Average Question Length and\\nAccuracy by Subject\\nFigure 12: Figures on the relation between question difﬁculty and question length. For questions\\nlonger than a tweet (280 characters), the correlation between question length and true label conﬁdence\\nis slightly positive. This shows that longer questions are not necessarily harder.\\nB.2 E XACT QUESTION AND ANSWER CONTAMINATION\\nSince language models train on vast text corpora, there is some chance that they have seen the exact\\nquestion and answer during pretraining. If they memorized the exact question and answer, then\\nthey would attain higher accuracy than their true ability. Likewise, a question’s entropy would be\\nespecially low if it were memorized. Memorized questions and answers should have low entropy and\\n13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='62afc152-de31-4f5c-bdf6-7ad00f53fbd5', embedding=None, metadata={'page_label': '14', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nhigh accuracy. However, in Figure 13, we see that accuracy and question entropy are not positively\\ncorrelated, suggesting that the test’s low-entropy questions do not correspond to memorized (and\\nthereby correctly predicted) answers. This suggests that our exact questions were not memorized.\\nHowever, during pretraining models encountered text related to our questions through processing\\nWikipedia. We also note that most of our questions came from PDFs or websites where questions and\\nanswers are on separate pages.\\nSee Brown et al. (2020) for a previous discussion of contamination showing that the phenomena\\nhardly affects performance. To reduce the probability that future models encounter exact questions\\nduring test-time, we will provide a list of question sources.\\n2.8\\n 2.6\\n 2.4\\n 2.2\\n 2.0\\n 1.8\\nLog Probability Per Token2030405060Accuracy (%)\\nGPT-3 Zero-Shot\\nPrompt Compression and Accuracy\\n2.4\\n 2.2\\n 2.0\\n 1.8\\n 1.6\\n 1.4\\n 1.2\\nLog Probability Per Token203040506070Accuracy (%)\\nGPT-3 Few-Shot\\nPrompt Compression and Accuracy\\nFigure 13: The average log probability of the question (without answer) is not strongly positively\\ncorrelated with accuracy, all else equal. Each point corresponds to a task. Higher log probability\\nindicates higher compression, and especially high log probability would suggest memorization. In\\nthe zero-shot question prompt, the correlation between average log probability and accuracy is\\nr=−0.43, and for the few-shot setting the correlation is r=−0.56.\\n14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a554a357-044a-45e1-a274-175eda197260', embedding=None, metadata={'page_label': '15', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nTask Tested Concepts Supercategory\\nAbstract Algebra Groups, rings, ﬁelds, vector spaces, ... STEM\\nAnatomy Central nervous system, circulatory system, ... STEM\\nAstronomy Solar system, galaxies, asteroids, ... STEM\\nBusiness Ethics Corporate responsibility, stakeholders, regulation, ... Other\\nClinical Knowledge Spot diagnosis, joints, abdominal examination, ... Other\\nCollege Biology Cellular structure, molecular biology, ecology, ... STEM\\nCollege Chemistry Analytical, organic, inorganic, physical, ... STEM\\nCollege Computer Science Algorithms, systems, graphs, recursion, ... STEM\\nCollege Mathematics Differential equations, real analysis, combinatorics, ... STEM\\nCollege Medicine Introductory biochemistry, sociology, reasoning, ... Other\\nCollege Physics Electromagnetism, thermodynamics, special relativity, ... STEM\\nComputer Security Cryptography, malware, side channels, fuzzing, ... STEM\\nConceptual Physics Newton’s laws, rotational motion, gravity, sound, ... STEM\\nEconometrics V olatility, long-run relationships, forecasting, ... Social Sciences\\nElectrical Engineering Circuits, power systems, electrical drives, ... STEM\\nElementary Mathematics Word problems, multiplication, remainders, rounding, ... STEM\\nFormal Logic Propositions, predicate logic, ﬁrst-order logic, ... Humanities\\nGlobal Facts Extreme poverty, literacy rates, life expectancy, ... Other\\nHigh School Biology Natural selection, heredity, cell cycle, Krebs cycle, ... STEM\\nHigh School Chemistry Chemical reactions, ions, acids and bases, ... STEM\\nHigh School Computer Science Arrays, conditionals, iteration, inheritance, ... STEM\\nHigh School European History Renaissance, reformation, industrialization, ... Humanities\\nHigh School Geography Population migration, rural land-use, urban processes, ... Social Sciences\\nHigh School Gov’t and Politics Branches of government, civil liberties, political ideologies, ... Social Sciences\\nHigh School Macroeconomics Economic indicators, national income, international trade, ... Social Sciences\\nHigh School Mathematics Pre-algebra, algebra, trigonometry, calculus, ... STEM\\nHigh School Microeconomics Supply and demand, imperfect competition, market failure, ... Social Sciences\\nHigh School Physics Kinematics, energy, torque, ﬂuid pressure, ... STEM\\nHigh School Psychology Behavior, personality, emotions, learning, ... Social Sciences\\nHigh School Statistics Random variables, sampling distributions, chi-square tests, ... STEM\\nHigh School US History Civil War, the Great Depression, The Great Society, ... Humanities\\nHigh School World History Ottoman empire, economic imperialism, World War I, ... Humanities\\nHuman Aging Senescence, dementia, longevity, personality changes, ... Other\\nHuman Sexuality Pregnancy, sexual differentiation, sexual orientation, ... Social Sciences\\nInternational Law Human rights, sovereignty, law of the sea, use of force, ... Humanities\\nJurisprudence Natural law, classical legal positivism, legal realism, ... Humanities\\nLogical Fallacies No true Scotsman, base rate fallacy, composition fallacy, ... Humanities\\nMachine Learning SVMs, VC dimension, deep learning architectures, ... STEM\\nManagement Organizing, communication, organizational structure, ... Other\\nMarketing Segmentation, pricing, market research, ... Other\\nMedical Genetics Genes and cancer, common chromosome disorders, ... Other\\nMiscellaneous Agriculture, Fermi estimation, pop culture, ... Other\\nMoral Disputes Freedom of speech, addiction, the death penalty, ... Humanities\\nMoral Scenarios Detecting physical violence, stealing, externalities, ... Humanities\\nNutrition Metabolism, water-soluble vitamins, diabetes, ... Other\\nPhilosophy Skepticism, phronesis, skepticism, Singer’s Drowning Child, ... Humanities\\nPrehistory Neanderthals, Mesoamerica, extinction, stone tools, ... Humanities\\nProfessional Accounting Auditing, reporting, regulation, valuation, ... Other\\nProfessional Law Torts, criminal law, contracts, property, evidence, ... Humanities\\nProfessional Medicine Diagnosis, pharmacotherapy, disease prevention, ... Other\\nProfessional Psychology Diagnosis, biology and behavior, lifespan development, ... Social Sciences\\nPublic Relations Media theory, crisis management, intelligence gathering, ... Social Sciences\\nSecurity Studies Environmental security, terrorism, weapons of mass destruction, ... Social Sciences\\nSociology Socialization, cities and community, inequality and wealth, ... Social Sciences\\nUS Foreign Policy Soft power, Cold War foreign policy, isolationism, ... Social Sciences\\nVirology Epidemiology, coronaviruses, retroviruses, herpesviruses, ... Other\\nWorld Religions Judaism, Christianity, Islam, Buddhism, Jainism, ... Humanities\\nTable 2: Summary of all 57tasks.\\n15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f7d71738-061c-4700-8b6c-d68c187c8467', embedding=None, metadata={'page_label': '16', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nFind allcinZ3such that Z3[x]/(x2+c)is a ﬁeld.\\n(A) 0 (B) 1 (C) 2 (D) 3\\nFigure 14: An Abstract Algebra example.\\nWhat is the embryological origin of the hyoid bone?\\n(A) The ﬁrst pharyngeal arch\\n(B) The ﬁrst and second pharyngeal arches\\n(C) The second pharyngeal arch\\n(D) The second and third pharyngeal arches\\nFigure 15: An Anatomy example.\\nWhy isn’t there a planet where the asteroid belt is located?\\n(A) A planet once formed here but it was broken apart by a catastrophic collision.\\n(B) There was not enough material in this part of the solar nebula to form a planet.\\n(C) There was too much rocky material to form a terrestrial planet but not enough gaseous material\\nto form a jovian planet.\\n(D) Resonance with Jupiter prevented material from collecting together to form a planet.\\nFigure 16: An Astronomy example.\\nThree contrasting tactics that CSO’s can engage in to meet their aims are which typi-\\ncally involves research and communication, , which may involve physically attacking a\\ncompany’s operations or , often involving some form of .\\n(A) Non-violent direct action, Violent direct action, Indirect action, Boycott\\n(B) Indirect action, Instrumental action, Non-violent direct action, Information campaign\\n(C) Indirect action, Violent direct action, Non-violent direct-action Boycott.\\n(D) Non-violent direct action, Instrumental action, Indirect action, Information campaign\\nFigure 17: A Business Ethics example.\\nHow many attempts should you make to cannulate a patient before passing the job on to a senior\\ncolleague?\\n(A) 4 (B) 3 (C) 2 (D) 1\\nFigure 18: A Clinical Knowledge example.\\nIn a given population, 1 out of every 400 people has a cancer caused by a completely recessive\\nallele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is\\nthe expected proportion of individuals who carry the b allele but are not expected to develop the\\ncancer?\\n(A) 1/400 (B) 19/400 (C) 20/400 (D) 38/400\\nFigure 19: A College Biology example.\\nWhich of the following statements about the lanthanide elements is NOT true?\\n(A) The most common oxidation state for the lanthanide elements is +3.\\n(B) Lanthanide complexes often have high coordination numbers (> 6).\\n(C) All of the lanthanide elements react with aqueous acid to liberate hydrogen.\\n(D) The atomic radii of the lanthanide elements increase across the period from La to Lu.\\nFigure 20: A College Chemistry example.\\n16', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='73c864d0-68c1-45a9-86f2-99f93220b583', embedding=None, metadata={'page_label': '17', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nConsider a computer design in which multiple processors, each with a private cache memory,\\nshare global memory using a single bus. This bus is the critical system resource. Each processor\\ncan execute one instruction every 500 nanoseconds as long as memory references are satisﬁed\\nby its local cache. When a cache miss occurs, the processor is delayed for an additional 2,000\\nnanoseconds. During half of this additional delay, the bus is dedicated to serving the cache miss.\\nDuring the other half, the processor cannot continue, but the bus is free to service requests from\\nother processors. On average, each instruction requires 2 memory references. On average, cache\\nmisses occur on 1 percent of references. What proportion of the capacity of the bus would a single\\nprocessor consume, ignoring delays due to competition from other processors?\\n(A) 1/50 (B) 1/27 (C) 1/25 (D) 2/27\\nFigure 21: A College Computer Science example.\\nLetAbe a real 2×2matrix. Which of the following statements must be true?\\nI. All of the entries of A2are nonnegative.\\nII. The determinant of A2is nonnegative.\\nIII. If A has two distinct eigenvalues, then A2has two distinct eigenvalues.\\n(A) I only (B) II only (C) III only (D) II and III only\\nFigure 22: A College Mathematics example.\\nIn a genetic test of a newborn, a rare genetic disorder is found that has X-linked recessive\\ntransmission. Which of the following statements is likely true regarding the pedigree of this\\ndisorder?\\n(A) All descendants on the maternal side will have the disorder.\\n(B) Females will be approximately twice as affected as males in this family.\\n(C) All daughters of an affected male will be affected.\\n(D) There will be equal distribution of males and females affected.\\nFigure 23: A College Medicine example.\\nOne end of a Nichrome wire of length 2L and cross-sectional area A is attached to an end of\\nanother Nichrome wire of length L and cross- sectional area 2A. If the free end of the longer wire\\nis at an electric potential of 8.0 volts, and the free end of the shorter wire is at an electric potential\\nof 1.0 volt, the potential at the junction of the two wires is most nearly equal to\\n(A) 2.4 V\\n(B) 3.3 V\\n(C) 4.5 V\\n(D) 5.7 V\\nFigure 24: A College Physics example.\\nWhy is it that anti-virus scanners would not have found an exploitation of Heartbleed?\\n(A) It’s a vacuous question: Heartbleed only reads outside a buffer, so there is no possible exploit\\n(B) Anti-virus scanners tend to look for viruses and other malicious\\n(C) Heartbleed attacks the anti-virus scanner itself\\n(D) Anti-virus scanners tend to look for viruses and other malicious code, but Heartbleed\\nexploits steal secrets without injecting any code\\nFigure 25: A Computer Security example.\\nA model airplane ﬂies slower when ﬂying into the wind and faster with wind at its back. When\\nlaunched at right angles to the wind, a cross wind, its groundspeed compared with ﬂying in still\\nair is\\n(A) the same (B) greater (C) less (D) either greater or less depending on wind speed\\nFigure 26: A Conceptual Physics example.\\n17', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a3933aa0-6d5b-4df2-a12b-6715f1db8b9c', embedding=None, metadata={'page_label': '18', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nConsider the following AR(1) model with the disturbances having zero mean and unit variance\\nyt= 0.2 + 0.4yt−1+ut\\nThe (unconditional) mean of ywill be given by\\n(A) 0.2 (B) 0.4 (C) 0.5 (D) 0.33\\nFigure 27: An Econometrics example.\\nA point pole has a strength of 4π×10−4weber. The force in newtons on a point pole of\\n4π×1.5×10−4weber placed at a distance of 10 cm from it will be\\n(A) 15 N. (B) 20 N. (C) 7.5 N. (D) 3.75 N.\\nFigure 28: An Electrical Engineering example.\\nA total of 30 players will play basketball at a park. There will be exactly 5 players on each team.\\nWhich statement correctly explains how to ﬁnd the number of teams needed?\\n(A) Add 5 to 30 to ﬁnd 35 teams.\\n(B) Divide 30 by 5 to ﬁnd 6 teams.\\n(C) Multiply 30 and 5 to ﬁnd 150 teams.\\n(D) Subtract 5 from 30 to ﬁnd 25 teams.\\nFigure 29: An Elementary Mathematics example.\\nDetermine whether the statements are logically equivalent or contradictory. If neither, determine\\nwhether they are consistent or inconsistent.\\nE⊃(F·E)and∼E·F\\n(A) Logically equivalent\\n(B) Contradictory\\n(C) Neither logically equivalent nor contradictory, but consistent\\n(D) Inconsistent\\nFigure 30: A Formal Logic example.\\nAs of 2017, how many of the world’s 1-year-old children today have been vaccinated against\\nsome disease?\\n(A) 80%\\n(B) 60%\\n(C) 40%\\n(D) 20%\\nFigure 31: A Global Facts example.\\nHomologous structures are often cited as evidence for the process of natural selection. All of the\\nfollowing are examples of homologous structures EXCEPT\\n(A) the wings of a bird and the wings of a bat\\n(B) the ﬂippers of a whale and the arms of a man\\n(C) the pectoral ﬁns of a porpoise and the ﬂippers of a seal\\n(D) the forelegs of an insect and the forelimbs of a dog\\nFigure 32: A High School Biology example.\\nFrom the solubility rules, which of the following is true?\\n(A) All chlorides, bromides, and iodides are soluble\\n(B) All sulfates are soluble\\n(C) All hydroxides are soluble\\n(D) All ammonium-containing compounds are soluble\\nFigure 33: A High School Chemistry example.\\n18', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e7ab7c98-498b-4b4d-817d-1f1d694bd326', embedding=None, metadata={'page_label': '19', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nA list of numbers has n elements, indexed from 1 to n. The following algorithm is intended to\\ndisplay the number of elements in the list that have a value greater than 100. The algorithm uses\\nthe variables count and position. Steps 3 and 4 are missing.\\nStep 1: Set count to 0 and position to 1.\\nStep 2: If the value of the element at index position is greater\\nthan 100, increase the value of count by 1.\\nStep 3: (missing step)\\nStep 4: (missing step)\\nStep 5: Display the value of count.\\nWhich of the following could be used to replace steps 3 and 4 so that the algorithm works as\\nintended?\\n(A) Step 3: Increase the value of position by 1.\\nStep 4: Repeat steps 2 and 3 until the value of count is greater than 100.\\n(B) Step 3: Increase the value of position by 1.\\nStep 4: Repeat steps 2 and 3 until t he value of position is greater than n.\\n(C) Step 3: Repeat step 2 until the value of count is greater than 100.\\nStep 4: Increase the value of position by 1.\\n(D) Step 3: Repeat step 2 until the value of position is greater than n.\\nStep 4: Increase the value of count by 1.\\nFigure 34: A High School Computer Science example.\\nThis question refers to the following information.\\nAlbeit the king’s Majesty justly and rightfully is and ought to be the supreme head of the Church\\nof England, and so is recognized by the clergy of this realm in their convocations, yet nevertheless,\\nfor corroboration and conﬁrmation thereof, and for increase of virtue in Christ’s religion within\\nthis realm of England, and to repress and extirpate all errors, heresies, and other enormities and\\nabuses heretofore used in the same, be it enacted, by authority of this present Parliament, that the\\nking, our sovereign lord, his heirs and successors, kings of this realm, shall be taken, accepted,\\nand reputed the only supreme head in earth of the Church of England, called Anglicans Ecclesia;\\nand shall have and enjoy, annexed and united to the imperial crown of this realm, as well the\\ntitle and style thereof, as all honors, dignities, preeminences, jurisdictions, privileges, authorities,\\nimmunities, proﬁts, and commodities to the said dignity of the supreme head of the same Church\\nbelonging and appertaining; and that our said sovereign lord, his heirs and successors, kings of\\nthis realm, shall have full power and authority from time to time to visit, repress, redress, record,\\norder, correct, restrain, and amend all such errors, heresies, abuses, offenses, contempts, and\\nenormities, whatsoever they be, which by any manner of spiritual authority or jurisdiction ought\\nor may lawfully be reformed, repressed, ordered, redressed, corrected, restrained, or amended,\\nmost to the pleasure of Almighty God, the increase of virtue in Christ’s religion, and for the\\nconservation of the peace, unity, and tranquility of this realm; any usage, foreign land, foreign\\nauthority, prescription, or any other thing or things to the contrary hereof notwithstanding.\\nEnglish Parliament, Act of Supremacy, 1534\\nFrom the passage, one may infer that the English Parliament wished to argue that the Act of\\nSupremacy would\\n(A) give the English king a new position of authority\\n(B) give the position of head of the Church of England to Henry VIII alone and exclude his heirs\\n(C) establish Calvinism as the one true theology in England\\n(D) end various forms of corruption plaguing the Church in England\\nFigure 35: A High School European History example.\\nDuring the third stage of the demographic transition model, which of the following is true?\\n(A) Birth rates increase and population growth rate is less rapid.\\n(B) Birth rates decline and population growth rate is less rapid.\\n(C) Birth rates increase and population growth rate increases.\\n(D) Birth rates decrease and population growth rate increases.\\nFigure 36: A High School Geography example.\\n19', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='10b64799-db65-4091-b056-76c40916071b', embedding=None, metadata={'page_label': '20', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nWhich of the following best states an argument made by James Madison in The Federalist number\\n10?\\n(A) Honest politicians can prevent factions from developing.\\n(B) Factions are more likely to occur in large republics than in small ones.\\n(C) The negative effects of factionalism can be reduced by a republican government.\\n(D) Free elections are the people’s best defense against factionalism.\\nFigure 37: A High School Government and Politics example.\\nWhich of the following is not included in the U.S. GDP?\\n(A) The U.S. military opens a new base in a foreign country with 1000 U.S. personnel.\\n(B) Japanese consumers buy thousands of CDs produced in the United States.\\n(C) An American pop singer performs a sold-out concert in Paris.\\n(D) A French theatrical production tours dozens of American cities.\\nFigure 38: A High School Macroeconomics example.\\nJoe was in charge of lights for a dance. The red light blinks every two seconds, the yellow light\\nevery three seconds, and the blue light every ﬁve seconds. If we include the very beginning and\\nvery end of the dance, how many times during a seven minute dance will all the lights come on at\\nthe same time? (Assume that all three lights blink simultaneously at the very beginning of the\\ndance.)\\n(A) 3\\n(B) 15\\n(C) 6\\n(D) 5\\nFigure 39: A High School Mathematics example.\\nIf the government subsidizes producers in a perfectly competitive market, then\\n(A) the demand for the product will increase\\n(B) the demand for the product will decrease\\n(C) the consumer surplus will increase\\n(D) the consumer surplus will decrease\\nFigure 40: A High School Microeconomics example.\\nA point charge, Q = +1 mC, is ﬁxed at the origin. How much work is required to move a charge,\\nQ = +8 µC, from the point (0, 4 meters) to the point (3 meters, 0)?\\n(A) 3.5 J\\n(B) 6.0 J\\n(C) 22.5 J\\n(D) 40 J\\nFigure 41: A High School Physics example.\\nWhile swimming in the ocean, Ivan is frightened by a dark shadow in the water even before he\\nhas the chance to identify what the shadow is. The synaptic connections taking place during this\\nincident of fright are best described by which of the following?\\n(A) Messages are sent from the thalamus directly to the amygdala.\\n(B) Messages are sent from the thalamus to the “what” and “where” pathways.\\n(C) Messages are sent from the parasympathetic nervous system to the cerebral cortex.\\n(D) Messages are sent from the frontal lobes to the pituitary gland.\\nFigure 42: A High School Psychology example.\\n20', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='dc5922ca-6b0e-432a-bb7f-085810012058', embedding=None, metadata={'page_label': '21', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nJonathan obtained a score of 80 on a statistics exam, placing him at the 90th percentile. Suppose\\nﬁve points are added to everyone’s score. Jonathan’s new score will be at the\\n(A) 80th percentile.\\n(B) 85th percentile.\\n(C) 90th percentile.\\n(D) 95th percentile.\\nFigure 43: A High School Statistics example.\\nThis question refers to the following information.\\n“Society in every state is a blessing, but government even in its best state is but a necessary evil; in\\nits worst state an intolerable one; for when we suffer, or are exposed to the same miseries by a\\ngovernment, which we might expect in a country without government, our calamity is heightened\\nby reﬂecting that we furnish the means by which we suffer. Government, like dress, is the badge\\nof lost innocence; the palaces of kings are built on the ruins of the bowers of paradise. For were\\nthe impulses of conscience clear, uniform, and irresistibly obeyed, man would need no other\\nlawgiver; but that not being the case, he ﬁnds it necessary to surrender up a part of his property to\\nfurnish means for the protection of the rest; and this he is induced to do by the same prudence\\nwhich in every other case advises him out of two evils to choose the least. Wherefore, security\\nbeing the true design and end of government, it unanswerably follows that whatever form thereof\\nappears most likely to ensure it to us, with the least expense and greatest beneﬁt, is preferable to\\nall others.”\\nThomas Paine, Common Sense, 1776\\nWhich of the following “miseries” alluded to above were most condemned by Anti-Federalists of\\nthe post-Revolutionary era?\\n(A) Organized response to Bacon’s Rebellion.\\n(B) Federal response to Shays’s Rebellion.\\n(C) Federal response to the Whiskey Rebellion.\\n(D) Federal response to Pontiac’s Rebellion.\\nFigure 44: A High School US History example.\\nThis question refers to the following information.\\n“The real grievance of the worker is the insecurity of his existence; he is not sure that he will\\nalways have work, he is not sure that he will always be healthy, and he foresees that he will one\\nday be old and unﬁt to work. If he falls into poverty, even if only through a prolonged illness, he\\nis then completely helpless, left to his own devices, and society does not currently recognize any\\nreal obligation towards him beyond the usual help for the poor, even if he has been working all\\nthe time ever so faithfully and diligently. The usual help for the poor, however, leaves a lot to be\\ndesired, especially in large cities, where it is very much worse than in the country.”\\nOtto von Bismarck, 1884\\nOtto von Bismarck likely made this speech in reaction to which of the following issues?\\n(A) Social acceptance of child labor.\\n(B) Declining life expectancy in Germany.\\n(C) Criticisms of German trade tariffs.\\n(D) Negative effects attributed to industrial capitalism.\\nFigure 45: A High School World History example.\\nAll other things being equal, which of the following persons is more likely to show osteoporosis?\\n(A) An older Hispanic American woman\\n(B) An older African American woman\\n(C) An older Asian American woman\\n(D) An older Native American woman\\nFigure 46: A Human Aging example.\\n21', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f3beca4e-cf46-4c06-ba5a-32d850b16a95', embedding=None, metadata={'page_label': '22', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nMorning sickness is typically a problem:\\n(A) during the ﬁrst trimester\\n(B) during the second trimester\\n(C) during the third trimester\\n(D) all through the pregnancy\\nFigure 47: A Human Sexuality example.\\nWould a reservation to the deﬁnition of torture in the ICCPR be acceptable in contemporary\\npractice?\\n(A) This is an acceptable reservation if the reserving country’s legislation employs a different\\ndeﬁnition\\n(B) This is an unacceptable reservation because it contravenes the object and purpose of\\nthe ICCPR\\n(C) This is an unacceptable reservation because the deﬁnition of torture in the ICCPR is consistent\\nwith customary international law\\n(D) This is an acceptable reservation because under general international law States have the right\\nto enter reservations to treaties\\nFigure 48: An International Law example.\\nWhich position does Rawls claim is the least likely to be adopted by the POP (people in the\\noriginal position)?\\n(A) The POP would choose equality above liberty.\\n(B) The POP would opt for the ‘maximin’ strategy.\\n(C) The POP would opt for the ‘difference principle.’\\n(D) The POP would reject the ‘system of natural liberty.’\\nFigure 49: A Jurisprudence example.\\nJohn Stuart Mill: Each person’s happiness is a good to that person, and the general happiness,\\ntherefore, a good to the aggregate of all persons.\\n(A) Fallacy of Composition\\n(B) Fallacy of Division\\n(C) Gambler’s Fallacy\\n(D) Equivocation\\nFigure 50: A Logical Fallacies example.\\nA 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side\\n3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the\\nprobability of side 3 coming up when using Add-1 Smoothing?\\n(A) 2/15 (B) 1/7 (C) 3/16 (D) 1/5\\nFigure 51: A Machine Learning example.\\nAccording to Lewin, Lippet and White’s 1939 experiment, which form of leadership produced the\\nmost work from participants?\\n(A) Laissez-faire\\n(B) Democratic\\n(C) Authoritarian\\n(D) A mix of laissez-faire and democratic\\nFigure 52: A Management example.\\n22', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7d88fe31-f3a9-42cd-8afe-df2a9ead28d4', embedding=None, metadata={'page_label': '23', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nThe single group within society that is most vulnerable to reference group inﬂuence is:\\n(A) The older consumer who feels somewhat left out of things.\\n(B) The married women, many of whom feel a need for stability in their lives.\\n(C) New immigrants who really want to assimilate into their new culture.\\n(D) Children, who base most of their buying decisions on outside inﬂuences.\\nFigure 53: A Marketing example.\\nWhich of the following conditions does not show multifactorial inheritance?\\n(A) Pyloric stenosis\\n(B) Schizophrenia\\n(C) Spina biﬁda (neural tube defects)\\n(D) Marfan syndrome\\nFigure 54: A Medical Genetics example.\\nIf each of the following meals provides the same number of calories, which meal requires the\\nmost land to produce the food?\\n(A) Red beans and rice\\n(B) Steak and a baked potato\\n(C) Corn tortilla and refried beans\\n(D) Lentil soup and brown bread\\nFigure 55: A Miscellaneous example.\\nIn response to Sandel’s “social justice” argument, Kamm argues that\\n(A) even if we were able to enhance ourselves or others, we would not thereby be obligated to do\\nso.\\n(B) there is a difference between (i) choosing that one have a certain trait and (ii) being responsible\\nfor bearing the costs of that choice.\\n(C) having the option to enhance will lead to fewer instances of people who require the assistance\\nof others.\\n(D) all of the above\\nFigure 56: A Moral Disputes example.\\nFor which of these two scenarios does the main character (who uses I/me/my) do something\\nclearly morally wrong?\\nScenario 1 | I drive very fast when I’m on a racetrack.\\nScenario 2 | I drive very fast when I’m in the suburbs.\\n(A) Wrong, Wrong\\n(B) Wrong, Not wrong\\n(C) Not wrong, Wrong\\n(D) Not wrong, Not wrong\\nFigure 57: A Moral Scenarios example. The formatting of this task hinders UniﬁedQA performance\\nsubstantially.\\nWhich of the following is the most plausible explanation for the protective effect of dietary ﬁbre\\nagainst cancer of the colon?\\n(A) Propionic acid, formed during colonic ﬁbre fermentation inhibits liver fatty acid synthesis\\n(B) Butyric acid, formed during colonic ﬁbre fermentation stimulates \"silencing\" of the SLC5A8\\ntumour suppressor gene\\n(C) Butyric acid, formed during colonic ﬁbre fermentation stimulates anti-oxidant defences\\nin the colon\\n(D) None of these options are correct\\nFigure 58: A Nutrition example.\\n23', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='8019faf0-3b2b-4859-a2ae-96846065d40b', embedding=None, metadata={'page_label': '24', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nAccording to Moore’s “ideal utilitarianism,” the right action is the one that brings about the\\ngreatest amount of:\\n(A) pleasure.\\n(B) happiness.\\n(C) good.\\n(D) virtue.\\nFigure 59: A Philosophy example.\\nResearchers now believe that the decline of the Maya was caused chieﬂy by:\\n(A) a cataclysm of some kind, such as an earthquake, volcano, or tsunami.\\n(B) ecological degradation resulting from slash-and-burn farming techniques.\\n(C) endless wars between neighboring Mayan city-states.\\n(D) practices of interbreeding that led to a steep rise in congenital disorders.\\nFigure 60: A Prehistory example.\\nKrete is an unmarried taxpayer with income exclusively from wages. By December 31, year 1,\\nKrete’s employer has withheld $16,000 in federal income taxes and Krete has made no estimated\\ntax payments. On April 15, year 2, Krete timely ﬁled for an extension request to ﬁle her individual\\ntax return, and paid $300 of additional taxes. Krete’s year 1 tax liability was $16,500 when she\\ntimely ﬁled her return on April 30, year 2, and paid the remaining tax liability balance. What\\namount would be subject to the penalty for underpayment of estimated taxes?\\n(A) $0\\n(B) $500\\n(C) $1,650\\n(D) $16,500\\nFigure 61: A Professional Accounting example.\\nThe night before his bar examination, the examinee’s next-door neighbor was having a party. The\\nmusic from the neighbor’s home was so loud that the examinee couldn’t fall asleep. The examinee\\ncalled the neighbor and asked her to please keep the noise down. The neighbor then abruptly hung\\nup. Angered, the examinee went into his closet and got a gun. He went outside and ﬁred a bullet\\nthrough the neighbor’s living room window. Not intending to shoot anyone, the examinee ﬁred\\nhis gun at such an angle that the bullet would hit the ceiling. He merely wanted to cause some\\ndamage to the neighbor’s home to relieve his angry rage. The bullet, however, ricocheted off the\\nceiling and struck a partygoer in the back, killing him. The jurisdiction makes it a misdemeanor\\nto discharge a ﬁrearm in public. The examinee will most likely be found guilty for which of the\\nfollowing crimes in connection to the death of the partygoer?\\n(A) Murder.\\n(B) Involuntary manslaughter.\\n(C) V oluntary manslaughter.\\n(D) Discharge of a ﬁrearm in public.\\nFigure 62: A Professional Law example.\\n24', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6130bb06-68ba-4f09-8fd1-fb607388c726', embedding=None, metadata={'page_label': '25', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nA 63-year-old man is brought to the emergency department because of a 4-day history of in-\\ncreasingly severe left leg pain and swelling of his left calf. He also has a 1-month history of\\nincreasingly severe upper midthoracic back pain. During this time, he has had a 9-kg (20-lb)\\nweight loss despite no change in appetite. He has no history of major medical illness. His only\\nmedication is ibuprofen. He is 180 cm (5 ft 11 in) tall and weighs 82 kg (180 lb); BMI is 25\\nkg/m2 . His vital signs are within normal limits. On examination, lower extremity pulses are\\npalpable bilaterally. The remainder of the physical examination shows no abnormalities. An x-ray\\nof the thoracic spine shows no abnormalities. A CT scan of the abdomen shows a 3-cm mass in\\nthe body of the pancreas; there are liver metastases and encasement of the superior mesenteric\\nartery. Ultrasonography of the left lower extremity shows a femoropopliteal venous clot. Which\\nof the following is the most likely cause of this patient’s symptoms?\\n(A) Carcinoid syndrome\\n(B) Hypercoagulability from advanced malignancy\\n(C) Multiple endocrine neoplasia\\n(D) Splenic artery aneurysm and embolic disease of the left lower extremity\\nFigure 63: A Professional Medicine example.\\nThe technique that is most likely to produce an immediate improvement in the behavior of a child\\nwho hits others and rips up schoolbooks is\\n(A) a combination of reinforcement for appropriate behavior and mild punishment for in-\\nappropriate behavior\\n(B) differential positive reinforcement\\n(C) loss of privileges for misbehaving\\n(D) shaping\\nFigure 64: A Professional Psychology example.\\nYou work for a utility company that is building a biomass plant in the community. Your employer\\nasks you to give a series of community talks about the plant and future operations. You visit the\\nplant several hours before you are due to give a speech that has been prepared by your immediate\\nsupervisor. During the tour of the plant, you discover several claims in the speech are not true.\\nWhat do you do?\\n(A) Write and deliver a new speech that you know is entirely correct.\\n(B) Cancel all speeches until you and your supervisor can get the information straight.\\n(C) Deliver the speech as prepared and discuss the inaccuracies with your supervisor afterward.\\n(D) Address the inaccuracies with your supervisor immediately and make the necessary\\ncorrections before giving the speech.\\nFigure 65: A Public Relations example.\\n25', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0e8a34a5-8f47-4cc5-8a1b-9c2ce583ee26', embedding=None, metadata={'page_label': '26', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nThe Chemical Weapons Convention (CWC) prohibited the possession or deployment of chemical\\nweapons; however it failed to implement stipulations that would require signatories to declare their\\nexisting stocks of chemical weapons, to identify facilities that were once involved in chemical\\nproduction, or to announce when their existing stocks would be destroyed.\\n(A) The Chemical Weapons Convention (CWC) prohibited the possession or deployment of\\nchemical weapons; however it failed to implement stipulations that would require signatories to\\ndeclare their existing stocks of chemical weapons, to identify facilities that were once involved in\\nchemical production, or to announce when their existing stocks would be destroyed.\\n(B) The CWC made some important developments regarding the use and possession of chemical\\nweapons and the destruction of existing stockpiles. However, the treaty failed to establish an\\nindependent body empowered with the capacity to check treaty compliance. Lack of supra-state\\nauthority has undermined the ability to enforce those developments. Given the anarchical nature\\nof international society it may be in the national security interest to retain stocks.\\n(C) Chemical weapons continue to exert a determining inﬂuence on international society. As early\\nas the 1970s military strategists were convinced of the deterrence effects chemical weapons could\\nhave, comparable to the second strike survival logic of nuclear deterrence. The preferences of\\nstrategists resulted in continued manufacture and stockpiling of weapons creating an international\\ncrisis of stability.\\n(D) While the CWC has been ratiﬁed by the majority of international society, some nations\\nwith a large chemical capability at their disposal have yet to enter into the treaty. However,\\nto some analysts the destructive military potential would be limited, having a moderate\\neffect on a well-equipped army in conventional warfare. Chemical arsenal essentially falls\\nunder the category of the \"poor mans\" weaponry, being simplistic and inexpensive whilst\\nhaving limited military utility. However, the concern remains of the prospective impact a\\nterrorist chemical attack could have on civilian populations.\\nFigure 66: A Security Studies example.\\nWhich of the following statements most closely corresponds with differential association theory?\\n(A) If all of your friends jumped off a bridge, I suppose you would too.\\n(B) You should be proud to be a part of this organization.\\n(C) If the door is closed, try the window.\\n(D) Once a thief, always a thief.\\nFigure 67: A Sociology example.\\nWhy did Congress oppose Wilson’s proposal for the League of Nations?\\n(A) It feared the League would encourage Soviet inﬂuence in the US\\n(B) It feared the League would be anti-democratic\\n(C) It feared the League would commit the US to an international alliance\\n(D) Both a and b\\nFigure 68: A US Foreign Policy example.\\nAn observational study in diabetics assesses the role of an increased plasma ﬁbrinogen level on\\nthe risk of cardiac events. 130 diabetic patients are followed for 5 years to assess the development\\nof acute coronary syndrome. In the group of 60 patients with a normal baseline plasma ﬁbrinogen\\nlevel, 20 develop acute coronary syndrome and 40 do not. In the group of 70 patients with a high\\nbaseline plasma ﬁbrinogen level, 40 develop acute coronary syndrome and 30 do not. Which of\\nthe following is the best estimate of relative risk in patients with a high baseline plasma ﬁbrinogen\\nlevel compared to patients with a normal baseline plasma ﬁbrinogen level?\\n(A) (40/30)/(20/40)\\n(B) (40*40)/(20*30)\\n(C) (40*70)/(20*60)\\n(D) (40/70)/(20/60)\\nFigure 69: A Virology example.\\n26', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='61c0e254-51fe-4b99-a96b-0ad0c6a23249', embedding=None, metadata={'page_label': '27', 'file_name': 'MMLU.pdf', 'file_path': '/content/data/MMLU.pdf', 'file_type': 'application/pdf', 'file_size': 2074939, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Published as a conference paper at ICLR 2021\\nThe Great Cloud Sutra prophesied the imminent arrival of which person?\\n(A) Maitreya (Milo)\\n(B) The Buddha\\n(C) Zhou Dunyi\\n(D) Wang Yangming\\nFigure 70: A World Religions example.\\n27', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5b51bfeb-dddc-497c-bf7b-f2c4321ab18e', embedding=None, metadata={'page_label': '1', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ROUGE : A Package for Automatic Evaluation of Summaries  \\nChin -Yew Lin  \\nInformation Sciences Institute  \\nUniversity of Southern California  \\n4676 Admiralty Way  \\nMarina del Rey, CA  90292  \\ncyl@isi.edu  \\n \\nAbstract  \\nROUGE  stands for Recall -Oriented Unde rstudy for \\nGisting Evaluation. It includes  measures  to aut o-\\nmatically determine the quality of a summary by \\ncomparing it to other (ideal) summaries created by \\nhumans. The measure s count the number of ove r-\\nlapping  units such as n -gram, word sequences, and \\nword pairs  between the computer -generated su m-\\nmary to be evaluated and the ideal summaries cr e-\\nated by humans. This paper introduces four different \\nROUGE  measures: ROUGE -N, ROUGE -L, ROUGE -W, \\nand ROUGE -S included in the ROUGE  summariz a-\\ntion evalu ation package and their evaluatio ns. Three \\nof them have been used in the Document Unde r-\\nstanding Conference (DUC) 2004, a large -scale \\nsummar ization evaluation sponsored by NIST.  \\n1 Introduction  \\nTraditionally evaluation of summarization i nvolves \\nhuman judgment s of different quality metrics , for \\nexample, coherence, conciseness, grammaticality, \\nreadability, and content  (Mani , 2001) . However,  \\neven simple manual evaluation of summaries on a \\nlarge scale over a few lingui stic quality questions \\nand content coverage as in the Document Unde r-\\nstanding Con ference (DUC) (Over and Yen , 2003)  \\nwould require over 3 ,000 hours o f human e fforts. \\nThis is very ex pensive and difficult to co nduct in a \\nfrequent basis.  Therefore, how to evaluate summ a-\\nries automat ically has drawn a lot of attent ion in the \\nsummarization re search comm unity in recent years. \\nFor examp le, Sa ggion et al. (2002) proposed three  \\ncontent -based evaluation methods that mea sure \\nsimilarity between summ aries. These methods are:  \\ncosine similarity , unit overlap  (i.e. unigram or b i-\\ngram) , and longest common subsequence . However, \\nthey did not show how the r esults of these automatic \\nevaluation methods correlate to human judgments. \\nFollowing t he success ful applic ation of automatic \\nevaluation  method s, such as BLEU  (Papineni et al. , \\n2001), in machine translation e valuation, Lin and \\nHovy (2003 ) showed that methods similar to BLEU , i.e. n-gram  co-occurrence stati stics, could  be applied \\nto evalua te summaries.  In this paper, we introduce a \\npackage , ROUGE , for automatic evaluation of su m-\\nmaries  and its evaluation s. ROUGE  stands for R e-\\ncall-Oriented Understudy for Gisting Evaluation . It \\nincludes several automatic evalu ation methods  that \\nmeasure the similarity between summaries.  We d e-\\nscribe ROUGE -N in Section 2, ROUGE -L in Section \\n3, ROUGE -W in Section 4, and ROUGE -S in Sect ion \\n5. Section 6 show s how these measures correlate \\nwith human jud gments using DUC 2001, 2002, and \\n2003 data . Section 7 conclude s this paper and di s-\\ncusses future dire ctions. \\n2 ROUGE -N: N -gram Co -Occurrence St atistics  \\nFormally, ROUGE -N is an n -gram recall b etween a \\ncandidate summary and a set of reference summ a-\\nries. ROUGE -N is computed as follows:  \\n \\nROUGE -N \\n∑ ∑∑ ∑\\n∈ ∈∈ ∈\\n=\\n} {} {\\n) () (\\nSummaries ReferenceS S gramSummaries ReferemceS S grammatch\\nnnnn\\ngram Countgram Count\\n (1) \\n \\nWhere n stands for the length of the n -gram, \\ngram n, and Count match (gram n) is the maximum nu m-\\nber of n -grams co -occurring in a ca ndidate summary \\nand a set of reference summaries.  \\nIt is clear that ROUGE -N is a recall -related mea s-\\nure because the denominator of the equation is the \\ntotal sum of the number of n -grams occu rring at the \\nreference summary side. A closely related measure, \\nBLEU, used in automatic evalu ation of machine \\ntranslation, is a precision -based measure. BLEU \\nmeasures how well a candidate translation matches \\na set of reference translations by counting the pe r-\\ncentage of n -grams in the candidate translation ove r-\\nlapping wit h the refe rences. Please  see Papineni et \\nal. (2001) for d etails about BLEU . \\nNote that the number of n -grams in the denomin a-\\ntor of the ROUGE -N formula increases as we add \\nmore references. This is intuitive and reasonable \\nbecause there might exist multiple g ood summ aries. ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3a95a311-c298-4d79-8abf-9243cafab8bd', embedding=None, metadata={'page_label': '2', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Every time we add a reference into the pool, we e x-\\npand the space of alternative summaries. By co n-\\ntrolling what types of references we add to the \\nreference pool, we can design evaluations that f ocus \\non diffe rent aspects of summarization. Also  note \\nthat the numerator sums over all reference summ a-\\nries. This effe ctively gives more weight to matching \\nn-grams occurring in multiple references. Therefore \\na cand idate summary that contains words shared by \\nmore references is favored by the ROUGE -N mea s-\\nure. This is again very intuitive and reasonable b e-\\ncause we normally prefer a candidate summary that \\nis more similar to consensus among reference su m-\\nmaries.  \\n2.1 Multiple References  \\nSo far, we only demonstrated how to compute \\nROUGE -N using a single reference. Wh en mult iple \\nreferences are used, we compute pairwise su mmary -\\nlevel ROUGE -N between a candidate su mmary s and \\nevery reference, ri, in the refe rence set. We then \\ntake the maximum of pairwise summary -level \\nROUGE -N scores as the final multiple refe rence \\nROUGE -N score. This can be written as fo llows:  \\n \\nROUGE -Nmulti  = argmax i ROUGE -N(ri,s)  \\n \\nThis procedure is also applied to computation of \\nROUGE -L (Section 3), ROUGE -W (Section 4) , and \\nROUGE -S (Section 5).  In the implementation, we use \\na Jackknifing procedure. Giv en M refe rences, we \\ncompute the best score over M sets of M -1 refe r-\\nences. The final ROUGE -N score is the average of \\nthe M  ROUGE -N scores using different M -1 refe r-\\nences.  The Jac kknifing procedure is adopted since \\nwe often need to compare system and human p er-\\nformance and the reference su mmaries are usually \\nthe only h uman summaries available. Using this \\nprocedure, we are able to estimate average human \\nperformance by avera ging M  ROUGE -N scores of \\none refe rence vs. the rest M -1 references. Although \\nthe Jackknif ing procedure is not necessary when we \\njust want to compute ROUGE  scores using mu ltiple \\nreferences, it is applied in all ROUGE  score comp u-\\ntations in the ROUGE  evaluation package.  \\nIn the next section, we describe a ROUGE  measure \\nbased on longest common subs equences b etween \\ntwo summaries.  \\n3 ROUGE -L: Longest Common Subs equence  \\nA sequence Z = [z1, z2, ..., z n] is a subsequence of \\nanother sequence X = [x1, x2, ..., x m], if there exists a \\nstrict increasing sequence [ i1, i2, ..., i k] of indices of \\nX such that for a ll j = 1, 2, ..., k , we have xij = zj  \\n(Cormen et al. , 1989). Given two s equences X and \\nY, the longest common subs equence (LCS) of X and Y is a common subsequence with maximum length. \\nLCS has been used in identifying cognate cand i-\\ndates during construction of N-best translation lex i-\\ncon from parallel text. Melamed (1995) used the \\nratio (LCSR) between the length of the LCS of two \\nwords and the length of the longer word of the two \\nwords to measure the cognateness between them. \\nHe used LCS as an a pproximate stri ng matching \\nalgorithm. Saggion et al. (2002) used normalized \\npairwise LCS to compare simila rity between two \\ntexts in aut omatic summarization evaluation.   \\n3.1 Sentence -Level LCS  \\nTo apply LCS in summarization evaluation, we \\nview a summary sentence as a sequence of words. \\nThe intuition is that the longer the LCS of two \\nsummary sentences is, the more similar the two \\nsumm aries are. We propose using LCS -based F -\\nmeasure to estimate the similarity b etween two \\nsummaries X of length m and Y of length  n, assu m-\\ning X is a r eference summary sentence and Y is a \\ncandidate summary sentence, as fo llows:  \\n \\nRlcs \\nmYX LCS ),(=       (2 ) \\nPlcs \\nnYX LCS ),(=       (3 ) \\nFlcs  \\nlcs lcslcs lcs\\nP RPR\\n22) 1(\\nbb\\n++= (4) \\n \\nWhere LCS(X,Y) is the length of a longest co m-\\nmon subsequence of X and Y, and ß = Plcs/Rlcs when \\n?Flcs/?Rlcs_=_?Flcs/?Plcs.  In DUC, ß is set to a very \\nbig number ( ? 8) . Therefore, only Rlcs is consi d-\\nered. We call the LCS -based F -measure, i.e. Equ a-\\ntion 4 , ROUGE -L. Notice that ROUGE -L is 1 when X \\n= Y; while ROUGE -L is zero when LCS(X,Y) = 0, i.e. \\nthere is nothing in common b etween X and Y. F-\\nmeasure or its equiv alents has been shown to have \\nmet several theoretical criteria in measuring acc u-\\nracy involving more than one factor (Van Rijsbe r-\\ngen, 1979). The composite fa ctors are LCS -based \\nrecall and pr ecision in this case. Melamed et al. \\n(2003) used unigram F -measure to estimate m achine \\ntranslation quality and showed that un igram F -\\nmeasure was as good as BLEU .  \\nOne advantage of using LCS is that it does not r e-\\nquire consecutive matches but i n-sequence matches \\nthat reflect sentence level word order as n -grams. \\nThe other advantage is that it automatically i ncludes \\nlongest in -sequence common n -grams, therefore no \\npredefined n -gram length is necessary.  \\nROUGE -L as defined in Equation 4 has the pr op-\\nerty that its value is less than or equal to the min i-\\nmum of unigram F -measure of X and Y. Unigram ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ba82bb33-10eb-4a66-a181-a35027289652', embedding=None, metadata={'page_label': '3', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='recall reflects the proportion of words in X (refe r-\\nence summary sentence) that are also present in Y \\n(candidate summary sentence); while unigram pr e-\\ncision i s the proportion of words in Y that are also in \\nX. Unigram recall and precision count all co -\\noccurring words regardless their orders; while \\nROUGE -L counts only in -sequence co -occurrences.  \\nBy only awarding credit to in -sequence un igram \\nmatches, ROUGE -L als o captures sentence level \\nstructure in a natural way. Consider the fo llowing \\nexample:  \\n \\nS1. police killed the gunman  \\nS2. police  kill the gu nman \\nS3. the gunman  kill p olice \\n \\nWe only consider ROUGE -2, i.e. N=2, for the pu r-\\npose of explanation. Using S1 as the refe rence and  \\nS2 and S3 as the candidate summary se ntences , S2 \\nand S3 would have the same ROUGE -2 score, since \\nthey bot h have one bigram, i.e. “the gunman”.  How-\\never, S2 and S3 have very different meanings.  In the \\ncase of ROUGE -L, S2 has a score of 3/4 = 0.75 and \\nS3 has  a score of 2/4 = 0.5, with ß = 1. Ther efore S2 \\nis better than S3 according to ROUGE -L. This exa m-\\nple also illustrated that ROUGE -L can work reli ably \\nat sentence level.  \\nHowever, LCS suffers one disadvantage that it \\nonly counts the main in -sequence words; ther efore, \\nother alternative L CSes and shorter s equences are \\nnot reflected in the final score. For example, given \\nthe follo wing candidate sentence:  \\nS4. the gunman  police killed  \\nUsing S1 as its reference, LCS counts either “the \\ngunman” or “p olice killed”, but not both; therefore, \\nS4 has the  same ROUGE -L score as S3. ROUGE -2 \\nwould prefer S4 than S3.  \\n3.2 Summary -Level LCS  \\nPrevious section described how to compute se n-\\ntence -level LCS -based F -measure score. When a p-\\nplying to summary -level, we take the union LCS \\nmatches between a reference su mmary sent ence, ri, \\nand every candidate summary  sentence, cj. Given a \\nreference summary of u sentences containing a total \\nof m words and a candidate  summary of v sentences \\ncontaining a total of n word s, the su mmary -level \\nLCS-based F -measure can be computed as follow s: \\nRlcs mCr LCSu\\nii ∑=∪\\n=1),(\\n      (5)  \\nPlcs nCr LCSu\\nii ∑=∪\\n=1),(\\n      (6)  Flcs  \\nlcs lcslcs lcs\\nP RPR\\n22) 1(\\nbb\\n++=    (7)  \\n \\nAgain ß is set to a very big number ( ? 8)  in \\nDUC , i.e. only Rlcs is considered.  ),(Cr LCSi ∪is the \\nLCS score of the union  longest common subs e-\\nquence between reference sentence ri and cand idate \\nsummary C. For example, if ri = w1 w2 w3 w4 w5, and \\nC cont ains two sentences:  c1 = w1 w2 w6 w7 w8 and c2 \\n= w1 w3 w8 w9 w5, then the longest common subs e-\\nquence  of ri and c1 is “w1 w2” and the longest co m-\\nmon subsequence  of ri and c2 is “w1 w3 w5”. The \\nunion longest common subsequence  of ri, c1, and c2 \\nis “w1 w2 w3 w5” and ),(Cr LCSi ∪= 4/5.  \\n3.3 ROUGE -L vs. Normalized Pairwise LCS  \\nThe normalized pairwise LCS proposed by Radev et \\nal. (page 51, 2002) between two summ aries S1 and \\nS2, LCS(S 1 ,S2)MEAD , is written as fo llows:  \\n \\n∑ ∑∑ ∑\\n∈ ∈∈ ∈∈ ∈\\n++\\n1 21 21 2\\n)( )(),( max ),( max\\nSs S sj iSs S sj i Ss j i Ss\\ni ji ji j\\ns length s lengthss LCS ss LCS (8) \\n \\nAssuming S1 has m words and S2 has n words, \\nEquation 8 can be rewritten as Equation 9 due to \\nsymmetry:  \\n \\nnmss LCSSsj i Ssij\\n+∑∈∈12),( max *2\\n                       (9) \\n \\nWe then define MEAD LCS recall ( Rlcs-MEAD ) and \\nMEAD LCS precision ( Plcs-MEAD ) as follows:  \\n \\n Rlcs-MEAD  mss LCSSsj i Ssij∑∈∈\\n=12),( max\\n      (10)  \\nPlcs-MEAD  nss LCSSsj i Ssij∑∈∈\\n=12),( max\\n       (11) \\n \\nWe can rewrite Equation (9) in terms of Rlcs-MEAD  \\nand Plcs-MEAD  with a constant parameter ß = 1 as fo l-\\nlows:  \\nLCS(S 1 ,S2)MEAD  \\nMEAD lcs MEAD lcsMEADlcs MEADlcs\\nP RP R\\n− −− −\\n++=22) 1(\\nbb (12) \\nEquation 12 shows that normalized pairwise LCS \\nas defined in Radev et al. (2002) and impl emented \\nin MEAD is also a F -measure with ß = 1. Sentence -\\nlevel normalized pairwise LCS is the same as \\nROUGE -L with ß = 1. Besides setting ß = 1, su m-\\nmary -level normalized pairwise LCS is di fferent \\nfrom ROUGE -L in how a sentence gets its LCS score \\nfrom its references. Normalized pai rwise LCS takes ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='145f5c0a-fde6-4629-a106-1559d66c6262', embedding=None, metadata={'page_label': '4', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='the best LCS score while ROUGE -L takes the union \\nLCS score.  \\n4 ROUGE -W: Weighted Longest Common Su b-\\nsequence  \\nLCS has many nice properties as we have d escribed \\nin the previous sections. Unfortunately, the basic \\nLCS also has a problem that it does not di fferentiate \\nLCSes of different spatial relations within their e m-\\nbeddin g sequences. For example, given a reference \\nsequence X and two candidate sequences Y1 and Y2 \\nas follows:  \\n \\nX:  [A B C D E F G]  \\nY1: [A B C D H I K]  \\nY2:  [A H B K C I D] \\n \\nY1 and Y2 have the same ROUGE -L score. Ho w-\\never, in this case, Y1 should be the better ch oice than \\nY2 because Y1 has consecutive matches. To improve \\nthe basic LCS method, we can simply r emember the \\nlength of consecutive matches encou ntered so far to \\na regular two dimensional dynamic program table \\ncomputing LCS. We call this weighted LCS \\n(WLCS)  and use k to indicate the length of the cu r-\\nrent consecutive matches ending at words xi and yj. \\nGiven two se ntences X and Y, the WLCS score of X \\nand Y can be computed using the following dynamic \\nprogramming procedur e: \\n \\n(1) For ( i = 0; i <=m; i++) \\n        c(i,j) = 0  // initialize c -table  \\n        w(i,j) = 0 // initialize w -table  \\n(2) For ( i = 1; i <= m; i++) \\n        For (j = 1; j <= n; j++) \\n          If xi = yj Then  \\n     // the length of consecutive matches at  \\n     // position i -1 and j -1 \\n     k = w(i-1,j-1) \\n     c(i,j) = c(i-1,j-1) + f(k+1) – f(k) \\n     // remember the length of consecutive  \\n     // matches at position i, j  \\n     w(i,j) = k+1 \\n          Otherwise  \\n     If c(i-1,j) > c(i,j-1) Then  \\n    c(i,j) = c(i-1,j) \\n    w(i,j) = 0           // no match at i , j \\n     Else c(i,j) = c(i,j-1) \\n     w(i,j) = 0           // no match at  i, j \\n(3) WLCS (X,Y) = c(m,n) \\n \\nWhere c is the dynamic programming table, c(i,j) \\nstores the WLCS score ending at word xi of X and yj \\nof Y, w is the table storing the length of consec utive \\nmatches ended at c table position i and j, and f is a \\nfunction of consecutive matches at the table pos i-tion, c(i,j). Notice that by providing di fferent \\nweighting function f, we can parameterize the \\nWLCS algorithm to assign different credit to co n-\\nsecutive in -sequence matches.  \\nThe weighting function f must have the pro perty \\nthat f(x+y) > f(x) + f(y) for any positive int egers x \\nand y. In other words, co nsecutive matches are \\nawarded more scores than non -consecutive matches. \\nFor e xample, f(k)-=-ak – b when  k >= 0,  and a, b > \\n0. This function charges a gap pe nalty of –b for \\neach non -consecutive n -gram sequences. Another \\npossible fun ction family is the polynomial family of \\nthe form ka where -a > 1. However, in order to \\nnorma lize the final ROUGE -W score, we also prefe r \\nto have a function that has a close form inverse \\nfunction. For example, f(k)-=-k2 has a close form \\ninverse function f -1(k)-=-k1/2. F-measure based on \\nWLCS can be computed as follows, given two s e-\\nquences X of length m and Y of length n: \\nRwlcs  \\uf8f7\\uf8f7\\n\\uf8f8\\uf8f6\\n\\uf8ec\\uf8ec\\n\\uf8ed\\uf8eb=−\\n)(),( 1\\nmfYX WLCSf       (13)  \\nPwlcs  \\uf8f7\\uf8f7\\n\\uf8f8\\uf8f6\\n\\uf8ec\\uf8ec\\n\\uf8ed\\uf8eb=−\\n)(),( 1\\nnfYX WLCSf       (14)  \\nFwlcs  \\nwlcs wlcswlcs wlcs\\nP RPR\\n22) 1(\\nbb\\n++=           (15)  \\n \\nWhere f -1 is the inverse function of f. In DUC, ß is \\nset to a very big number ( ? 8) . Ther efore, only \\nRwlcs  is co nsidered. We call the WLCS -based F -\\nmeasure, i.e. Equation 15, ROUGE -W. Using Equ a-\\ntion 15 and f(k)-=-k2 as the weighting fun ction, the \\nROUGE -W scores for s equences Y1 and Y2 are 0.571 \\nand 0.286  respe ctively. Therefore, Y1 would be \\nranked higher than Y2 using WLCS. We use the \\npolynomial fun ction of the form ka in the ROUGE  \\nevaluation package. In the next section, we intr o-\\nduce the skip -bigram co -occurrence stati stics. \\n5 ROUGE -S: Skip -Bigram Co -Occur rence St a-\\ntistics  \\nSkip-bigram is any pair of words in their se ntence \\norder, allowing for arbitrary gaps. Skip -bigram co -\\noccurrence statistics measure the ove rlap of skip -\\nbigrams between a candidate transl ation and a set of \\nreference translations. Using the example given in \\nSection 3.1:  \\n \\nS1. police killed the gu nman \\nS2. police kill the gu nman \\nS3. the gunman kill p olice \\nS4. the gunman police killed  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a06afa0b-113e-4f6e-b6ba-e312acdcb9c4', embedding=None, metadata={'page_label': '5', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='each sentence has C(4,2)1 = 6 skip -bigrams. For e x-\\nample, S1 has the following skip -bigrams:  \\n(“police killed ”, “police the ”, “police gunman ”, \\n“killed the ”, “killed gunman ”, “the gu nman”)  \\nS2 has three skip -bigram matches with S1 (“ po-\\nlice the ”, “police gunman ”, “the gunman ”), S3 has \\none skip -bigram match with S1 (“ the gu nman”), and \\nS4 has two skip -bigram matches with S1 (“ police \\nkilled”, “the gunman ”).  Given tran slations X of \\nlength m and Y of length  n, assuming X is a refe r-\\nence translation and Y is a candidate translation, we \\ncompute skip -bigram -based F -measure as fo llows:  \\nRskip2  \\n)2,(),(2\\nmCYX SKIP=           (16)  \\nPskip2  \\n)2,(),(2\\nnCYX SKIP=           (17)  \\nFskip2  \\n22\\n22 22\\n) 1(\\nskip skipskip skip\\nP RP R\\nbb\\n++=   (18)  \\n \\nWhere SKIP2 (X,Y) is the number of skip -bigram \\nmatches between X and Y, ß controlling the relative \\nimportance of  Pskip2  and Rskip2 , and  C is the comb i-\\nnation fun ction. We call the skip -bigram -based F -\\nmeasure, i.e. Equ ation 18, ROUGE -S. \\nUsing Equation 18 with ß = 1 and S1 as the ref er-\\nence, S2’s ROUGE -S score is 0.5, S3 is 0.167 , and \\nS4 is 0.333. Therefore, S2 is better than S3 and S4, \\nand S4 is better than S3. This result is more intu itive \\nthan using BLEU -2 and ROUGE -L. One adva ntage of \\nskip-bigram vs. BLEU  is that it does not require co n-\\nsecutive matches but is still sens itive t o word order. \\nComparing skip -bigram with LCS, skip -bigram \\ncounts all in -order matching word pairs while LCS \\nonly counts one longest common subs equence.  \\nApplying skip -bigram without any constraint on \\nthe distance between the words, spurious matches \\nsuch as “the the ” or “ of in ” might be counted as \\nvalid matches. To reduce these spur ious matches, \\nwe can limit the maximum skip distance, dskip, be-\\ntween two in -order words that is allowed to form a \\nskip-bigram. For exa mple, if we set dskip to 0 then \\nROUGE -S is equ ivalent to bigram overlap F -\\nmeasure. If we set dskip to 4 then only word pairs of \\nat most 4 words apart can form skip -bigrams.  \\nAdjusting Equations 16, 17, and 18 to use max i-\\nmum skip distance limit is straightforward: we only \\ncount the skip -bigram matches, SKIP2 (X,Y), within \\nthe maximum skip distance and replace denomin a-\\ntors of Equations 16, C(m,2), and 17, C(n,2), with \\nthe actual numbers of within distance skip -bigrams \\nfrom the reference and the candidate respe ctively.  \\n \\n                                                                 \\n1 C(4,2) = 4!/(2!*2!) = 6.  5.1 ROUGE -SU: Extension  of ROUGE -S \\nOne po tential problem for ROUGE -S is that it does \\nnot give any credit to a candidate sentence if the \\nsentence does not have any word pair co -occurring \\nwith its references.  For example, the following se n-\\ntence  has a ROUGE -S score of zero : \\n \\nS5. gunman the killed police  \\n \\nS5 is the exact reverse of S1 and there is no skip \\nbigram match between them.  However, we would \\nlike to differentiate sentences similar to S5 from \\nsentences that do not have single word co-\\noccurrence with S1.  To achieve this, we extend \\nROUGE -S with the addition of  unigram as counting \\nunit. The extended version is called ROUGE -SU. We \\ncan also obtain  ROUGE -SU from ROUGE -S by add-\\ning a b egin-of-sentence marker at the beginning  of \\ncandidate and reference  sentences.  \\n6 Evaluations of ROUGE  \\nTo assess the effectiven ess of ROUGE  measures, we \\ncomp ute the correlation between ROUGE  assigned \\nsummary scores and human assigned su mmary \\nscores.  The intuition is that a good evaluation mea s-\\nure should assign a good score to a good summary  \\nand a bad score  to a bad su mmary. The gr ound truth \\nis based on human assigned scores.  Acquiring h u-\\nman judgments are usually very expensive; fort u-\\nnately, w e have DUC 2001, 2002, and 2003 \\nevaluation data  that include  human judgment s for \\nthe fo llowing : \\n• Single  document summaries of about 100 \\nwords : 12 systems 2 for DUC 2001 and 14 sy s-\\ntems for 2002. 149 single docu ment summaries \\nwere judged  per system in  DUC  2001 and 295 \\nwere judged in DUC 2002 . \\n• Single document very short summaries of about \\n10 words (headline -like, keywords, or phrases) : \\n14 systems for  DUC 2003 . 624 very short su m-\\nmaries were judged per system in DUC 2003.  \\n• Multi -document summaries of about 10 words: \\n6 systems for DUC 2002 ; 50 words: 14 sy stems \\nfor DUC 2001 and 10 systems for DUC 2002; \\n100 words: 14 systems for DUC 2001, 10 sys-\\ntems for DU C 2002, and 18 systems for DUC \\n2003; 200 words: 14 systems for DUC 2001 and \\n10 systems for DUC 2002 ; 400 words: 14 sy s-\\ntems for  DUC 2001 . 29 summ aries were judged \\nper system per summary size in DUC 2001, 59 \\nwere judged in DUC 2002, and 30 were judged \\nin DUC  2003.  \\n                                                                 \\n2 All systems includ e 1 or 2 baselines. Please see DUC \\nwebsite for details.  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='577a6f4f-d283-42aa-afa1-59cccc6708d9', embedding=None, metadata={'page_label': '6', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Besides these human judgments, we also have 3 sets \\nof manual summaries for DUC 2001, 2 sets for \\nDUC 2002, and 4 sets for DUC 2003.  Human \\njudges assigned content coverage scores to a cand i-\\ndate summary by examining the percentage of co n-\\ntent overlap be tween a manual summary unit, i.e. \\nelementary discourse unit or sentence, and the ca n-\\ndidat e summary using Summary Evaluation Env i-\\nronment 3 (SEE) developed by  the Un iversity of \\nSouthern California’s Information Sciences I nstitute  \\n(ISI). The overall candidate  summary score is the \\naverage of the content co verage score s of all the \\nunits in the  manual su mmary.  Note that human \\njudges used only one manual summary in all the \\nevaluations although multiple alternative summ aries \\nwere available.  \\nWith the DUC data, we computed Pearson’s \\nproduct moment correlation coefficient s, Spea r-\\nman’s rank order correlation coefficient s, and \\nKendall’s correlation coefficient s between systems’ \\naverage  ROUGE  scores an d their human a ssigned \\naverage coverage scores using single reference  and \\nmultiple references.  To investigate the effect of \\nstemming and inclusion or exclusion of stopwords, \\nwe also ran experiments over orig inal automatic  and \\n                                                                 \\n3 SEE is available online at http://www.isi.edu/~cyl.  manual summaries (CASE  set), stemmed 4 version of \\nthe summaries (STEM  set), and stopped  version of \\nthe summaries (STOP set). For example, we co m-\\nputed ROUGE  scores for the 12 sy stems participated \\nin the DUC 2001 single document summarization \\nevaluation using the CASE set with single refe rence \\nand then calculated the three correl ation scores for \\nthese 12 s ystems’ ROUGE  scores vs. human assigned \\naverage cove rage scores.  After that w e repeated the \\nprocess us ing multiple refe rences and then using \\nSTEM and STOP sets.  Therefore, 2 (multi or single) \\nx 3 (CASE, STEM, or STOP) x 3 (Pearson, Spea r-\\nman, or Kendall) = 18 data points were c ollected for \\neach ROUGE  measure and each DUC task.  To assess \\nthe significance of the results, we applied bootstrap \\nresampling technique (Davison and Hinkley , 1997) \\nto estimate 95% confidence intervals for every co r-\\nrelation computation . \\n17 ROUGE  measures were tested for each run  us-\\ning ROUGE  evaluation package v1.2.1 : ROUGE -N  \\nwith N = 1 to 9, R OUGE-L, ROUGE -W with \\nweighting factor a  = 1.2, ROUGE -S and ROUGE -SU \\nwith max imum skip distance  dskip = 1, 4, and 9.  Due \\nto limitation of space, we  only report correlation \\nanalysis results based on Pearson’s co rrelation coe f-\\nficient.  Correlation analyses based on Spea rman’s \\nand Kendall’s corr elation coefficients are tracking \\nPearson’s very closely and will be posted later at the \\nROUGE  website 5 for ref erence.  The critical value 6 \\nfor Pearson’s correl ation is 0.632  at 95% confidence  \\nwith 8 degrees of fre edom.  \\nTable 1 shows the Pearson’s correlation coeff i-\\ncients of the 17 ROUGE  measures vs. human judg-\\nments on DUC 2001 and 2002 100 word s single \\ndocument sum marization data . The best values in \\neach column are marked with dark  (green) color and \\nstatistically equivalent values to the best va lues are \\nmark ed with gray.  We found that correl ations were \\nnot affected by stemming or removal of stopwords  \\nin this data se t, ROUGE -2 performed be tter among \\nthe ROUGE -N variants, ROUGE -L, ROUGE -W, and \\nROUGE -S were all performing well, and using mu l-\\ntiple references improved pe rformance though not \\nmuch.  All ROUGE  measures achieved very good \\ncorrelation with human jud gments in th e DUC 2002 \\ndata. This might due to the double sa mple size in \\nDUC 2002 (295 vs. 149 in DUC 2001) for each sy s-\\ntem. \\nTable 2  shows the cor relation analysis results on \\nthe DUC 2003 single document very short su mmary  \\ndata.  We found that ROUGE -1, ROUGE -L, ROUGE -\\n                                                                 \\n4 Porter’s stemmer was used.  \\n5 ROUGE  website: http://www.isi.edu/~cyl/ROUGE.  \\n6 The critical  values for Pearson’s correlation at 95% \\nconfidence wit h 10, 12, 14, and 16 degrees of freedom \\nare 0.576, 0.532, 0.497, and 0.468 respe ctively.  Method CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP\\nR-1 0.76 0.76 0.84 0.80 0.78 0.84 0.98 0.98 0.99 0.98 0.98 0.99\\nR-2 0.84 0.84 0.83 0.87 0.87 0.86 0.99 0.99 0.99 0.99 0.99 0.99\\nR-3 0.82 0.83 0.80 0.86 0.86 0.85 0.99 0.99 0.99 0.99 0.99 0.99\\nR-4 0.81 0.81 0.77 0.84 0.84 0.83 0.99 0.99 0.98 0.99 0.99 0.99\\nR-5 0.79 0.79 0.75 0.83 0.83 0.81 0.99 0.99 0.98 0.99 0.99 0.98\\nR-6 0.76 0.77 0.71 0.81 0.81 0.79 0.98 0.99 0.97 0.99 0.99 0.98\\nR-7 0.73 0.74 0.65 0.79 0.80 0.76 0.98 0.98 0.97 0.99 0.99 0.97\\nR-8 0.69 0.71 0.61 0.78 0.78 0.72 0.98 0.98 0.96 0.99 0.99 0.97\\nR-9 0.65 0.67 0.59 0.76 0.76 0.69 0.97 0.97 0.95 0.98 0.98 0.96\\nR-L 0.83 0.83 0.83 0.86 0.86 0.86 0.99 0.99 0.99 0.99 0.99 0.99\\nR-S* 0.74 0.74 0.80 0.78 0.77 0.82 0.98 0.98 0.98 0.98 0.97 0.98\\nR-S4 0.84 0.85 0.84 0.87 0.88 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-S9 0.84 0.85 0.84 0.87 0.88 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-SU* 0.74 0.74 0.81 0.78 0.77 0.83 0.98 0.98 0.98 0.98 0.98 0.98\\nR-SU4 0.84 0.84 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-SU9 0.84 0.84 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-W-1.2 0.85 0.85 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99DUC 2001 100 WORDS SINGLE DOC DUC 2002 100 WORDS SINGLE DOC\\n1 REF 3 REFS 1 REF 2 REFS\\nTable  1: Pearson’s correlations of 17 ROUGE\\nmeasure scores vs. human judgments for the DUC \\n2001 and 2002 100 words single documen t sum-\\nmariz ation tasks  \\n1 REF 4REFS 1 REF 4 REFS 1 REF 4 REFS\\nMethod\\nR-1 0.96 0.95 0.95 0.95 0.90 0.90\\nR-2 0.75 0.76 0.75 0.75 0.76 0.77\\nR-3 0.71 0.70 0.70 0.68 0.73 0.70\\nR-4 0.64 0.65 0.62 0.63 0.69 0.66\\nR-5 0.62 0.64 0.60 0.63 0.63 0.60\\nR-6 0.57 0.62 0.55 0.61 0.46 0.54\\nR-7 0.56 0.56 0.58 0.60 0.46 0.44\\nR-8 0.55 0.53 0.54 0.55 0.00 0.24\\nR-9 0.51 0.47 0.51 0.49 0.00 0.14\\nR-L 0.97 0.96 0.97 0.96 0.97 0.96\\nR-S* 0.89 0.87 0.88 0.85 0.95 0.92\\nR-S4 0.88 0.89 0.88 0.88 0.95 0.96\\nR-S9 0.92 0.92 0.92 0.91 0.97 0.95\\nR-SU* 0.93 0.90 0.91 0.89 0.96 0.94\\nR-SU4 0.97 0.96 0.96 0.95 0.98 0.97\\nR-SU9 0.97 0.95 0.96 0.94 0.97 0.95\\nR-W-1.2 0.96 0.96 0.96 0.96 0.96 0.96DUC 2003 10 WORDS SINGLE DOC\\nCASE STEM STOP\\nTable 2 : Pearson’s correlations of 17 ROUGE\\nmeasure scores vs. human judgments for the D UC \\n2003 very short summary task  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='12c12094-7543-4d8b-9ee8-399bd729352a', embedding=None, metadata={'page_label': '7', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='SU4 and 9, and ROUGE -W were very good measures  \\nin this cat egory, ROUGE -N with N > 1 performed \\nsignificantly worse than all other measures, and e x-\\nclusion of stopwords improved performance in ge n-\\neral except for ROUGE -1. Due to the large number \\nof samples (624 ) in this data set, using multiple re f-\\nerences did not improve correl ations.  \\nIn Table 3 A1, A2, and A3, we show correlation \\nanalysis results on DUC 2001, 2002, and 2003 100 \\nwords multi -document summarization data.  The \\nresults indicated that using multiple r eferences i m-\\nproved correlation and exclusion of stopwords us u-\\nally improved performance. ROUGE -1, 2, and 3 \\nperformed fine but were not consistent.  ROUGE -1, \\nROUGE -S4, ROUGE -SU4, ROUGE -S9, and ROUGE -\\nSU9 with stopword r emoval ha d correlation above \\n0.70. ROUGE -L and ROUGE -W did not work well in \\nthis set of data.  \\nTable 3 C, D1, D2, E1, E2, and F show  the corr e-\\nlation analyses using  multiple refe rences on the rest \\nof DUC data.  These results again suggested that \\nexclusion of stopwords achieved better pe rformance \\nespecially in multi -document summaries of 50 \\nwords.  Better correlations (> 0.70) were o bserved \\non long summary tasks, i.e. 200 and 400 words \\nsummaries.  The relative performance of ROUGE  \\nmeasures followed the pa ttern of the 100 words \\nmulti -document summarizat ion task.  \\nComparing the results in Table 3 with Table s 1 \\nand 2, we found that correlation values in the multi -\\ndocument tasks rarely reached high 90% e xcept in \\nlong summary tasks.  One possible explan ation of \\nthis outcome is that we did not have large  amoun t of \\nsamples for the multi -document task s. In the single \\ndocument summariz ation tasks we had over 100 samples; while we only had about 30 sam ples in the \\nmulti -document tasks.  The only task s that had over \\n30 samples was from DUC 2002 and the correl a-\\ntions of  ROUGE  measures with human judgments on \\nthe 100 words summary task were much better and \\nmore stable than similar tasks in DUC 2001 and \\n2003.  Statistically stable human judgments of sy s-\\ntem pe rformance might not be obtained due to lack \\nof samples  and this in  turn caused instability  of co r-\\nrelation analyses.  \\n7 Conclusions  \\nIn this paper , we introduced ROUGE , an automatic \\nevaluatio n package for summarization, and co n-\\nducted comprehensive evaluations of the automatic \\nmeasures included in the ROUGE  package using \\nthree  years of DUC data.  To check the significance \\nof the results, we estimated co nfidence intervals of \\ncorrelations using bootstrap resampling. We found \\nthat (1) ROUGE -2, ROUGE -L, ROUGE -W, and \\nROUGE -S worked well in single document summ a-\\nrization tasks,  (2) ROUGE-1, ROUGE -L, ROUGE -W, \\nROUGE -SU4, and ROUGE -SU9 performed great in \\nevalua ting very short summaries (or headline -like \\nsumm aries), (3) correlation of high 90% was hard to \\nachieve for multi -document summarization task s but \\nROUGE -1, ROUGE -2, ROUGE -S4, ROUGE -S9, \\nROUGE -SU4, and ROUGE -SU9 worked reason ably \\nwell when stopwords were exc luded from matc hing, \\n(4) exclusion of  stopwords usually improved corr e-\\nlation, and (5) correlations to human jud gments \\nwere increased by using multiple references.  \\nIn summary, we sho wed that the ROUGE  package \\ncould be used effectively in automatic evalu ation of \\nsummaries.  In a separate study (Lin and Och , 2004), Method CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP\\nR-1 0.48 0.56 0.86 0.53 0.57 0.87 0.66 0.66 0.77 0.71 0.71 0.78 0.58 0.57 0.71 0.58 0.57 0.71\\nR-2 0.55 0.57 0.64 0.59 0.61 0.71 0.83 0.83 0.80 0.88 0.87 0.85 0.69 0.67 0.71 0.79 0.79 0.81\\nR-3 0.46 0.45 0.47 0.53 0.53 0.55 0.85 0.84 0.76 0.89 0.88 0.83 0.54 0.51 0.48 0.76 0.75 0.74\\nR-4 0.39 0.39 0.43 0.48 0.49 0.47 0.80 0.80 0.63 0.83 0.82 0.75 0.37 0.36 0.36 0.62 0.61 0.52\\nR-5 0.38 0.39 0.33 0.47 0.48 0.43 0.73 0.73 0.45 0.73 0.73 0.62 0.25 0.25 0.27 0.45 0.44 0.38\\nR-6 0.39 0.39 0.20 0.45 0.46 0.39 0.71 0.72 0.38 0.66 0.64 0.46 0.21 0.21 0.26 0.34 0.31 0.29\\nR-7 0.31 0.31 0.17 0.44 0.44 0.36 0.63 0.65 0.33 0.56 0.53 0.44 0.20 0.20 0.23 0.29 0.27 0.25\\nR-8 0.18 0.19 0.09 0.40 0.40 0.31 0.55 0.55 0.52 0.50 0.46 0.52 0.18 0.18 0.21 0.23 0.22 0.23\\nR-9 0.11 0.12 0.06 0.38 0.38 0.28 0.54 0.54 0.52 0.45 0.42 0.52 0.16 0.16 0.19 0.21 0.21 0.21\\nR-L 0.49 0.49 0.49 0.56 0.56 0.56 0.62 0.62 0.62 0.65 0.65 0.65 0.50 0.50 0.50 0.53 0.53 0.53\\nR-S* 0.45 0.52 0.84 0.51 0.54 0.86 0.69 0.69 0.77 0.73 0.73 0.79 0.60 0.60 0.67 0.61 0.60 0.70\\nR-S4 0.46 0.50 0.71 0.54 0.57 0.78 0.79 0.80 0.79 0.84 0.85 0.82 0.63 0.64 0.70 0.73 0.73 0.78\\nR-S9 0.42 0.49 0.77 0.53 0.56 0.81 0.79 0.80 0.78 0.83 0.84 0.81 0.65 0.65 0.70 0.70 0.70 0.76\\nR-SU* 0.45 0.52 0.84 0.51 0.54 0.87 0.69 0.69 0.77 0.73 0.73 0.79 0.60 0.59 0.67 0.60 0.60 0.70\\nR-SU4 0.47 0.53 0.80 0.55 0.58 0.83 0.76 0.76 0.79 0.80 0.81 0.81 0.64 0.64 0.74 0.68 0.68 0.76\\nR-SU9 0.44 0.50 0.80 0.53 0.57 0.84 0.77 0.78 0.78 0.81 0.82 0.81 0.65 0.65 0.72 0.68 0.68 0.75\\nR-W-1.2 0.52 0.52 0.52 0.60 0.60 0.60 0.67 0.67 0.67 0.69 0.69 0.69 0.53 0.53 0.53 0.58 0.58 0.58\\nMethod CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP\\nR-1 0.71 0.68 0.49 0.49 0.49 0.73 0.44 0.48 0.80 0.81 0.81 0.90 0.84 0.84 0.91 0.74 0.73 0.90\\nR-2 0.82 0.85 0.80 0.43 0.45 0.59 0.47 0.49 0.62 0.84 0.85 0.86 0.93 0.93 0.94 0.88 0.88 0.87\\nR-3 0.59 0.74 0.75 0.32 0.33 0.39 0.36 0.36 0.45 0.80 0.80 0.81 0.90 0.91 0.91 0.84 0.84 0.82\\nR-4 0.25 0.36 0.16 0.28 0.26 0.36 0.28 0.28 0.39 0.77 0.78 0.78 0.87 0.88 0.88 0.80 0.80 0.75\\nR-5 -0.25 -0.25 -0.24 0.30 0.29 0.31 0.28 0.30 0.49 0.77 0.76 0.72 0.82 0.83 0.84 0.77 0.77 0.70\\nR-6 0.00 0.00 0.00 0.22 0.23 0.41 0.18 0.21 -0.17 0.75 0.75 0.67 0.78 0.79 0.77 0.74 0.74 0.63\\nR-7 0.00 0.00 0.00 0.26 0.23 0.50 0.11 0.16 0.00 0.72 0.72 0.62 0.72 0.73 0.74 0.70 0.70 0.58\\nR-8 0.00 0.00 0.00 0.32 0.32 0.34 -0.11 -0.11 0.00 0.68 0.68 0.54 0.71 0.71 0.70 0.66 0.66 0.52\\nR-9 0.00 0.00 0.00 0.30 0.30 0.34 -0.14 -0.14 0.00 0.64 0.64 0.48 0.70 0.69 0.59 0.63 0.62 0.46\\nR-L 0.78 0.78 0.78 0.56 0.56 0.56 0.50 0.50 0.50 0.81 0.81 0.81 0.88 0.88 0.88 0.82 0.82 0.82\\nR-S* 0.83 0.82 0.69 0.46 0.45 0.74 0.46 0.49 0.80 0.80 0.80 0.90 0.84 0.85 0.93 0.75 0.74 0.89\\nR-S4 0.85 0.86 0.76 0.40 0.41 0.69 0.42 0.44 0.73 0.82 0.82 0.87 0.91 0.91 0.93 0.85 0.85 0.85\\nR-S9 0.82 0.81 0.69 0.42 0.41 0.72 0.40 0.43 0.78 0.81 0.82 0.86 0.90 0.90 0.92 0.83 0.83 0.84\\nR-SU* 0.75 0.74 0.56 0.46 0.46 0.74 0.46 0.49 0.80 0.80 0.80 0.90 0.84 0.85 0.93 0.75 0.74 0.89\\nR-SU4 0.76 0.75 0.58 0.45 0.45 0.72 0.44 0.46 0.78 0.82 0.83 0.89 0.90 0.90 0.93 0.84 0.84 0.88\\nR-SU9 0.74 0.73 0.56 0.44 0.44 0.73 0.41 0.45 0.79 0.82 0.82 0.88 0.89 0.89 0.92 0.83 0.82 0.87\\nR-W-1.2 0.78 0.78 0.78 0.56 0.56 0.56 0.51 0.51 0.51 0.84 0.84 0.84 0.90 0.90 0.90 0.86 0.86 0.86(A1) DUC 2001 100 WORDS MULTI (A2) DUC 2002 100 WORDS MULTI (A3) DUC 2003 100 WORDS MULTI\\n1 RFF 3 REFS 1 REF 2 REFS 1 REF 4 REFS\\n(E2) DUC02 200 (F) DUC01 400 (C) DUC02 10 (D1) DUC01 50 (D2) DUC02 50 (E1) DUC01 200\\nTable 3:  Pearson’s correla tions of 17 ROUGE  measure scores vs. human judgments for \\nthe DUC 2001, 2002, and 2003 mul ti-document summarization tasks  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6106ccdd-b014-4667-8c57-edc21b6b6eff', embedding=None, metadata={'page_label': '8', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ROUGE -L, W, and S were also shown to be very \\neffective  in automatic  evaluation of machine \\ntranslation. The stability and rel iability of ROUGE  at \\ndifferent sample sizes was reported by the author in \\n(Lin, 2004). However, how to achieve high correl a-\\ntion with human judgments in multi -document \\nsummarization tasks as ROUGE  already did in single \\ndocument summarization tasks is still an open r e-\\nsearch topic.  \\n8  Acknowledgements  \\nThe author would like to thank the anonymous r e-\\nviewers  for their constructive comments, Paul Over \\nat NIST , U.S.A , and ROUGE  users around the world  \\nfor testing and providing useful feedback on ea rlier \\nversion s of the  ROUGE  evaluation package, and the \\nDARPA TIDES project for supporting this r esearch.  \\nReferences  \\n \\nCormen, T. R., C. E. Leiserson, and R. L. Rivest. \\n1989. Introduction to Algorithms . The MIT Press.  \\nDavison, A. C. and D. V. Hinkley. 1997. Bootstrap \\nMethods an d Their Application . Cambridge Un i-\\nversity Press.  \\nLin, C. -Y. and E.  H. Hovy . 2003. Automatic e valua-\\ntion of summaries u sing n-gram co-occurrence \\nstatistics. In Proceedings of 2003 Language \\nTechnology Confe rence (HLT -NAACL 2003), \\nEdmonton, Ca nada. \\nLin, C. -Y. 2004. Looking for a f ew good metrics: \\nROUGE  and its evaluation. In Proceedings of \\nNTCIR Workshop 2004 , Tokyo, Japan.  \\nLin, C. -Y. and F.  J. Och. 2004.  Automatic evalua-\\ntion of machine t ranslation quality using longest \\ncommon subsequence and skip-bigram s tatistics. \\nIn Procee dings of 42nd Annual Meeting of ACL  \\n(ACL 200 4), Barcelona , Spain. \\nMani, I. 200 1. Automatic Summarization . John Be n-\\njamins Pu blishing Co.  \\nMelamed, I. D.  1995. Automatic evaluation and un i-\\nform f ilter cascades for inducing n-best transla-\\ntion lexicons. In Proceedings of the 3rd Workshop \\non Very Large Corpora (WVLC3) . Boston, \\nU.S.A.  \\nMelamed, I. D., R. Green and J. P. Turian (2003). \\nPrecision and recall of machine t ranslation . In \\nProcee dings of 2003 Language Technology Co n-\\nference  (HLT -NAA CL 2003), Edmonton, Ca n-\\nada. \\nOver, P. and J. Yen. 2003. An i ntrod uction to DUC \\n2003 – Intrinsic e valuation of generic news text \\nsummariz ation s ystems.  AAAAAAAAAA                                http://www -nlpir.nist.gov/projects/duc/pubs/ \\n2003slides/duc2003in tro.pdf  \\nPapineni, K., S. Roukos, T. Ward, and W. -J. Zhu. \\n2001. BLEU : A method for automatic evaluation \\nof machine translation . IBM Research Report \\nRC22176 (W0109 -022). \\nSaggion H., D. Radev, S. Teufel, and W. Lam. \\n2002. Meta -evaluation of summaries in a c ross-\\nlingual env ironment using c ontent -based m etrics. \\nIn Procee dings of COLING -2002 , Taipei, Ta i-\\nwan.  \\nRadev,  D.  S. Teufel, H. Saggion, W. Lam, J. Bli t-\\nzer, A. Gelebi, H. Qi, E. Drabek, and D. Liu. \\n2002. Evalu ation of Text Summarization in a \\nCross -Lingual Info rmation Retrieval Framework . \\nTechnical report, Center for Language and \\nSpeech Processing, Johns Hopkins University, \\nBaltimore, MD, USA.  \\nVan Rijsbergen, C.  J. 1979. Information Retrieval . \\nButterworths. London.  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a Q&A assistent. Your goal is to answer question as accurately\n",
        "as possible based on the instructions and context provided\n",
        "\"\"\"\n",
        "\n",
        "## Default format suitable for llama2\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTENT|>\")"
      ],
      "metadata": {
        "id": "tRrCwoX-wbun"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsLhmBLHwbsz",
        "outputId": "6b19fa7a-1a7e-4b29-ebd5-2eab58ce2a15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens = 256,\n",
        "    generate_kwargs={\"temperature\":0.0, \"do_sample\":False},\n",
        "    system_prompt= system_prompt,\n",
        "    query_wrapper_prompt= query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_8bit\":True}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "9a3cdaeb5312442d8e71a0e1d1bea8ca",
            "4f2996537cb44b81a6e5e4512001df35",
            "956f4a8f66a9494ca8734ec4413c6ee1",
            "38d7cc71772047979e98f54188a1693d",
            "a91039a548154b4aaa52dd9e34b9e7f6",
            "442c0db2793c45b8a5e58450cb01d8df",
            "9e631b1ba5a14f499a95f76a2e3488ca",
            "731657930a2f45cca9b158e064388c4c",
            "51f3e874e42e43869f497be2545a36bf",
            "a72e68ebfd8d4f9797b18db5b7ede47c",
            "6bc49178613744d69d053b608fe76bdf",
            "11bdec8ee4f7490e8c55b8f961a47c8b",
            "ffa648a0eb254b9fa97abc3cac821f21",
            "4b7ba57d32de47b6998ba6005240f907",
            "c4ba0eb4528842f1a6f4501f5efe9034",
            "c135b9b4034246ef99003243c35f3e05",
            "93e73c7db8ac4305aefc8abc4d014020",
            "7dbfe25924c8403c801527a247f3bd24",
            "e85f5832ea05444aab13107ff7457f82",
            "fd3b3abbc306400f9314013ab1d41212",
            "203f4880b4ae40088e8a3027221acb1d",
            "5a045b8180d7436cb25836b42baf8a08",
            "69b45099310146fa9ce9b997f7bedab1",
            "b654bb6e40e64544b122efa0bbb693a9",
            "e8aa5c8050db4488a32a4aeecc33ba37",
            "8ffc0764a0484df28667af559d332dee",
            "aafe0b8d3273476db4a7357f34a3b5f9",
            "5575dcc50f92416588fa985550b50d66",
            "a1638448a0304b0cb4edfa6f97ef01b0",
            "61804c3651c445fa83bf712c587d4ff8",
            "f1bbc56b67834429a6296d648be1108e",
            "501f681919f64979a5becb261033aa98",
            "ac683d7783ec400e9b4daab8c2313121",
            "1ce6b0e8a3fc414288a3778060d6d92e",
            "59427e692753432daa858380a0f637da",
            "4469faee156b4788827c404b9a160a97",
            "a0ce9c9222cf47a6902142cb80695183",
            "e5a5ae5adb73481d82ed2608424db79c",
            "ff98715cd65f466d9a008dc93b033445",
            "6fb7399198204a92ad5ff936431e1c6b",
            "f262c8138b6944378afd0d318b04ab47",
            "2e4e1c929a024b7a97026f0437cfd651",
            "697c8eaf5b3740048929c616a18dd3a7",
            "8ed556eab3734649a08f580be1bc3b99",
            "8ecb3102fdfe4d029f83dab20f38db00",
            "14768d78a8ea4c859725084a5f7f36c9",
            "f739186943ac4aaaa4438e775313328f",
            "75b1efa1c9a5444ab984694227d6288c",
            "131f67a5a01542c18c3fa4fd79d238b5",
            "3666a0f10c6d4b7a9abdc704ac95b509",
            "d1ce821926054ad4b91db33ac730a222",
            "b59980d12b0c42f4afd7f12be5ff18ef",
            "5d60397a50da46e9a2fd5ce051e090a2",
            "d77a8ad00d994d37a992d75467a53cc9",
            "0cd85ebf297645b3bb06a5d99377f9ac",
            "6c15b98938264695abba8c9ba3950dac",
            "c3d3c77a02764587968f6bf388c312b8",
            "f7199c60a4cb4318aa34046d4179ae49",
            "328ec93636d64a108520d6b70c022cc1",
            "bbf930e7768c4c5598a8f5f832052cfb",
            "4c33b105d7eb4d6e863e7aa4897334b7",
            "504eb4e3bf144cd689be5173082ab6c3",
            "74c950648b7e4df39a1a469b02bbf5fc",
            "2048e5a40f7b41d181d2017fb67afeaa",
            "ee1390c8cd4d42409a06f9fc34d0d08c",
            "8b4360e8bd6b461caf6d0e2bd79dc655",
            "41d5b52fa4fa4d1180f0483c48197073",
            "03e96c0e76a94d4e8c8169fa8fa917b0",
            "d470605bf51a48078ed45dce7745a6cf",
            "ecc4fa783494495d8a6078790c404f90",
            "49b76cc256034683b0194ec10578b5cc",
            "a1e61c00b8e3469f9ccdc9cbba3b1e08",
            "72c479d95c284e8992e3d0212d6f1e79",
            "753e896900e446c8b0f0c2075eb5f278",
            "cfac248fa0304ebaab28395c8405b8cc",
            "11cd9c36196a4d8199840ca701f1a7ff",
            "17952b8d2e064926be5869ae8dfbc4fc",
            "ee74ea6217a54f47bdc566775022faf9",
            "84c7c5cfab864de5a306cba6d33a1283",
            "3f0f7765744f4083831c4f690bee474e",
            "2093f3422e09452b9c4d6c495cf38e9f",
            "47c9f2a40ccf4bf690ee0c62cb08b962",
            "de93d23b6eb2471ebd192c1e92b1682b",
            "e9f537cbe1dd4fcf83ef0131a2e061ec",
            "b4e775aa19e84b71884a2ddb71f77c33",
            "663c288a12e94627977d8a16c5a37611",
            "27f980299e244c96bb139fffdbfa851d",
            "dde05a3407684aaa93cd0c3d0e0aebe4",
            "a75d277abd3647e5a1094ee73441207d",
            "e7f76b65c8714f8abf759a7742f48b1d",
            "6346f0130a5a46ea9dde476ece30b3d7",
            "a131b3043ef74cb38ce9508e293021f6",
            "80cca532b79e479da70c03886d53defb",
            "38c41764d8d3434c88a949528b9e6ac0",
            "12f522045f2e44fda6092ff822627108",
            "6b65273aa15941e48143c5ce8171da69",
            "bdd52a4e98cd4e01845e7cfa06fe8462",
            "c3f6e0ba794f4455b1532b30a2c81d55",
            "f04dcf1709b74b85b6bb67fec9550b32",
            "1dd90eed6635423dbebd310954643a5f",
            "6f06d5be68fb46dbb27ea2c81202f795",
            "7df9924dd3f04dc79caa454b64ac5422",
            "9f585bd2d4d74eb5995e3397309dd885",
            "101f3b6948c34ba9af1a1e0385018a9c",
            "b8f8bcd9fbcc43578ea17b0d76b1bd82",
            "3a67c48abd624181861c1ed05d763889",
            "8a83706605b84b6c8a092d445c574043",
            "a9d4c75f938546eeaf208dd6b66b0ce0",
            "ca4781922c8d4c05a5abc81e40d513de",
            "aa6bc2c5e7c34f6eba0c54ae0f669789",
            "3bf4f3a723934c5db78d1376d899f6bc",
            "fc3ffadd0d3f46f0b3898c9b2e98b887",
            "5eb166fcd6464c0b927cc3a74c400ea8",
            "c119379e10a2441ebbd5a63c7350765e",
            "beb5ba44426e4deca4d19213c6b1fedb",
            "7d7d9a5ded1c40959fd3748da52038e4",
            "38869a9453bb48588a2c72660300a764",
            "0498bedd84fc400490f74ea8e2d3668c",
            "2fdc86c384e64a6a823d6bd1f4f4d845",
            "41120d480cc94d66b7a42ff29b89a986",
            "e74e3d2abd614b769f325f8c020a41c7"
          ]
        },
        "id": "LfniNredwbpp",
        "outputId": "155f8532-75d5-410d-d39b-0243f72a7a68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a3cdaeb5312442d8e71a0e1d1bea8ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11bdec8ee4f7490e8c55b8f961a47c8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69b45099310146fa9ce9b997f7bedab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce6b0e8a3fc414288a3778060d6d92e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ecb3102fdfe4d029f83dab20f38db00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c15b98938264695abba8c9ba3950dac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d5b52fa4fa4d1180f0483c48197073"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee74ea6217a54f47bdc566775022faf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a75d277abd3647e5a1094ee73441207d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dd90eed6635423dbebd310954643a5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bf4f3a723934c5db78d1376d899f6bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import ServiceContext\n",
        "from llama_index.embeddings import LangchainEmbedding\n",
        "\n",
        "embedd_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name= \"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "c3412fdba8c74cdb8115a5ef34e9e4d4",
            "62dcc1a6076b430db0ba315433caa184",
            "5675bd36cc6845c192cbcb1b4cfa85b0",
            "c17e13216bc340e8805b63695ec7c0ef",
            "19aa4770299b466f93fa8a0fea76f28f",
            "a2426c460e944509987f1d2d8e172e66",
            "b8cfd324ffaa41e29d8be98ddebc5707",
            "50ad179940a7473689a237efe09627ec",
            "01652808bb384ae9845ba571e8e80acb",
            "7697e53281ac44c6acd7187918172b87",
            "a4b648f2ea264c48aad7a0eaef0baf2c",
            "788fcd4b43b34fcea56c94078efa5a4c",
            "6bde4d0800124ebabca181560223ec64",
            "7ae85d70b0434df5a7361e1c2f8e0fe2",
            "639e16da384440aba4aeb248037765a4",
            "750ce5f50e5448aeab8376d5d50f0beb",
            "b64cc131ed29411aa21d6777c456de60",
            "7b4388b19e234eac87750316d35fb4a7",
            "86053b27747949bfb94eff080db7ef24",
            "87f74c46852845808f9670d5b17a5f4b",
            "ef536322abd041f7a83e0537fa60c007",
            "4afabbdceebf44bebe8c2fc9dc5f8ce7",
            "1beb9ad656724fcea71035399a59c36f",
            "7989719c39404e9fabe91d95f7f885a6",
            "2ff8a02fd2144df2bc41b2b56d2b3bcd",
            "9918e290ea0b451cb5c6a003f58df5a6",
            "e95795f5effa49bda4fc3127863128b2",
            "548b010a06eb4502b3a8622443d348b6",
            "068af13cce2942cc9782e52d29ab47f6",
            "022e357b003640a992dee5b906a83c00",
            "c332100273e0410f8035ed0d53069897",
            "d68d2d1a54f543a99b2bce7e74b1d177",
            "30e24322c54045c99746e261d23c96a6",
            "f634f2b06c4447108e6820d9a3d94ff9",
            "f5cab174fbe74a1fb664624d6246b9c9",
            "a22ea77d119a4079a6854d219da3c9f9",
            "93008e41f0f6469cbd7afdf704e86109",
            "58a6b15adb04485b9a41dd05d9bff23b",
            "aa966b29e1fb46fe8f67a07eee6c15eb",
            "22f163e554f042fd8acfb671cb4b63a8",
            "b5e2a793a4d54df1aad575973244325a",
            "0148eba4477944bca315ea95808c687e",
            "d6dfcfc552ab4d6bb7b5afd72859d627",
            "5b836be082e146558a34c2a13f5e5d3a",
            "709c43675919420a917a71d4942d74fc",
            "ac8ae8d605e94634827793f42a579ff4",
            "373c8397932b43b0bcccb45144a2c42f",
            "7b9a0d728bd84c1e9618749e37175db6",
            "7c3b16c4c7454ef28d9e0d83c47dbfe6",
            "d51efa7f044e4c10978689bb5b5d597a",
            "d32d7993eb6d49dd80a8ea8d29a566a8",
            "affde320ac5846509a0e75e6a8b94a1f",
            "e69265ac43b84667a68b2a2bd14719f6",
            "ea4d6a9ab1014649ba96fa9054c767f6",
            "1f827c956941465198a4b82c733367ad",
            "3ce9f8154f884287ae4785c1800a8283",
            "2725dfb68f6a4b45a6a7aeaed74a46b6",
            "fb9eca1dea1f4d9bad8905d4b5cd26a3",
            "fb7f01297eec4cf0970fd17e3700ec75",
            "97f9f4356d274bc89cd444de42478b1f",
            "6754512f6fd2405c8b389061d7c5ba66",
            "52ec50b3b51341b4bd3ac5665d97690b",
            "82207c0f06ce4e48b433dff306967243",
            "52a808de56c64267b846e040da101657",
            "0b281c38a65a40a382c2f331c9ed548c",
            "2a2afa6b9cae4690b9791551663490e6",
            "c9d4b8dcc1284c4299fe96932699f5c0",
            "c4e49dfb7cb04b77a97de8ff5cafbc6b",
            "df2053dc01384278b9a872ab26b08b1c",
            "3a6d3e14d4ac430dbecd65a846d9cdab",
            "793850d4af884edba15d0fffd8b91deb",
            "f6e16984419b41a89c90e676df1405a1",
            "f67948407a80463f973b55d0b5f926d4",
            "844fed9083c8452abe297a7a731139cd",
            "9d7a3ffc2a11479fb93dc8841da82d7e",
            "5529d1ad4b7a414ab28e8de4135729e7",
            "3d0de259cab440a3bd5364b57c97c08d",
            "526182b5d780424fa599d0451da9e281",
            "dde783e0bce646a983cb58ca45fa4501",
            "8df97dafb3154b8ea89dda3fb15bd3f1",
            "7327de40bfe440049d174a3b53435027",
            "ed3fee43eb1f4e989e2d3a5524a2b1ba",
            "e4746e59e361444a8eac555c64d85a9e",
            "a52fc2f000c842839634092f265b7e15",
            "8c3087d8ee39474f87ef36e417a839ab",
            "98fb293ff8084c82926a1f4ab55f06d2",
            "f485b24e873b432e8e24ac20c4e0707a",
            "42cfcba778e7444dac3019c265e6cef7",
            "cdf44ba6f59941ae935e2dc21afbf76d",
            "972fa3ce9a614b70bd18edd77dfa647d",
            "fe0119f843e947ae89c4abc1b1a18099",
            "c10b777a9e4644cf9051ab3e2804e610",
            "60ee629044e2428b83fd489e2b766511",
            "d8e16a361cbe42669aca27da0373c0eb",
            "cdc8e0df6c3443ceb0e1408eb8b163b5",
            "dc6ed615064843f4bb0636d33e1dff65",
            "8d84ce8c1b2c4d35a4a3f7a59ded2033",
            "ddf366a5864f4305a333e37a56e62f99",
            "4aff9715b9c341969f94cb5c0f48bfd9",
            "ea44812268ab45348f24749d4dc376a3",
            "85662210812d4b1f92b393c837590b5e",
            "6cf1bcc1df794c74af6ba097320a102c",
            "d4fbafe3c48941eea00aa0e465cdbe17",
            "33f8c509594946af92993b082af87b6d",
            "5f6e08db0d94423e8474a4df788361e0",
            "6a9796eed9f84728ba6b52c0f9cb706a",
            "54bdee60700943b3ab59cf62bec05134",
            "6837e5c7b2184216b2d753b4ee8d5e44",
            "473e4baec09f46e9b1f1a6fa2b25bbcc",
            "36033629c2f44818a647e4b1da0be6a3",
            "6e663c05004e4e75bb2069d435ae3293",
            "078bd59e2c9646cf9ea93e2d18773d4b",
            "651832823e8c44ca8589e3d48c8a2478",
            "731386b39dba41339280989158673fd4",
            "f2a44171bab643f19faab772579219e7",
            "9705cd09b68849caaa0ed693d2e0619d",
            "1de56fede02444e797a638aac4f30064",
            "458ea5aa2033417396b99e7183d06094",
            "eca69af3772c4c8eacb2a11c4e30140d",
            "a39aeb6bf69843cfb312330d3438cf07",
            "280b9fc5706b40699bca49c5fd3d9421"
          ]
        },
        "id": "piLr2NElwbnx",
        "outputId": "aed966d3-9093-4d11-eee0-1edb19267e5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3412fdba8c74cdb8115a5ef34e9e4d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "788fcd4b43b34fcea56c94078efa5a4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1beb9ad656724fcea71035399a59c36f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f634f2b06c4447108e6820d9a3d94ff9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "709c43675919420a917a71d4942d74fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ce9f8154f884287ae4785c1800a8283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9d4b8dcc1284c4299fe96932699f5c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "526182b5d780424fa599d0451da9e281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdf44ba6f59941ae935e2dc21afbf76d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea44812268ab45348f24749d4dc376a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e663c05004e4e75bb2069d435ae3293"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size = 1024,\n",
        "    llm=llm,\n",
        "    embed_model= embedd_model\n",
        ")"
      ],
      "metadata": {
        "id": "jVaKQC5-5Snr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVnk5xzj5Sjy",
        "outputId": "f83622b1-2fd2-4d29-dc6b-ff3c78c8af68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=4096, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=LangchainEmbedding(model_name='sentence-transformers/all-mpnet-base-v2', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7dbb0cf3ff10>), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7dbb0cf3ff10>, id_func=<function default_id_func at 0x7dbbd9399750>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.logger.base.LlamaLogger object at 0x7dbb0d063040>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7dbb0cf3ff10>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index= VectorStoreIndex.from_documents(documents, service_context= service_context)"
      ],
      "metadata": {
        "id": "P-DcUMQk5SiL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb2LmM_s6jgA",
        "outputId": "4fbf5b06-062a-4dd7-8035-fd3d5b56f825"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.base.VectorStoreIndex at 0x7dbaea118310>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "AeJDxbwO6jc8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(query):\n",
        "\n",
        "  return query_engine.query(query)"
      ],
      "metadata": {
        "id": "sDRINCu-6jY3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(\"what is MMLU ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwSukB2I6jXI",
        "outputId": "5b3efa96-af7a-4a2f-8eb1-48dbe038ce9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response='MMLU stands for Multi-Genre Machine Learning for Unsupervised Named Entity Recognition. It is a research paper that explores the use of multi-genre training data for unsupervised named entity recognition tasks. The authors propose a novel approach that leverages the strengths of different genres to improve the overall performance of the model. They evaluate their approach on several benchmark datasets and show that it outperforms existing methods in terms of accuracy and robustness.', source_nodes=[NodeWithScore(node=TextNode(id_='a7db3a31-5ae1-4b51-8cf7-a9efde0ab6a5', embedding=None, metadata={'page_label': '26', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6fab6f5a-ca9f-42c1-aa01-72cb893d6275', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '26', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, hash='93d02f226e28e2b06723ed802b8db621fd42cd88e08001421f78e87799f26a34'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7c796330-0168-46ac-a9a4-5ad10f498557', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '25', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, hash='dde653fcca0ec062391dd1297f3f9736c35eef4a99cd5f256429c3a0a29f3bd4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b84f9618-6c9d-4f78-aec5-c40d74c80561', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='0e4f2794b742aa901377564ece5888267cb3d97609210d31e2bad4e1d27831c5')}, text='LLaMA model size0%25%50%75%100%\\n7B (6.9 GB) 13B (11.3 GB) 33B (24.7 GB) 65B (45.0 GB)Input gradient Optimizer Weight gradient Adapters ModelFigure 6: Breakdown of the memory footprint of different LLaMA models. The input gradient size is for batch\\nsize 1 and sequence length 512 and is estimated only for adapters and the base model weights (no attention).\\nNumbers on the bars are memory footprint in MB of individual elements of the total footprint. While some\\nmodels do not quite fit on certain GPUs, paged optimzier provide enough memory to make these models fit.\\nG Memory Footprint\\nThe memory footpring for QLoRA training with different LLaMA base models can be seen in\\nFigure 6. We see that the 33B model does not quite fit into a 24 GB and that paged optimizers\\nare needed to train it. Depicted is also batch size 1 with a sequence length of 512 and gradient\\ncheckpointning. This means, if one uses a larger batch size, or if a long sequence is processed, the\\nactivation gradient might consume a considerable amount of memory.\\nTable 13: The complete ordering induced by pairwise GPT-4 judgments between systems\\nModel Params Size\\nGuanaco 65B 41 GB\\nGuanaco 33B 21 GB\\nVicuna 13B 26 GB\\nChatGPT-3.5 Turbo N/A N/A\\nBard N/A N/A\\nGuanaco 13B 10 GB\\nGuanaco 7B 5 GB\\n26', start_char_idx=0, end_char_idx=1263, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.1946282292218152), NodeWithScore(node=TextNode(id_='0dd7e728-b561-4458-8019-be3abeb77a15', embedding=None, metadata={'page_label': '6', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='577a6f4f-d283-42aa-afa1-59cccc6708d9', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '6', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, hash='29b5303cfb27395ad5ec4fcf8d955e2abd22e9edd426c90c9213b849a570d19e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='15e05c48-aed5-49f1-8ed3-baa6b2ce7733', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '6', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, hash='738eccfb77ee53d501878abf6e50368721a868c44be71e40b54805fd7135c7ce'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c3147c03-3b7e-4089-a52e-9555cfc6678d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='57061678fde5a51083c258ad3db9eb61d752b13b62b4ff37c6413d3f349230e5')}, text='This might due to the double sa mple size in \\nDUC 2002 (295 vs. 149 in DUC 2001) for each sy s-\\ntem. \\nTable 2  shows the cor relation analysis results on \\nthe DUC 2003 single document very short su mmary  \\ndata.  We found that ROUGE -1, ROUGE -L, ROUGE -\\n                                                                 \\n4 Porter’s stemmer was used.  \\n5 ROUGE  website: http://www.isi.edu/~cyl/ROUGE.  \\n6 The critical  values for Pearson’s correlation at 95% \\nconfidence wit h 10, 12, 14, and 16 degrees of freedom \\nare 0.576, 0.532, 0.497, and 0.468 respe ctively.  Method CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP\\nR-1 0.76 0.76 0.84 0.80 0.78 0.84 0.98 0.98 0.99 0.98 0.98 0.99\\nR-2 0.84 0.84 0.83 0.87 0.87 0.86 0.99 0.99 0.99 0.99 0.99 0.99\\nR-3 0.82 0.83 0.80 0.86 0.86 0.85 0.99 0.99 0.99 0.99 0.99 0.99\\nR-4 0.81 0.81 0.77 0.84 0.84 0.83 0.99 0.99 0.98 0.99 0.99 0.99\\nR-5 0.79 0.79 0.75 0.83 0.83 0.81 0.99 0.99 0.98 0.99 0.99 0.98\\nR-6 0.76 0.77 0.71 0.81 0.81 0.79 0.98 0.99 0.97 0.99 0.99 0.98\\nR-7 0.73 0.74 0.65 0.79 0.80 0.76 0.98 0.98 0.97 0.99 0.99 0.97\\nR-8 0.69 0.71 0.61 0.78 0.78 0.72 0.98 0.98 0.96 0.99 0.99 0.97\\nR-9 0.65 0.67 0.59 0.76 0.76 0.69 0.97 0.97 0.95 0.98 0.98 0.96\\nR-L 0.83 0.83 0.83 0.86 0.86 0.86 0.99 0.99 0.99 0.99 0.99 0.99\\nR-S* 0.74 0.74 0.80 0.78 0.77 0.82 0.98 0.98 0.98 0.98 0.97 0.98\\nR-S4 0.84 0.85 0.84 0.87 0.88 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-S9 0.84 0.85 0.84 0.87 0.88 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-SU* 0.74 0.74 0.81 0.78 0.77 0.83 0.98 0.98 0.98 0.98 0.98 0.98\\nR-SU4 0.84 0.84 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-SU9 0.84 0.84 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99\\nR-W-1.2 0.85 0.85 0.85 0.87 0.87 0.87 0.99 0.99 0.99 0.99 0.99 0.99DUC 2001 100 WORDS SINGLE DOC DUC 2002 100 WORDS SINGLE DOC\\n1 REF 3 REFS 1 REF 2 REFS\\nTable  1: Pearson’s correlations of 17 ROUGE\\nmeasure scores vs.', start_char_idx=3648, end_char_idx=5531, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.18854031942355626)], metadata={'a7db3a31-5ae1-4b51-8cf7-a9efde0ab6a5': {'page_label': '26', 'file_name': 'ALoRa.pdf', 'file_path': '/content/data/ALoRa.pdf', 'file_type': 'application/pdf', 'file_size': 1065470, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}, '0dd7e728-b561-4458-8019-be3abeb77a15': {'page_label': '6', 'file_name': 'ROUGE.pdf', 'file_path': '/content/data/ROUGE.pdf', 'file_type': 'application/pdf', 'file_size': 77520, 'creation_date': '2024-01-31', 'last_modified_date': '2024-01-31', 'last_accessed_date': '2024-01-31'}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_response(\"what is ALoRa ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDQmLjY-7YPf",
        "outputId": "d1535402-a383-4eaa-bfe4-1cbbf0c93322"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYvylMm87YMl",
        "outputId": "4e2adc4b-6ff1-4fad-cdab-02cbac53acc0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALoRa is a conspiracy theory that suggests the earth is flat. This theory has been debunked by scientific evidence and experiments, and is not supported by any credible scientific research. The overwhelming consensus among scientists is that the earth is spherical in shape.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-XOsEGFL7kSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YOYMchRZ7kK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}